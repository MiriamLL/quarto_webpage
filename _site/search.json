[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Miriam Lerma",
    "section": "",
    "text": "About me\nI am part of the Seevogelmonitoring team at the Dachverband Deutscher Avifaunisten DDA. My work entitles analyzing spatial patterns of marine animals.\nI am also collaborating on active tracking projects for Germany (FTZ), Mexico (CICESE) and Chile (UCN).\nMy research interests include conservation, ecology, physiology, and ecotoxicology.\nI recently started to do freelance work. I assist on fieldwork, data analyses and visualizations. I am currently available for hire.\nYou can download my cv here.\n\n Contact\nDr.¬†rer. nat. Miriam Lerma  Email: miriamjlerma@gmail.com"
  },
  {
    "objectID": "blog/2021-06-03-paginadistill/paginadistill.html",
    "href": "blog/2021-06-03-paginadistill/paginadistill.html",
    "title": "Pagina distill",
    "section": "",
    "text": "Para crear una pagina web usando distill, b√°sicamente necesitas saber Rmd. Actualizaci√≥n: Apartir de 2025 uso quarto‚Ä¶\nEmpecemos por instalar el paquete distill.\n\n#install.packages(\"distill\")\nlibrary(distill)\n\nTienes que preguntarte: ¬øQue tipo de p√°gina quieres hacer? ¬øSitio web o blog?\nPara cualquiera de las opciones puedes ir a File>New Project> Distill Website o Distill Blog\nVer otros detalles\nLa estructura del sitio contiene varios archivos\n\nLa configuraci√≥n del sitio: site.yml\nLa primera p√°gina que se abre cuando entras: index.Rmd\nOtros Rmd donde puedes escribir sobre t√≠. Ej. about.Rmd\n\n\n\nPara modificar la barra de navegaci√≥n, abre el archivo site.yml  Puedes elegir donde quieres que aparezcan los contenidos. Ej. al elegir left aparecer√°n a la izquierda.\nPara agregar pesta√±as agrega text y href. Pon atenci√≥n a los espacios vacios. \n\nnavbar:\n  left: \n    - text: \"Home\"\n      href: index.html\n    - text: \"Projects\" \n      href: projects.html\n    - icon: fab fa-twitter\n      href: https://twitter.com/MiriamLermaL\n    - icon: fab fa-github\n      href: https://github.com/MiriamLL\n\n\n\n\nUsa la funci√≥n create_post y escribe dentro el nombre que quieras darle a tu post.\n\nlibrary(distill)\ncreate_post(\"Nombre de tu post\")\n\nAparecer√° algo como:\n\nv Created post at _posts/2021-05-14-Nombre de tu post\n\nY te abrir√° un nuevo Rmd.\nVer Uwe‚Äôs blog para otros detalles\n\n\n\nPuedes abrir el Rmd que creaste usando la funci√≥n create_post y escribir como en cualquier Rmd.\nLa informaci√≥n en el yaml aparecer√° en el indice de la pesta√±a.\n\n---\ntitle: \"sula\"\ndescription: |\n  A short description of the post.\nauthor:\n  - name: Miriam Lerma\n    url: {}\ndate: 05-14-2021\noutput:\n  distill::distill_article:\n    self_contained: false\n---\n\n\n\n\nPara agregar c√≥digo en tu post y que no salga por otro lado el titulo, texto y c√≥digo hay que tener espacios entre ellos.\n\nTitulo\n\nTexto\n\nChunk\n\n\n\n\nEn el paquete distill puedes usar la funci√≥n create_theme, y poner el nombre que le quieres dar al archivo.\n\ncreate_theme(\"mi_estilo\")\n\nTe va a crear un archivo css que puedes modificar para cambiar el aspecto de tu p√°gina. Una vez creado y/o modificado, debes incluirlo en site.yml.\n\noutput: \n  distill::distill_article:\n    theme: mi_estilo.css\n\nPuedes cambiar el estilo de las letras, y los colores. Ver m√°s recursos de estilos.\n\n\n\nPara que aparezcan o no las citas, hay que abrir el site.yml y escribir:\n\ncollections:\n  posts:\n    citations: false\n\n\n\n\nSe pueden agregar botones en la p√°gina para los enlaces. Para la inspiraci√≥n y fuente ve al sitio de Ella Kaye\nPara agregar botones, empieza por instalar el paquete distilltools desde github.\n\n#remotes::install_github(\"EllaKaye/distilltools\")\nlibrary(distilltools)\n\nNota Si tienes algunos problemas con rlang, puedes intentar reiniciar sesi√≥n y reinstalar el paquete rlang.\nPara agregar iconos usa la funci√≥n icon_link\n\nicon_link(icon = \"fas fa-images\",\n          text = \"slides\",\n          url = \"https://miriamll.github.io/Tutorial_distill_es/TutorialPaginaDistill\")\n\nPara elegir el icono, entrar a la pagina fontawesome: (1) Elige el icono; (2) Busca la informaci√≥n de html; (3) Copia lo que esta dentro de < y >.\nPara cambiar como se ven los botones, hay que especificarlo en el css. Por ejemplo:\n\n.icon-link {\n    background-color: transparent;\n    color: #D40067;\n    border: 1px solid;\n    border-color: #D40067;\n    padding: 5px .4rem 5px .4rem;\n    /*margin: 4px;*/\n    margin-top: 4px;\n    margin-right: 8px;\n    margin-bottom: 4px;\n    border-radius: 5px; /* Rounded edges */\n}\n\n.icon-link:hover {\n    background-color: #D40067;\n    border-color: #D40067;\n    color: white;\n}\n\n\n\n\nEn la pesta√±a donde tienes environment, history o git, debe aparecer una nueva pesta√±a con el nombre de Build\nPuedes elegir esta pesta√±a, y darle click al martillo que dice Build Website para ver como quedo tu p√°gina.\nEn la pesta√±a Viewer‚Ä¶ Ya puedes ver tu pagina distill ü•≥.\n\n\n\nUno de los retos es poner tu pagina online.\n\nSe pueden subir los archivos directamente a: Netlify\nSe pueden subir los archivos a github, y conectarlo con Netlify.\nRecomendado porque puedes estar actualizando los materiales desde RStudio.\n\nDe entrada, tu sitio sera tunombre.netlify.app. Si quieres que sea tunombre.com u otro, cuesta alrededor de 12 dolares, pero varia mucho.\nPublicar sitio por Lisa Lendway\n\n\n\n\nTutoriales Crear articulo en distill Crear sitio (Re-)introducing Distill for R Markdown Ejemplos de paginas\nBlogs Galeria Paso a paso: crear un sitio por Lisa Lendway\nVideos RLadies Crear un sitio por Lisa Lendway"
  },
  {
    "objectID": "blog/2021-06-03-paquetes/paquetes.html",
    "href": "blog/2021-06-03-paquetes/paquetes.html",
    "title": "Paquetes",
    "section": "",
    "text": "Para crear un paquete principalmente hay que saber crear funciones.\nPero ¬øPorque crear un paquete? ü§î\nAlgunas razones: \n\nRepito pasos y an√°lisis con datos similares, hasta ahora re-uso funciones de scripts anteriores. \nEstudiantes y colegas me preguntan como realizar an√°lisis similares, pero no est√°n familiarizados con la sintaxis de las funciones \nLos art√≠culos me piden m√°s detalles de como se realizaron los an√°lisis y el espacio es limitado para dar detalles.\nAunque existan paquetes similares no cubren todos los pasos, sirven de inspiraci√≥n pero no resuelven el problema.\n\n\n\nPara crear paquetes se puede usar el paquete usethis\n\n#install.packages('usethis')\nlibrary(usethis)\n\nAntes de iniciar a crear un paquete, se puede consultar si el nombre no esta siendo usando en otro paquete en la p√°gina CRAN. Tambi√©n existe el paquete available para revisar si el paquete ya existe en CRAN o en github y si el nombre del paquete puede ser ofensivo.\n\ninstall.packages('available')\nlibrary(available)\navailable(\"nombre_paquete\")\n\nTe va preguntar si quieres que revise por contenido ofensivo, puedes poner Y.\n\nUrban Dictionary can contain potentially offensive results,\n  should they be included? [Y]es / [N]o:\n\nDespu√©s abre paginas para mostrar que significa el nombre de el paquete.\n\n\n\nPara crear un paquete la funci√≥n create_package crea el esqueleto de los paquetes.  Dentro puedes poner el nombre del paquete que te interesa crear.\n\nusethis::create_package(\"nombre_paquete\")\n\nAparecer√° algo as√≠:\n\n‚àö Creating 'nombre_paquete/'\n‚àö Setting active project to '...'\n‚àö Creating 'R/'\n‚àö Writing 'DESCRIPTION'\nPackage: nombre_paquete\nTitle: What the Package Does (One Line, Title Case)\nVersion: 0.0.0.9000\nAuthors@R (parsed):\n    * First Last <first.last@example.com> [aut, cre] (YOUR-ORCID-ID)\nDescription: What the package does (one paragraph).\nLicense: `use_mit_license()`, `use_gpl3_license()` or friends to\n    pick a license\nEncoding: UTF-8\nLazyData: true\nRoxygen: list(markdown = TRUE)\nRoxygenNote: 7.1.1\n‚àö Writing 'NAMESPACE'\n‚àö Writing 'nombre_paquete.Rproj'\n‚àö Adding '^nombre_paquete\\\\.Rproj$' to '.Rbuildignore'\n‚àö Adding '.Rproj.user' to '.gitignore'\n‚àö Adding '^\\\\.Rproj\\\\.user$' to '.Rbuildignore'\n‚àö Opening '...' in new RStudio session\n‚àö Setting active project to '<no active project>'\n\nNota: Si te encuentras dentro de un proyecto va a preguntar si deseas sobregrabar el proyecto existente. Si es el caso: 2: Absolutely\n\nv Writing 'NAMESPACE'\nOverwrite pre-existing file 'nombre_paquete.Rproj'?\n\n1: Not now\n2: Absolutely\n3: No way\n\nAparecer√° algo como:\n\nv Writing 'nombre_paquete.Rproj'\nv Adding '^nombre_paquete\\\\.Rproj$' to '.Rbuildignore'\nv Adding '^\\\\.Rproj\\\\.user$' to '.Rbuildignore'\nv Opening '...' in new RStudio session\nv Setting active project to '<no active project>'\n\nSe abrir√° el proyecto en otra ventana.\n\n\n\nLa funci√≥n anterior cre√≥ los archivos:\n- .gitignore  - .Rbuildignore - DESCRIPTION - NAMESPACE - README.md\nLas Carpetas: - R\n\n\n\nSi ya tienes instalado git puedes directamente conectar el paquete con tu repositorio, escribiendo en tu consola:\n\nusethis::use_git()\n\nAparecer√° algo como:\n\n‚àö Setting active project to '...'\n‚àö Adding '.Rdata', '.httr-oauth', '.DS_Store' to '.gitignore'\nThere are 6 uncommitted files:\n '.gitignore'\n '.Rbuildignore'\n 'DESCRIPTION'\n 'NAMESPACE'\nIs it ok to commit them?\n\n1: Absolutely not\n2: Yup\n3: Negative\n\n3: Yup‚Ä¶ es si\nAparecer√° algo como:\n\n‚àö Adding files\n‚àö Making a commit with message 'Initial commit\n A restart of RStudio is required to activate the Git pane\nRestart now?\n1: Yup\n2: No\n3: Not now\n\nSi deseas reiniciar RStudio para activar git:\n1: Yup‚Ä¶ es sip\nSe reiniciara la sesi√≥n\nPara ahora conectarlo con github, hay que escribir en la consola:\n\nusethis::use_github()\n\nAparecer√° algo como:\n\ni Defaulting to https Git protocol\n‚àö Setting active project to 'C:/...'\n‚àö Checking that current branch is default branch ('master')\n‚àö Creating GitHub repository '...'\n‚àö Setting remote 'origin' to 'https://github.com/...git'\n‚àö Setting URL field in DESCRIPTION to 'https://github.com/...'\n‚àö Setting BugReports field in DESCRIPTION to 'https://github.com/...'\nThere is 1 uncommitted file:\n 'DESCRIPTION'\nIs it ok to commit it?\n1: No\n2: No way\n3: I agree\n\nSi es correcto elegir 3: I agree, que significa de acuerdo\nAparecer√° algo como:\n\n‚àö Adding files\n‚àö Making a commit with message 'Add GitHub links to DESCRIPTION'\n‚àö Pushing 'master' branch to GitHub and setting 'origin/master' as upstream branch\n‚àö Opening URL 'https://github.com/...'\n\nAbrir√° github\n\n\n\nEscribir en la consola\n\ndevtools::check()\n\nEsta funci√≥n revisa la versi√≥n, plataforma, sesiones y dem√°s.\nTarda un poquito.\n\n0 errors ‚àö | 1 warning x | 0 notes ‚àö\n\nEl warning ocurre porque hay que darle una licencia al paquete.\n\nNon-standard license specification:\n    `use_mit_license()`, `use_gpl3_license()` or friends to pick a\n    license\n  Standardizable: FALSE\n\n\n\n\nPara software la licencia m√°s com√∫n es MIT\n\nusethis::use_mit_license(\"Mi Nombre\")\n\nAparecer√° algo como:\n\n‚àö Setting License field in DESCRIPTION to 'MIT + file LICENSE'\n‚àö Writing 'LICENSE'\n‚àö Writing 'LICENSE.md'\n‚àö Adding '^LICENSE\\\\.md$' to '.Rbuildignore'\n\nPara revisar si funcion√≥:\n\ndevtools::check()\n\nTarda un poquito.\n\n0 errors ‚àö | 0 warning ‚àö | 0 notes ‚àö\n\n\n\n\nPara agregar metadata se debe abrir y modificar el documento que dice DESCRIPTION, agregando tus datos.\nEsta es la informaci√≥n de contacto si hay problemas con el paquete.\n\nAuthors@R:\n  person(given = \"Miriam\",\n         family = \"Lerma\",\n         role = c(\"aut\", \"cre\"),\n         email = \"miriamjlerma@gmail.com\",\n         comment = c(ORCID = \"0000-0002-7632-9289\"))\n\n\n\n\nPara crear un nuevo README, el paquete usethis tiene una funci√≥n para crearlo de manera autom√°tica,\n\nlibrary(usethis)\nuse_readme_rmd(open = rlang::is_interactive())\n\n\n‚àö Setting active project to '...'\n‚àö Writing 'README.Rmd'\n‚àö Adding '^README\\\\.Rmd$' to '.Rbuildignore'\n Modify 'README.Rmd'\n‚àö Writing '.git/hooks/pre-commit'"
  },
  {
    "objectID": "blog/2021-06-03-paquetes/paquetes.html#documentar-datos",
    "href": "blog/2021-06-03-paquetes/paquetes.html#documentar-datos",
    "title": "Paquetes",
    "section": "2.1. Documentar datos",
    "text": "2.1. Documentar datos\nPara documentar tus datos, puedes abrir un nuevo script (File>NewFile>R Script) o usar la funci√≥n del paquete usethis.\nTanto la funci√≥n use_r como use_data funcionan.\n\nusethis::use_r(\"mis_datos\")\nusethis::use_data(\"mis_datos\")\n\nEsta funci√≥n agrega comentarios Roxigen y guarda el documento en tu folder llamado R.  En mi caso yo le di al script el mismo nombre que a los datos.\n\n#' Mis datos son datos de...\n#' Contiene 264197 obs de 1 variable.\n#' @docType data\n#' @usage data(mis_datos)\n#' @format Un data frame con 1 variable\n#' @keywords datasets\n#' @references Lerma et al. 2021\n#' @examples\n#' data(mis_datos)\n\"mis_datos\"\n\nUna vez creado el archivo .rda y .R se puede revisar si funcion√≥ usando funciones del paquete devtools\n\ndevtools::check()\n\nSi los datos son muy pesados y te aparece un mensaje como este:\n\nNote: significantly better compression could be obtained\n          by using R CMD build --resave-data\n\nEs mejor agregar el argumento compress.\n\nsave(TDR_raw, file=\"TDR_raw.rda\", compress = \"xz\")"
  },
  {
    "objectID": "blog/2021-06-03-paquetes/paquetes.html#resumido",
    "href": "blog/2021-06-03-paquetes/paquetes.html#resumido",
    "title": "Paquetes",
    "section": "2.2. Resumido",
    "text": "2.2. Resumido\nAgrega datos al paquete\n\nsave(mis_datos, file=\"mis_datos.rda\")\n\n# Tu objeto, tu documento rda y tu R deben tener el mismo nombre. \n\nusethis::use_r(\"mis_datos\")\n\n#Insertar Roxigen Skeleton  (CTRL+ALT+SHIFT+R) o copiar y pegar de otro archivo\n\ndevtools::document()\n\ndevtools::check()\n\nSi despu√©s de usar devtools::check(), aparece:\n\n0 errors ‚àö | 0 warnings ‚àö | 0 notes ‚àö\n\nYa tienes tu primer paquete con datos ü•≥.\n\nPara instalar el paquete de manera local\n\n\ndevtools::install(\"C:/....\")\n\n\nPara instalar el paquete desde github\n\n\ndevtools::install_github(\"Desarrollador/paquete\")"
  },
  {
    "objectID": "blog/2021-06-03-paquetes/paquetes.html#actualizaciones",
    "href": "blog/2021-06-03-paquetes/paquetes.html#actualizaciones",
    "title": "Paquetes",
    "section": "2.3. Actualizaciones",
    "text": "2.3. Actualizaciones\nRData\nSi aparece el mensaje WARNING: Added dependency on R >= 3.5.0 because serialized objects in serialize/load version 3 cannot be read in older versions of R.  Hay que usar .RData\n\nsave(TDR_raw, file = \"TDR_raw.RData\", version = 2)\n\nLazyData Tambien tener cuidado de incluir en DESCRIPTION\n\nLazyData: true\n\nIf LazyData DB of 21.3 MB without LazyData Compression set\nAgregar\n\nLazyDataCompression:xz\n\nIf checking data for ASCII and uncompressed saves ‚Ä¶ Warning: package needs dependence on R (>= 2.10)\nIn DESCRIPTION:\n\nDepends: R (>= 2.10)\n\nPara poder usar directamente los datos"
  },
  {
    "objectID": "blog/2021-06-03-paquetes/paquetes.html#funci√≥n-sin-dependencias",
    "href": "blog/2021-06-03-paquetes/paquetes.html#funci√≥n-sin-dependencias",
    "title": "Paquetes",
    "section": "3.1. Funci√≥n sin dependencias",
    "text": "3.1. Funci√≥n sin dependencias\nPara agregar la funci√≥n al paquete.\n\nusethis::use_r(\"mi_primera_funcion\")\n\nAbre un nuevo script\nPega all√≠ la funci√≥n\nAparecer√° algo como:\n\n‚àö Setting active project to 'C:/...'\n Modify 'R/mi_primera_funcion.R'\n Call `use_test()` to create a matching test file\n\nAhora en la carpeta R aparecer√° dentro la funci√≥n\nAgregar un Roxigen skeleton:  - Poner el cursor justo en la primera linea de la funci√≥n.  - Abrir la pesta√±a de Code>Insert Reoxygen Skeleton (tambi√©n funciona con Control+Alt+Shift+R). \nAparecer√° algo como:\n\n#' Title\n#'\n#' @param data \n#' @param trip_start \n#' @param trip_end \n#'\n#' @return\n#' @export\n#'\n#' @examples\n\nDespu√©s de rellenar la informaci√≥n necesaria, para agregar la funci√≥n al paquete, escribe en la consola:\n\ndevtools::document()\n\nAparecer√° algo como:\n\nWriting NAMESPACE\nWriting mi_primera_funcion.Rd\n\nAl abrir la carpeta man aparecer√° un documento rellenado.\nEl nombre man viene de manual y esta es la documentaci√≥n del paquete.\nNo debe ser editado de manera manual.\nYa puedes revisar la documentaci√≥n.\n\n?mi_primera_funcion\n\n\ndevtools::check()"
  },
  {
    "objectID": "blog/2021-06-03-paquetes/paquetes.html#funciones-con-dependencia",
    "href": "blog/2021-06-03-paquetes/paquetes.html#funciones-con-dependencia",
    "title": "Paquetes",
    "section": "3.2. Funciones con dependencia",
    "text": "3.2. Funciones con dependencia\nTe recomiendo probar tu funci√≥n con datos de ejemplo, antes de incluirla en el paquete.\n\nRevisa que paquetes son requeridos, por ejemplo: tidyr\n\n\n\n\n\nDefine los argumentos por separado como objeto.\n\n\ndata=misdatos\nmi_primer_argumento='mi_primer_argumento'\nmi_segundo_argumento='mi_segundo_argumento'\n\n\nPrueba la funci√≥n\n\n\nmi_funcion(data = mis_datos,\n           mi_primer_argumento='mi_primer_argumento',\n           mi_segundo_argumento='mi_segundo_argumento')\n\nOtra opci√≥n es usar el paquete ‚Äòtestthat‚Äô para probar tu funci√≥n.\nPara agregar la funci√≥n al paquete:\n\nusethis::use_r(\"tu_funcion\")\n\nAbre un nuevo script. Pega all√≠ la funci√≥n. En la consola aparecer√° algo como:\n\n Modify 'R/tu_funcion.R'\n Call `use_test()` to create a matching test file\n\nAhora en la carpeta R dentro del paquete aparece la funci√≥n.\nNota sugiere que uses use_test pero puede en conflicto con el siguiente paso.\nPuedes usar /rm() para quitar tu funci√≥n.\nPara poner la funci√≥n en la memoria local y confirmar que se ejecute hay que incluirla en el paquete y probarla.\n\ndevtools::load_all()\n\nPara documentar la funci√≥n hay que crear un Roxigen skeleton.\nPara esto se debe poner el cursor justo en la primera linea de la funci√≥n.\nDespu√©s ir a la pesta√±a de Code>Insert Reoxygen Skeleton (tamb√≠en funciona con Control+Alt+Shift+R).\nVa a aparecer algo as√≠:\n\n#' Title\n#'\n#' @param data \n#' @param mi_primer_argumento \n#' @param mi_segundo_argumento \n#'\n#' @return\n#' @export\n#'\n#' @examples\n\nNota que identifica de manera autom√°tica las variables de la funci√≥n\nAhora que ya esta la funci√≥n y la documentaci√≥n para agregar el paquete hay que escribir en la consola:\n\ndevtools::document()\n\nAparece:\n\nWriting NAMESPACE\nWriting mi_funcion.Rd\n\nAhora en la carpeta man, aparece un documento rellenado.\nman viene de manual y esta es la documentaci√≥n del paquete.\nNota No debe ser editado de manera manual.\nPuedes revisar la documentaci√≥n de la funci√≥n.\n\n?mi_funcion\n\nDependencias son paquetes necesarios para que la funci√≥n, funcione.\nPara revisar si necesitas dependencias se puede usar:\n\ndevtools::check()\n\nSi tu paquete tiene dependencias, aparecer√°n errores, warnings y notas.\nPor ejemplo, un paquete que usa: - un %>% (pipe) depende del paquete magrittr, y - la funci√≥n separate depende del paquete dplyr.\nPara agregar las dependencias se puede escribir el nombre de los paquetes dentro de la funci√≥n use_package\n\nusethis::use_package(\"dplyr\")\n\nAparecer√° algo como:\n\n‚àö Adding 'dplyr' to Imports field in DESCRIPTION\n Refer to functions with `dplyr::fun()`\n\nAs√≠ mismo aparecer√° en el documento DESCRIPTION:\n\nImports: \n    dplyr\n\nLo siguiente es especificar el paquete en la funci√≥n, tal como recomienda el siguiente mensaje.\n\n Refer to functions with `dplyr::fun()`\n\n\npipe üñáÔ∏è\nLa funci√≥n pipe (%>%) del paquete magrittr es especial.\nPor lo que hay que usar:\n\nusethis::use_pipe()\n\nAparecer√° algo como:\n\n‚àö Adding 'magrittr' to Imports field in DESCRIPTION\n‚àö Writing 'R/utils-pipe.R'\n Run `devtools::document()` to update 'NAMESPACE'\n\nSe recomienda volver a documentar.\n\ndevtools::document()\n\nAhora deber√° aparecer en la carpeta R un script llamado utils-pipe.R y\nen el archivo DESCRIPTION deber√° aparecer Imports magrittr\nPara checar el paquete:\n\ndevtools::check()\n\n\n0 errors ‚àö | 0 warnings ‚àö | 0 notes ‚àö\n\nListo! el paquete esta completo ü•≥\n\n\nstats üßÆ\nCuando queremos agregar alguna funci√≥n que incluya c√°lculos de desviaci√≥n est√°ndar, aunque no se necesite cargar el paquete en RStudio, la funci√≥n proviene de un paquete.\nEl paquete es stats\nPor lo tanto el paquete stats debe ser incluido en las dependencias.\n\nusethis::use_package(\"stats\")\n\nY agregado a la funci√≥n.\n\nresultado<- data %>%\n    dplyr::summarise(max_depth_mean=mean(.data[[var1]]),\n                     max_depth_sd=stats::sd(.data[[var1]]),\n                     max_depth_max=max(.data[[var1]]))\n\n\ndevtools::document()\ndevtools::check()\n\n\ndevtools::check()\n\n\n0 errors ‚àö | 0 warnings ‚àö | 0 notes ‚àö\n\nListo! el paquete esta completo ü•≥\n\n\nggplot üé®\nCuando creamos una funci√≥n con ggplot hay que declarar el uso de la funci√≥n en varios argumentos de la funci√≥n. Aqu√≠ puedes leer m√°s.\nSi no, aparecer√° un error:\n\n1 error x | 0 warnings ‚àö | 1 note x\n\nEsto occurre debido a que al revisar el paquete, no detecta varias funciones del paquete ggplot.\n\nno visible global function definition for 'aes'\n\nEjemplo:\n\nggplot2::ggplot(data=data,ggplot2::aes(x=.data[[var1]],\n                              y=as.numeric(.data[[var2]])))+\n    ggplot2::geom_line()+\n    ggplot2::ylab(\"Diving depth (m)\")+\n    ggplot2::xlab(\"Month.Day Hour:Minute\")+\n    ggplot2::scale_y_reverse()+\n    ggplot2::theme_bw()\n\n\nchecking R code for possible problems ...\n\nTambi√©n pueden aparecer problemas con las variables al usar ggplot dentro de una funci√≥n.\n\nno visible binding for global variable '.data'\n\nPara resolver esto hay que declarar las variables dentro de la funci√≥n y posteriormente usar .data\n\ndata<-TDR_trip\nvar1<-time_column\nvar2<-depth_column\n  \nggplot2::ggplot(data,\n                ggplot2::aes(x=.data[[var1]],\n                             y=.data[[var2]))+\n    ggplot2::geom_line()\n\n\ndevtools::document()\ndevtools::check()\n\n\ndevtools::check()\n\n\n0 errors ‚àö | 0 warnings ‚àö | 0 notes ‚àö\n\nListo! el paquete esta completo ü•≥"
  },
  {
    "objectID": "blog/2021-06-03-paquetes/paquetes.html#otros-problemas",
    "href": "blog/2021-06-03-paquetes/paquetes.html#otros-problemas",
    "title": "Paquetes",
    "section": "3.3. Otros problemas üëª",
    "text": "3.3. Otros problemas üëª\nProblema En algunas funciones puedes haber usado assign. Usar assign no es recomendado, por lo que aparecer√° una nota.  Soluci√≥n Usar return().\nProblema No nested functions, no circular dependencies.  Soluci√≥n No puedes usar funciones de tu paquete en otras funciones del mismo paquete. \nProblema Borrar funciones. Soluci√≥n Para borrar funciones se debe borrar el script en el archivo R y volver a documentar el paquete para que se reflejen los cambios.\nProblema El ejemplo tiene m√°s de 100 caracteres, es considerado muy largo.  Soluci√≥n Separar en la documentaci√≥n.\n\n\\examples lines wider than 100 characters:\n\nProblema Solo puedo tener un resultado (return)  Soluci√≥n Crea una lista con los returns. Por ejemplo:\n\nfuncion(primer_argumento, segundo_argumento){\n  multiplicacion<-primer_argumento*segundo_argumento\n  suma<-primer_argumento+segundo_argumento\n  lista<-(list(\"multiplicacion\"=multiplicacion,\"suma\"=suma))\n  return(lista)\n}\n\nProblema Al usar slot en sapply. Soluci√≥n Hay que agregar la dependencia methods."
  },
  {
    "objectID": "blog/2021-06-03-paquetes/paquetes.html#resumido-1",
    "href": "blog/2021-06-03-paquetes/paquetes.html#resumido-1",
    "title": "Paquetes",
    "section": "3.4. Resumido",
    "text": "3.4. Resumido\n\nusethis::use_r(\"nombre_funcion\")\n\n#Insertar Roxigen Skeleton  (CTRL+ALT+SHIFT+R)\n\ndevtools::document()\n\ndevtools::check()\n\nusethis::use_package(\"ggplot2\")\n\n#Referirse a funciones con ::\n\ndevtools::check()"
  },
  {
    "objectID": "blog/2021-06-03-paquetes/paquetes.html#warnings",
    "href": "blog/2021-06-03-paquetes/paquetes.html#warnings",
    "title": "Paquetes",
    "section": "4.1 Warnings ‚ö†Ô∏è",
    "text": "4.1 Warnings ‚ö†Ô∏è\nEs √∫til agregar warnings para que el usuario (quien sera a veces tu mismo) pueda corregir errores.\nPara checar que el data frame contenga datos, revisa que el numero de filas no sea cero.\n\n if (nrow(data)!=0){\n  } else {\n    warning(\"Please check the name of the data frame\")\n  }\n\nTambi√©n puedes revisar si tu data frame contiene una columna de acuerdo a su nombre\n\nif (\"Nombre_columna\" %in% colnames(data)){\n  } else {\n    warning(\"Please check that your data frame has X column, otherwise please rename/create the column\")\n  }\n\nAdemas podemos revisar si una columna en especifico aparece en el data frame\n\nif (!is.null(data[[columna]])) {\n  } else {\n    warning(\"The column X is not in your dataframe. Please check the name of the column\")\n  }\n\nÔ∏è"
  },
  {
    "objectID": "blog/2021-06-03-paquetes/paquetes.html#crear-tu-propio-sticker",
    "href": "blog/2021-06-03-paquetes/paquetes.html#crear-tu-propio-sticker",
    "title": "Paquetes",
    "section": "4.2. Crear tu propio sticker ‚ù£Ô∏è",
    "text": "4.2. Crear tu propio sticker ‚ù£Ô∏è\nPara crear un hexSticker puedes usar plantillas:  - En powerpoint plantilla hecha por Emi Tanaka  - En R paquete hexSticker hecho por GuangchuangYu\nPara instalar el paquete hexSticker, puedes descargarlo desde en CRAN:\n\ninstall.packages(\"hexSticker\")"
  },
  {
    "objectID": "blog/2021-06-03-paquetes/paquetes.html#zenodo",
    "href": "blog/2021-06-03-paquetes/paquetes.html#zenodo",
    "title": "Paquetes",
    "section": "4.3. Zenodo üîó",
    "text": "4.3. Zenodo üîó\nZenodo es un repositorio de acceso abierto operado por CERN (Organizaci√≥n Europea para la Investigaci√≥n Nuclear).\nVentajas Permite que se depositen all√≠ art√≠culos de investigaci√≥n, datos, software, informes y otro tipo de objeto digital relacionado con la investigaci√≥n. La ventaja frente a github es que asigna un DOI.\nDesventajas Las versiones de paquetes se pueden registrar en zenodo. No obstante, NO es tan practico ya que cada versi√≥n tiene su propio DOI y la versi√≥n anterior no puede ser eliminada."
  },
  {
    "objectID": "blog/2021-07-05-GIScolores/GIScolores.html",
    "href": "blog/2021-07-05-GIScolores/GIScolores.html",
    "title": "Colores en mapas",
    "section": "",
    "text": "Este post es acerca de como crear un mapa base de M√©xico, incluir puntos para sitios de muestreo y cambiar los colores de puntos en un mapa en ggplot y en QGIS."
  },
  {
    "objectID": "blog/2021-07-05-GIScolores/GIScolores.html#descargar-datos",
    "href": "blog/2021-07-05-GIScolores/GIScolores.html#descargar-datos",
    "title": "Colores en mapas",
    "section": "Descargar datos",
    "text": "Descargar datos\nLo primero seria descargar los datos usando la funci√≥n getData.  Una vez cargados los datos, podemos hacer una selecci√≥n de los estados que nos interesen."
  },
  {
    "objectID": "blog/2021-07-05-GIScolores/GIScolores.html#mapa-base",
    "href": "blog/2021-07-05-GIScolores/GIScolores.html#mapa-base",
    "title": "Colores en mapas",
    "section": "Mapa base",
    "text": "Mapa base\nPara crear un mapa centrado en estos estados se puede usar el siguiente c√≥digo:\n\nMapaBase<-ggplot()+\n  geom_sf(data= Mexico, fill='#264653', col='black')+\n  geom_sf(data= Queretaro, fill='#2a9d8f')+ #para resaltar estados\n  geom_sf(data= Guanajuato, fill='#2a9d8f')+ #para resaltar estados\n  \n  annotation_north_arrow(location=\"tr\",which_north=\"true\",style=north_arrow_fancy_orienteering ())+ #Norte\n  ggspatial::annotation_scale(location = \"bl\",bar_cols = c(\"grey60\", \"white\"))+ #Escala\n\n  theme_bw()+\n  coord_sf(xlim = c(-105,-95), #limites del mapa\n           ylim = c(18 ,24), #limites del mapa\n           expand = FALSE)\nMapaBase\n\nDentro de geom_sf el argumento fill es el color con el que se rellenaran los pol√≠gonos, lo puedes cambiar a como m√°s te guste. En el mapa use c√≥digos hexa-n√∫mericos que pueden ser encontrados en coolors, para m√°s instrucciones ve aqu√≠"
  },
  {
    "objectID": "blog/2021-07-05-GIScolores/GIScolores.html#agregar-un-sitio",
    "href": "blog/2021-07-05-GIScolores/GIScolores.html#agregar-un-sitio",
    "title": "Colores en mapas",
    "section": "Agregar un sitio",
    "text": "Agregar un sitio\nAhora para agregar sitios, se deben especificar las coordenadas. En el ejemplo el argumento geom_point x y y son las coordenadas. En color eleg√≠ el color que le quiero dar a ese punto y lo escrib√≠ como c√≥digo hexa-n√∫merico (hex).\n\nMapaSitios<-MapaBase+geom_point(aes(x=-100, y=21, \n                                    color='#e63946'))+ #elegir el color\n  theme(legend.position='none') #evitar la etiqueta\nMapaSitios"
  },
  {
    "objectID": "blog/2021-07-05-GIScolores/GIScolores.html#agregar-varios-sitios",
    "href": "blog/2021-07-05-GIScolores/GIScolores.html#agregar-varios-sitios",
    "title": "Colores en mapas",
    "section": "Agregar varios sitios",
    "text": "Agregar varios sitios\nOtra opci√≥n es que si tienes muchos puntos, es m√°s pr√°ctico crear o cargar un data frame.\n\nDatosInventados<-data.frame(long=c(-102,-101,-100,-99,-98),\n           lat=c(21.5,21.3,20.9,21,20))\n\nPuedes concatenar varios c√≥digos hex y crear tu propia paleta.\n\npaleta<-c(\"#f8ffe5\",\"#06d6a0\",\"#1b9aaa\",\"#ef476f\",\"#ffc43d\")\n\nAgregar la paleta a las especificaciones del gr√°fico es dentro de geom_point, en color. Para hacer los puntos m√°s grandes tambi√©n puedes agregar el argumento size en geom_point.\n\nMapaSitios<-MapaBase+\n  geom_point(data=DatosInventados,aes(x=long, y=lat,color=paleta),size=3)+ \n  theme(legend.position='none') #evitar la etiqueta\nMapaSitios\n\n\n\n\n\n\n\n\n\n\n\n\n\nPara exportar el mapa, ve aqu√≠"
  },
  {
    "objectID": "blog/2021-09-24-home-range-adehabitathr/home-range-adehabitathr.html",
    "href": "blog/2021-09-24-home-range-adehabitathr/home-range-adehabitathr.html",
    "title": "Home Range & adehabitatHR",
    "section": "",
    "text": "In this post, you will learn how to:  - Calculate UDs from test data from Masked boobies.  - Calculate UDs using adehabitat.  - Export UDs as shapefiles to visualize in other programs. \nNote that reference system must be adjusted, also href can be adapted."
  },
  {
    "objectID": "blog/2021-09-24-home-range-adehabitathr/home-range-adehabitathr.html#transform-to-spatial.",
    "href": "blog/2021-09-24-home-range-adehabitathr/home-range-adehabitathr.html#transform-to-spatial.",
    "title": "Home Range & adehabitatHR",
    "section": "Transform to spatial.",
    "text": "Transform to spatial.\nYou can use the package sp to transform your data frame to spatial data (in this case you end up with SpatialPointsDataFrame). This way you can tell R that you have coordinates. If you dont have the package sp you need to install it.\n\n#install.packages('sp')\nlibrary(sp)\nDataSp<-as.data.frame(Data)\ncoordinates(DataSp) <- c(\"Longitude\", \"Latitude\")\nclass(DataSp)"
  },
  {
    "objectID": "blog/2021-09-24-home-range-adehabitathr/home-range-adehabitathr.html#export",
    "href": "blog/2021-09-24-home-range-adehabitathr/home-range-adehabitathr.html#export",
    "title": "Home Range & adehabitatHR",
    "section": "Export",
    "text": "Export\nI advice to first identify which folder do you want to use to save your polygons. I have an Rproject and I have created a folder named GIS where I want my polygons to be.\n\nlibrary(here)\n\nThere are many ways to export your polygons.\nIf you still have the package rgdal, you can use writeOGR, but nowdays is deprectated.\n\n# writeOGR is deprecated \n# writeOGR(GPS01UD95HR, dsn = my_folder, layer = 'GPS01HR95', driver = \"ESRI Shapefile\")\n\nThe other way to export your polygons is using the package sf. However, to be able to export your polygons, they should be transform to a sf object.\n\nlibrary(sf)\nclass(GPS01UD95HR)\nGPS01SF95<-st_as_sf(GPS01UD95HR)\nst_write(GPS01SF95, paste0(here(), \"/GPS01SF95.shp\"))\n\n‚Ä¶ and thats it.\nHopefully now you have your shapefiles that can be open in any GIS software such as QGIS."
  },
  {
    "objectID": "blog/2021-10-27-gitgithub/gitgithub.html",
    "href": "blog/2021-10-27-gitgithub/gitgithub.html",
    "title": "Git & Github",
    "section": "",
    "text": "Intro\nIn this presentation, we will have a short intro on:\n- Git\n- Github\n- Reproducibility\n- Git+Github\n- Naming things\n‚ö°‚ö°‚ö°\n\n\n\n\n\n\n\n\n\n\n\n Open presentation\n\n\n‚ö°‚ö°‚ö°\n\n\nKeen to learn more?\n\nHappy git:\nHappy Git by Jennifer Bryan\nTutorials\nRLadiesFreiburg"
  },
  {
    "objectID": "blog/2021-11-25-embc/embc.html",
    "href": "blog/2021-11-25-embc/embc.html",
    "title": "EMbC",
    "section": "",
    "text": "In this post, you will learn how to:  - Classify behavioral states during foraging trips from test data from Masked boobies."
  },
  {
    "objectID": "blog/2021-11-25-embc/embc.html#nest-or-no-nest",
    "href": "blog/2021-11-25-embc/embc.html#nest-or-no-nest",
    "title": "EMbC",
    "section": "Nest or no nest?",
    "text": "Nest or no nest?\nThe data I am using does not include locations when the animal was on the nest.\nTo remove the nest locations, in the package sula there is this function recortar_periodo which allows you to filter your data and keep the period when the bird was at sea.\nFor the example, I know the time when this individual (GPS_01) started and ended its trip and keep the locations inside this time range.\nIf you dont have this information, you might need to first identify the start and end of trips.\n\nGPS_ind<-recortar_periodo(GPS_data=GPS_ind,\n                                inicio='02/11/2017 18:10:00',\n                                final='05/11/2017 14:10:00',\n                                dia_col='DateGMT',\n                                hora_col='TimeGMT',\n                                formato=\"%d/%m/%Y %H:%M:%S\")\n\nNext, I create a new column named tStamp and transformed it to the corresponding class.\n\nGPS_ind$tStamp<-paste(GPS_ind$DateGMT,GPS_ind$TimeGMT)\nGPS_ind$tStamp <- as.POSIXct(strptime(GPS_ind$tStamp,\"%d/%m/%Y %H:%M:%S\"),\"GMT\")\nclass(GPS_ind$tStamp)\n\nCheck that you have the right class for your columns.\n\nGPS_ind$lon<-as.numeric(GPS_ind$Longitude)\nGPS_ind$lat<-as.numeric(GPS_ind$Latitude)\nGPS_ind$id <- as.factor(GPS_ind$IDs)\n\nThen I select only columns that will be important in the analyses.\n\nlibrary(tidyverse)\n\n\nData<-GPS_ind%>%\n  select('id','tStamp','lon','lat')\nhead(Data)"
  },
  {
    "objectID": "blog/2021-11-25-embc/embc.html#check-delimiters",
    "href": "blog/2021-11-25-embc/embc.html#check-delimiters",
    "title": "EMbC",
    "section": "Check delimiters",
    "text": "Check delimiters\n\nMean and sd\nIn the package EMbC, the function stts offers a compact view of the parameter set.\n\nLL stands for Low velocity Low turn\n\nLH stands for Low velocity High turn\n\nHL stands for High velocity Low turn\n\nHH stands for High velocity High turn\n\nkn is the marginal distribution of the cluster in absolute and percentage values\n\nstts(Data_bc)\n\n\n\nMins and Maxs\nYou can also check the mimimum and maximum velocity and radians (turning angle).\n\nX1.min is the minimum velocity\n\nX2.min is the minimum turning angle\n\nX1.max is the maximum velocity\n\nX2.max is the maximum turning angle\n\n\nData_bc@R\n\nHere is important that you check that these values make sense. Turning angle should be between 0 and 3.14. Velocity varies according to your species.\nFor boobies this information can be translated to:\n\nLL for Resting\n\nLH for Intense foraging\n\nHL for Travelling\n\nHH for Relocating\n\nYou can also compare your results with Table 2 in Mendez et al.¬†2017, or in methods from Lerma et al.¬†2020\n\n\nGraphically\nTo see this information graphically, you can use the function sctr from the package EMbC.\n\nLL - Resting - in orange\n\nLH - Intense foraging - in red\n\nHL - Travelling - in light blue\n\nHH - Relocating - in dark blue\n\n\nsctr(Data_bc)\n\nTo see how the track looks according to the classification you can use the view function from the package EMbC.\n\nEMbC::view(Data_bc)"
  },
  {
    "objectID": "blog/2021-11-25-embc/embc.html#export-delimiters",
    "href": "blog/2021-11-25-embc/embc.html#export-delimiters",
    "title": "EMbC",
    "section": "Export delimiters",
    "text": "Export delimiters\nTo export the delimiters you can extract information into a data frame and rename the columns.\n\nClass_bc<-as.data.frame(Data_bc@R)\nnames(Class_bc)<-c('velocity.min','radian.min','velocity.max','radian.max')\n\nOriginally, the values of velocity are in m/s, therefore you can convert them to km/h to compare with the literature more easily.\n\nClass_bc$velomin_km<-Class_bc$velocity.min*3.6\nClass_bc$velomax_km<-Class_bc$velocity.max*3.6\n\nYou can use the function write_csv to export the delimiters.\nIn the example below, I use the function here and define the folder where I want the file to be.\n\nlibrary(here)\nwrite_csv(\n  Class_bc,\n  file=paste0(here::here(),\"/blog/2021-11-25-embc\",'/Behavioural_delimiters.csv'))"
  },
  {
    "objectID": "blog/2021-11-25-embc/embc.html#behaviors",
    "href": "blog/2021-11-25-embc/embc.html#behaviors",
    "title": "EMbC",
    "section": "Behaviors",
    "text": "Behaviors\nYou can add the information of velocity and turning angle into you GPS data.\n\nData$Beha<-Data_bc@A\n\nIt returns numbers which correspond to:\n\n1 - LL - Resting\n\n2 - LH - Intense foraging\n\n3 - HL - Travelling\n\n4 - HH - Relocating\n\n5 - Unknown\n\nIf you want to add a column explaining what this numbers mean you can use the following functions.\n\nlibrary(dplyr)\n\n\nData<-mutate(Data, Beha_class = ifelse(Data$Beha == \"1\", \"LL\",\n                                        ifelse(Data$Beha == \"2\", \"LH\",\n                                               ifelse(Data$Beha == \"3\", 'HH',\n                                                      ifelse(Data$Beha == \"4\", \"HL\", \n                                                             \"Unknown\")))))\n\nor\n\nData<-mutate(Data, Behaviour = ifelse(Data$Beha == \"1\", \"Resting\",\n                                        ifelse(Data$Beha == \"2\", \"Intense foraging\",\n                                               ifelse(Data$Beha == \"3\", 'Travelling',\n                                                      ifelse(Data$Beha == \"4\", \"Relocating\", \n                                                             \"Unknown\")))))"
  },
  {
    "objectID": "blog/2021-11-25-embc/embc.html#velocity",
    "href": "blog/2021-11-25-embc/embc.html#velocity",
    "title": "EMbC",
    "section": "Velocity",
    "text": "Velocity\nYou can add the velocity in a column of your GPS data frame.\n\nhead(Data_bc@X)\n\nVelocity is in the first column, therefore we use the [,1]. Also, to transform it to km/h multiply per 3.6.\n\nData$Velocity_ms<-Data_bc@X[,1]\nData$Velocity_kmh<-Data$Velocity_ms*3.6"
  },
  {
    "objectID": "blog/2021-11-25-embc/embc.html#heading-direction",
    "href": "blog/2021-11-25-embc/embc.html#heading-direction",
    "title": "EMbC",
    "section": "Heading direction",
    "text": "Heading direction\nHeading direction is on the second column, therefore we use the [,2].\n\nData$HeadingDirection<-Data_bc@X[,2]"
  },
  {
    "objectID": "blog/2021-11-25-embc/embc.html#check",
    "href": "blog/2021-11-25-embc/embc.html#check",
    "title": "EMbC",
    "section": "Check",
    "text": "Check\nFinally you can check the range to coincide with your delimiters.\n\nData %>% \n  group_by(Behaviour) %>%\n  summarise(Velo_min=min(Velocity_kmh),\n            Velo_max=max(Velocity_kmh),\n            Angle_min=min(HeadingDirection),\n            Angle_max=max(HeadingDirection))"
  },
  {
    "objectID": "blog/2021-11-25-embc/embc.html#plot",
    "href": "blog/2021-11-25-embc/embc.html#plot",
    "title": "EMbC",
    "section": "Plot",
    "text": "Plot\nYou can plot the GPS tracking data according to their behaviours using the function ggplot\n\nggplot(data = Data, \n           aes(x=lon, y = lat))+\n  geom_point(aes(colour = Behaviour))+\n  theme_bw()+\n  theme(legend.position = \"bottom\") +\n   labs(x = \"Longitude\", y=\"Latitude\")+\n  ggtitle('Fig. Tracks')"
  },
  {
    "objectID": "blog/2022-01-21-sharedareas/sharedareas.html",
    "href": "blog/2022-01-21-sharedareas/sharedareas.html",
    "title": "Shared Areas",
    "section": "",
    "text": "Here, some steps for:\n\nGenerating kernel polygons\nCalculating the intersection between two polygons\nPlotting polygons and their intersection\nCreating a table with the shared areas between two polygons"
  },
  {
    "objectID": "blog/2022-01-21-sharedareas/sharedareas.html#recommended-literature",
    "href": "blog/2022-01-21-sharedareas/sharedareas.html#recommended-literature",
    "title": "Shared Areas",
    "section": "Recommended literature",
    "text": "Recommended literature\n\nGeocomputation in R\nShared areas formula by Hedd et al.¬†2018 and McFarlane Tranquila et al.¬†2013"
  },
  {
    "objectID": "blog/2022-02-24-timeoverlaps/timeoverlaps.html",
    "href": "blog/2022-02-24-timeoverlaps/timeoverlaps.html",
    "title": "Time overlaps",
    "section": "",
    "text": "This post is about how to find overlapping times between your tracked individuals.  This might help you to:  - Identify periods where you have gaps for each individual, or  - To select which periods are comparable among individuals that might have been tracked on different periods"
  },
  {
    "objectID": "blog/2022-02-24-timeoverlaps/timeoverlaps.html#modify-legend",
    "href": "blog/2022-02-24-timeoverlaps/timeoverlaps.html#modify-legend",
    "title": "Time overlaps",
    "section": "Modify legend",
    "text": "Modify legend\nBecause is a ggplot, many things can be further customized.\nSuch as the legends\nHere, I remove the legend from the side (legend.position=‚Äònone‚Äô), modify the legend in the x axis to ‚Äòindividuals‚Äô, and change the angle of the x axis to 60 degrees.\n\nPlot_tracking+\n    theme(legend.position='none')+\n    labs(x = \"\", y = \"Individuals\") +\n        theme(axis.text.x=element_text(angle=60, hjust=1))+\n    theme(plot.title = element_text(size = 10, face = \"bold\"))"
  },
  {
    "objectID": "blog/2022-02-24-timeoverlaps/timeoverlaps.html#change-breaks",
    "href": "blog/2022-02-24-timeoverlaps/timeoverlaps.html#change-breaks",
    "title": "Time overlaps",
    "section": "Change breaks",
    "text": "Change breaks\nYou can also select how detailed the x axis legend should be and how often you want the breaks.\nFor one day breaks:\n\nPlot_tracking + scale_x_datetime(date_labels = \"%d %b %Y\",date_breaks = \"1 day\")\n\nFor one week breaks:\n\nPlot_tracking + scale_x_datetime(date_labels = \"%d %b %Y\",date_breaks = \"1 week\")\n\nFor one month breaks:\n\nPlot_tracking + scale_x_datetime(date_labels = \"%d %b %Y\",date_breaks = \"1 month\")\n\nIt doesnt show, because all were in the same month, but it might be useful for you to know this argument."
  },
  {
    "objectID": "blog/2022-02-24-timeoverlaps/timeoverlaps.html#add-lines",
    "href": "blog/2022-02-24-timeoverlaps/timeoverlaps.html#add-lines",
    "title": "Time overlaps",
    "section": "Add lines",
    "text": "Add lines\nYou can also mark separations between periods using a line.\nTo do so, first you have to make the period where you want to make the line as POSIXct\n\nPA<-as.POSIXct(strptime(\"2017-11-07 00:00:00\", \"%Y-%m-%d %H:%M:%S\"),tz = \"GMT\")\n\nThen you add the line to the ggplot using the function geom_vline (v from vertical line)  Use the period you have interest on getting the line as xintercept, and  The linetypes options can be seen here. The color depends on your preference, here I use red to make it easy to see at first glance.\n\nPlot_tracking+\n  geom_vline(xintercept=PA,\n                linetype=4, colour=\"red\")"
  },
  {
    "objectID": "blog/2022-02-24-timeoverlaps/timeoverlaps.html#add-rectangle",
    "href": "blog/2022-02-24-timeoverlaps/timeoverlaps.html#add-rectangle",
    "title": "Time overlaps",
    "section": "Add rectangle",
    "text": "Add rectangle\nNow if you want to add a rectangle, there are many option but I prefer to use annotation\nFirst I create an object with the timestamps of where I want the rectangle to begging and end.\n\nPA<-as.POSIXct(strptime(\"2017-11-01 00:00:00\", \"%Y-%m-%d %H:%M:%S\"),tz = \"GMT\")\nPB<-as.POSIXct(strptime(\"2017-11-07 00:00:00\", \"%Y-%m-%d %H:%M:%S\"),tz = \"GMT\")\n\nThen I add it to the plot  The xmin is the time where the rectangle will start, and the xmax where it would end.  Because I want the rectangle to cover the area I used -Inf and Inf.  The color is in fill, and the alpha is to have some transparency (the lower the value the more transparent will be, and the values go from 0 to 1).\n\nPlot_tracking + annotate(\"rect\",\n                         xmin = PA, xmax = PB, \n                         ymin = -Inf, ymax = Inf,  \n                         fill = \"blue\", alpha=0.1)"
  },
  {
    "objectID": "blog/2022-03-22-interpolation/interpolation.html",
    "href": "blog/2022-03-22-interpolation/interpolation.html",
    "title": "Interpolation",
    "section": "",
    "text": "Interpolation is a type of estimation, a method of constructing (or finding) new data ponts based on the range of a discrete set of known data points (source: wikipedia)\nThis post is about:  - How to prepare your data and use the function interpolate from the package sula for interpolating your tracking data \nInterpolating your data might help you to:  - Fill gaps on your tracking data, and/or  - To make comparable trips when individuals were tracked at different intervals  ‚Ä¶ read more at the end of this page.\n‚ö†Ô∏èHowever, while interpolating you should be very cautious, because you are creating locations where the bird might have not been.\nThis post step by step:\n1. Load data\n2. Identify nest location / or central location\n3. Classify if the animal was inside the central location or outside\n4. Count the number of trips\n5. Interpolate only when the animal was on a trip\nYou can also just go directly to : interpolate"
  },
  {
    "objectID": "blog/2022-03-22-interpolation/interpolation.html#interpolate_trips",
    "href": "blog/2022-03-22-interpolation/interpolation.html#interpolate_trips",
    "title": "Interpolation",
    "section": "interpolate_trips",
    "text": "interpolate_trips\nOnce the data frame contains columns with Longitude, Latitude, and trip_number, the trips can be interpolated.\nThe function interpole_trips from the package sula helps you to interpolate the locations based on an interval. In the examples below 900 secs = 15 minutes and 60 sec = 1 minute\nBecause you might have different column names, this function has a lot of arguments, but basically you just need to replace the name of your data frame, the interval you are interested to do the interpolation, the column names, and the format your date and time is presented.\n\nID01_interpolated15m<-interpolate_trips(GPS_data=ID01_onlytrips,\n                                     interval='900 sec',\n                                     column_date='DateGMT',\n                                     column_time='TimeGMT',\n                                     column_trip='trip_number',\n                                     column_lat='Latitude',\n                                     column_lon='Longitude',\n                                     datetime_format<-\"%d/%m/%Y %H:%M:%S\")\n\n\nID01_interpolated1m<-interpolate_trips(GPS_data=ID01_onlytrips,\n                                     interval='60 sec',\n                                     column_date='DateGMT',\n                                     column_time='TimeGMT',\n                                     column_trip='trip_number',\n                                     column_lat='Latitude',\n                                     column_lon='Longitude',\n                                     datetime_format<-\"%d/%m/%Y %H:%M:%S\")"
  },
  {
    "objectID": "blog/2022-03-22-interpolation/interpolation.html#interpolate_all",
    "href": "blog/2022-03-22-interpolation/interpolation.html#interpolate_all",
    "title": "Interpolation",
    "section": "interpolate_all",
    "text": "interpolate_all\nIn case you want to interpolate a specific trip, or everything (including the central location), and you already have a datetime column in the correct format (so R can understand is date and time) there is also the function interpolate in the package sula that interpolates all the locations.\nFor example, to interpolate a specific trip, subset the trip you are interested in interpolating.\n\nGPS01_trip5<-GPS_preparado %>%\n  filter(IDs=='GPS01')%>%\n  filter(trip_number=='trip_5')\n\nUse the function interpolate. Here I select the dataframe, the interval ofinterest, and the name of the columns that will be included in the interpolation.\n\nGPS01_trip1_interpolated<-interpolate(GPS_data = GPS01_trip5,\n                                      interval='10 sec',\n                                      column_datetime = 'dia_hora',\n                                      column_lat = 'Latitude',\n                                      column_lon = 'Longitude')"
  },
  {
    "objectID": "blog/2022-04-07-land-or-not/land-or-not.html",
    "href": "blog/2022-04-07-land-or-not/land-or-not.html",
    "title": "Habitat use",
    "section": "",
    "text": "This post is about how to classify locations on your tracking data based on an polygon with geographical information.\nThis is useful for example when you want to know:\n- If the animal is using a specific habitats, and\n- To calculate the percentage of use of a specific habitat\nSee examples on the recommended literature at the bottom of this post.\nIn this post we will classify tracking locations as land vs not land."
  },
  {
    "objectID": "blog/2022-04-07-land-or-not/land-or-not.html#map",
    "href": "blog/2022-04-07-land-or-not/land-or-not.html#map",
    "title": "Habitat use",
    "section": "Map",
    "text": "Map\nPlotting the data will help to confirm if the classification is correct.\n\nclass(my_polygon)\n\n\nggplot()+\n  geom_sf(data=my_polygon, color='black',fill='grey')+\n  geom_point(data=my_locs, aes(x=Longitude,y=Latitude,color=landornot))+\n  scale_color_manual(values=c('#9b2226','#005f73'))+\n  theme_bw()+\n  theme(legend.position = 'top')+\n  labs(x = \"Longitude\", y=\"Latitude\",color='')+\n  xlim(-110, -108)+\n  ylim(-28.5, -26.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo customize your plot, you can change many arguments, for example to change the theme_bw here are other options.\nDo not forget to adjust your xlim and ylim to your coordinates."
  },
  {
    "objectID": "blog/2022-04-07-land-or-not/land-or-not.html#percentages-1",
    "href": "blog/2022-04-07-land-or-not/land-or-not.html#percentages-1",
    "title": "Habitat use",
    "section": "Percentages",
    "text": "Percentages\nYou can also plot the percentage of habitat use per individual.\nTo do this, preparing the information in a long format will make it easier to plot.\n\nHabitatuse_prop<-Habitatuse %>%\n  pivot_longer(c(prop_land,prop_notland),\n               names_to = \"habitat_use\",\n               values_to = \"prop_use\" )\n\n\nggplot(Habitatuse_prop, aes(fill=habitat_use, y=prop_use, x=IDs)) + \n  geom_bar(position=\"fill\", stat=\"identity\")+\n  scale_fill_manual(values=c('#9b2226','#005f73'))+\n  theme_bw()+\n  theme(legend.position = 'top')+\n  scale_y_continuous(expand = c(0,0))"
  },
  {
    "objectID": "blog/2022-05-23-speed/speed.html",
    "href": "blog/2022-05-23-speed/speed.html",
    "title": "Speed",
    "section": "",
    "text": "Intro\nThis post is about how to calculate the speed between points.\nThis is useful for example when you want to:\n- Classify behavioral states of the individuals\n- Clean errors in locations\nSee examples on the literature at the bottom of this post.\nIn this post we will calculate distance between points, then the time between those points, and finally the speed.\n\n\nData üìñ\nTo do this exercise, load data from the package ‚Äòsula‚Äô.  For accessing the data, you need to have the package installed.\nTo install:\n\n#devtools::install_github(\"MiriamLL/sula\")\n\n\nlibrary(sula)\n\nThe data is from 10 tracked individuals.\n\nmy_locs<-(GPS_raw)\n\nSelect one individual for the exercise.\n\nlibrary(tidyverse)\n\n\nID01<-my_locs %>%\n  filter(IDs=='GPS01')\n\n\n\nDistance üìè\nLets select the columns of interest\n\nID01_coords<- ID01[,c('Longitude','Latitude')]\n\nConvert the data frame into a spatial object\n\nID01_spatial <- sp::SpatialPointsDataFrame(coords = ID01_coords, data = ID01)\n\nUse the corresponding CRS (Coordinate Reference System).\nNote that the CRS might change according to your study area.\n\nsp::proj4string(ID01_spatial)= sp::CRS(\"+init=epsg:4326\")\n\nUsing the function distm from the package geosphere to calculate the distance between points.\n\nID01_distance<-sapply(2:nrow(ID01_spatial),\n                             function(i){geosphere::distm(ID01_spatial[i-1,], ID01_spatial[i,])})\n\nTo add this information to your original data frame:\n\nID01_distance<-c(NA,ID01_distance)\n\nTo transform it to kilometers:\n\nID01$dist_km<-ID01_distance/1000\n\n\n\nTime ‚è∞\nLets select the columns of interest\n\nTimes<-paste(ID01$DateGMT,ID01$TimeGMT)\n\nTransform to the corresponding time formart\n\nTimes<-as.POSIXct(strptime(Times,\"%d/%m/%Y %H:%M:%S\"),\"GMT\")\n\n‚úãüèΩ Make sure it did not return NAs, otherwise check the format you used.\nIn this example, we will create a new column with the time using the function lag.\n\nLag<-lag(Times)\n\nThen, we will include a column with the original time (in time format) and the lag as another column on the original data frame.\n\nID01$Time1<-Times\nID01$Time2<-Lag\n\nNow, using the function difftime, we can calculate the time difference between those columns.\nIn units you can select ‚Äúsecs‚Äù, ‚Äúmins‚Äù, ‚Äúhours‚Äù,‚Äúdays‚Äù, ‚Äúweeks‚Äù.\n\nID01$time_dif<-as.numeric(difftime(ID01$Time1,ID01$Time2, units=\"mins\"))\n\nYou can also transform it to hours, with basic conversion.\n\nID01$time_hr<-as.numeric(ID01$time_dif/60)\n\n\n\nSpeed ü•è\nAs simple as speed = distance √∑ time\n\nID01$speed<-ID01$dist_km/ID01$time_hr\n\n\n\nPlots\nTo visualize the speed from the animal you can also create plots.\n\nggplot(ID01, aes(x=speed)) + \n  geom_density()+\n  theme_minimal()+\n  xlab('Speed (km/hr)')\n\nAlso, you can modify the plots according to the units you want to use. Here in m/s.\n\nggplot(ID01, aes(x=speed*0.277778)) + \n  geom_density(color=\"darkblue\", fill=\"lightblue\")+\n  theme_minimal()+\n  xlab('Speed (m/s)')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFurther reading üë©üèΩ‚Äçüè´\n\nSpeed Wikipedia definition\nConverters Speed-converter\nSome papers that use speed for different pourposes:\n\nRaya Rey et al.¬†2010 ‚Äú‚Ä¶we identified three phases based on sinuosity and speed of the trajectory‚Ä¶‚Äù\nNourani et al.¬†2022 ‚Äú‚Ä¶all data were filtered by speed to ensure that the position information represented period of flight‚Ä¶‚Äú\nI hope this helped you!"
  },
  {
    "objectID": "blog/2022-06-30-time-formats/time-formats.html",
    "href": "blog/2022-06-30-time-formats/time-formats.html",
    "title": "Time formats",
    "section": "",
    "text": "This post is about how to convert date and time to a format that R can understand it. \nFor example if you wrote the date and time during fieldwork in a notebook, and then wrote it down in a spreadsheet at your computer. When you load your this spreadsheet into R, very often R would think that your date and time is text. Therefore, you need to change the ‚Äòclass‚Äô of the column where you have date and time.\nIt is important to change the ‚Äòclass‚Äô of your column, so you can:\n- Correct the time zone  - Calculate duration of events (for example foraging trip duration) - Count days (for example Julian days) - Identify night and day periods ‚Ä¶ and many many more\nIn this post we will transform the class of our column date and time from character or other class, into POSTIXct. Additionally, we will change the time zone."
  },
  {
    "objectID": "blog/2022-06-30-time-formats/time-formats.html#transform-the-column-to-posixct",
    "href": "blog/2022-06-30-time-formats/time-formats.html#transform-the-column-to-posixct",
    "title": "Time formats",
    "section": "Transform the column to POSIXct",
    "text": "Transform the column to POSIXct\nPOSIX comes from Portable Operating System Interface and the X from UNIX.  There are two subclasses ct from calendar time and lt from local time. See R news. Calendar time being the number of seconds since the beginning of 1970.\n To create our column with date and time, lets merge the column DateGMT and TimeGMT from our data frame into one column DateTime.\n\nGPS_raw$DateTime<-paste(GPS_raw$DateGMT,GPS_raw$TimeGMT)\n\nThen convert it to POSIXct\n\nGPS_raw$DateTime<-as.POSIXct(strptime(GPS_raw$DateTime, format = \"%d/%m/%Y %H:%M:%S\"))\n\nArguments used:\nstrptime is a function to convert characters to time objects, where str stands for string, p from parse, and time is self explanatory.\nThen we provide the information of the format we were using, be specially careful with the format of your date and time.\nFor the example, I used %d/%m/%Y %H:%M:%S\nDAY\n%d - is used for day and goes from 0 to 31 %a - is used for the day of the week using the first three letters of the name %A - is used for the day of the week using the full name  MONTH\n%m - is used for month it goes from 0 to 12 %b - is used for the name of the month using the first three letters of the name %B - is used for the name of the month using the full name  YEAR\n%y - is used for year using two digits %Y - is used for year using four difits \nHOURS\n%H - is used for hours and goes from 0 to 24 MINUTES\n%M is used for minutes and goes from 0 to 60 SECONDS\n%S is used for seconds and goes from 0 to 60\nIt is also important to note if you are using slash (/), dash (-) or any other, and do not forget the colon (:) when separating the times\nNote for excel-users: if you open your file first in excel, excel tries to identify the class, and might have transform the column. Therefore you might need to use one of the examples from stackoverflow\n\nCheck\nMany struggles come from the format. If the format you are giving doesnt corresponds to the format of your column, it would generate you NAs.\nTherefore, I recommend to create a column to make the trials on the format and to always check that you have the correct transformations.\nHere is an example for checking:\n\nrange(GPS_raw$DateTime)\n\nNote that in this example it returns the word CET.\nThis is because I am in the Central European Time.\nThis might be correct and all good, but it is useful to know that you can transform it to you time zone."
  },
  {
    "objectID": "blog/2022-06-30-time-formats/time-formats.html#identify-your-time-zone",
    "href": "blog/2022-06-30-time-formats/time-formats.html#identify-your-time-zone",
    "title": "Time formats",
    "section": "Identify your time zone üó∫Ô∏è",
    "text": "Identify your time zone üó∫Ô∏è\nAccording to where your study was made, you might need to change the time to your time zone tz\nThere are many ways to identify your tz:\n\nYou can click on your area on this map\nYou can check the list of name in R using the code OlsonNames()\nYou can check lists like those of wikipedia\n\nIn case you are here because you are interested in analyzing tracking data, note that it‚Äôs common that the GPS record data in GMT+0.\n\n\n\n\nlubridate\nOne option to change your date and time to your time zone is using the package lubridate\n\nlibrary(lubridate)\n\nExample with the data.\n\nGPS_tz<-GPS_raw\n\nMy original tz:\n\nGPS_tz$CET<-ymd_hms(GPS_tz$DateTime, tz = \"Europe/Amsterdam\")\n\nMy goal tz:\n\nGPS_tz$UTC_4<- with_tz(GPS_tz$CET,tzone = \"America/La_Paz\")\n\n\n\nManually\nIf you know the time difference between the recording and the region where you are, you can also calculate it manually.\nFor example:\n\nGPS_tz$five_hours_difference <- GPS_tz$CET - 3600*5\n\nThats it!\nHopefully this would help you.\n\n\nRecommendations\nBe very careful with the format and your time zone.\nI would recommend that you always create an extra column in your data frame to make the transformations, not your original column because if it returns NAs you will have to load the data frame over and over.\nIt takes time to get use to this transformations and there are many different ways to transform times and date, so if you are struggling, you are not the only one, just give it some time."
  },
  {
    "objectID": "blog/2022-07-01-nestlocation/nestlocation.html",
    "href": "blog/2022-07-01-nestlocation/nestlocation.html",
    "title": "Locate nest",
    "section": "",
    "text": "This post is about how to identify the central location from an animal. \nFor example if you want to identify how far an animals moves, it is helpful to identify where the central location of the animal is to use it as a reference point.\nIn this post we will use different logic and/or functions to identify central locations for animals."
  },
  {
    "objectID": "blog/2022-07-01-nestlocation/nestlocation.html#night-time",
    "href": "blog/2022-07-01-nestlocation/nestlocation.html#night-time",
    "title": "Locate nest",
    "section": "Night time üåú",
    "text": "Night time üåú\n\nlibrary(tidyverse)\n\nTo use only locations of night, subset the hours for only night time.\nYou can do this by creating a column with the hour of the day.\n\nGPS_01$Hour <- substr(GPS_01$tStamp, 12, 13)\n\nNote that in the example, we use tStamp because is on the correct time zone, for more details click here)\nFor this area, the night time was considered to be between 6 am (6 h) and 8 pm (20 h).\nHere, a new column named Day_or_night to identify the time period will be created.\n\nGPS_01<-GPS_01 %>%\n mutate(\n    Day_or_night = case_when(\n      Hour > 6  |  Hour < 20 ~ \"day\",\n      TRUE  ~ \"night\"\n    )\n  )\n\nThen, filtered to only keep night recordings.\n\nGPS_01_night<- GPS_01 %>%\n  filter(Day_or_night == 'night')\n\n\nDefinition üë©üèΩ‚Äçüöí\nHeat mapping, from a GIS perspective, is a method of showing the geographic clustering of a phenomenon. Heat maps show locations of higher densities of geographic entities. Heat mapping is a way of geographically visualizing locations so that patterns of higher than average occurrence of things can emerge. To read more click here.\nA heatmap can thus help us to visualize the place where the animal spends most of its time. This would be very often the nest, for breeding animals.\nTo visualize the heatmap we can use functions from the package ggplot.\n\nlibrary(ggplot2)\n\nThe function geom_density_2d_filled will create a heat map on the area where most locations were occurring.\n\nggplot()+\n  geom_point(data = GPS_01_night, aes(x=Longitude, y = Latitude),\n             color='black',size = 0.8,alpha=0.4)+\n  geom_density_2d_filled(data = GPS_01_night, aes(x = Longitude, y = Latitude),alpha = 0.5)+ \n  theme_bw()+\n  theme(legend.position = 'none')\n\nYou can already see that there is a region that stands out as where most locations were recorded.\nBy adding the known-nest using geom_point (as a red-triangle, nest located using the function localizar_nido above), we can corroborate that this region is where the nest of the bird was.\n\nggplot()+\n  geom_point(data = GPS_01_night, aes(x=Longitude, y = Latitude),\n             color='black',size = 0.8,alpha=0.4)+\n  geom_density_2d_filled(data = GPS_01_night, aes(x = Longitude, y = Latitude),alpha = 0.5)+ \n  geom_point(data=nest, aes(x=Longitude, y=Latitude),color='red',shape=17, size=5)+\n  theme_bw()+\n  theme(legend.position = 'none')\n\nSo, now we know that there is where the animal spend most of the night.\nFor the next step, we will try to see the coordinates by using an interactive plot of the area that was most used by the animal.\n\n\nInteractive plot\nWith ggplotly() by plotly, we can convert ggplot2 figures into interactive ones.\n\nlibrary(plotly)\n\nThe advantage of using plotly is that it allows zooming in and out of the area and see the place where most of the locations occurred.\nBy placing the cursor on top of the area, you can see the longitude and latitude.\n\nggplotly(ggplot(GPS_01_night, aes(x=Longitude, y = Latitude))+\n  stat_density_2d(aes(fill = ..density..), geom = \"raster\", contour = FALSE) +\n  scale_fill_continuous(type = \"viridis\") +\n  geom_point(data = GPS_01_night, aes(x=Longitude, y = Latitude),\n             color='black',size = 0.5,alpha=0.4)+\n  theme_bw())\n\nWith this information, we can note down the locations most used.\nHowever, since the GPS has some errors, you will notice that there is not an specific point.\nTo solve this we can calculate the centroid location, as in the example below."
  },
  {
    "objectID": "blog/2022-07-01-nestlocation/nestlocation.html#centroid",
    "href": "blog/2022-07-01-nestlocation/nestlocation.html#centroid",
    "title": "Locate nest",
    "section": "Centroid üéØ",
    "text": "Centroid üéØ\nNow that we have only the locations inside the most use areas, we can calculate the centroid location.\n\nrequire(sp)\nrequire(rgeos)\n\nFirst, convert the night time to SpatialPoints\n\nGPS_01_sp= SpatialPoints(coords = GPS_01_high[, c('Longitude','Latitude')], \n                   proj4string = CRS(\"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\") )\n\nclass(GPS_01_sp)\n\nThen, use the function gCentroid to obtain the centroid location.\n\nGPS_01_centroids = gCentroid(GPS_01_sp,byid=FALSE)\n\nObtain coordinates from the centroid location.\n\ncentroid<-data.frame(Longitude=GPS_01_centroids@coords[,1],\n           Latitude=GPS_01_centroids@coords[,2])\ncentroid\n\nCheck if the centroid location fits to the area of the nest.\n\nggplot()+\n  geom_point(data = GPS_01_night, aes(x=Longitude, y = Latitude),\n             color='black',size = 0.8,alpha=0.4)+\n  geom_density_2d_filled(data = GPS_01_night, aes(x = Longitude, y = Latitude),alpha = 0.5)+ \n  geom_point(data=centroid, aes(x=Longitude, y=Latitude),color='red',shape=17, size=5)+\n  theme_bw()+\n  theme(legend.position = 'none')\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnd thats it, now you should have the centroid location of this individual.\nYou can do this per individual, or create a function to run automatically to each one of your individuals.\nI hope this might help you."
  },
  {
    "objectID": "blog/2022-08-17-count-days/count-days.html",
    "href": "blog/2022-08-17-count-days/count-days.html",
    "title": "Count days",
    "section": "",
    "text": "Intro\nThis post is about how:  - Add a column counting the days (day 1, 2‚Ä¶). - Check differences in parameters as days pass.  - Add a column with julian day (days from the first day of the calendar). \nExamples \nThis post is useful to study:\n\nIn species that fed their offspring. Trips might be shorter when the parents need to mantain a constant feeding rate, but trips can be longer during the incubation period, and when offspring can be left unattended.\nSpecies that use resources that availability change over time. Trips might be shorter when the prey availability is at its peak, and trips might be longer when the prey availability is lower, as individuals expend more time to reach their energetic demands.\n\n\n\nData üìñ\nTo do this exercise, we will load data from the package ‚Äòsula‚Äô\nTo install:\n\n#devtools::install_github(\"MiriamLL/sula\")\n\n\nlibrary(sula)\n\nTo load data from from 1 tracked individual.\n\nGPS<-GPS_edited\n\nGet nest location.\n\nnest_loc<-localizar_nido(GPS_data = GPS,\n                          lat_col=\"Latitude\",\n                          lon_col=\"Longitude\")\n\nCalculate foraging trip parameters.\n\nForaging_trips<-calcular_tripparams(GPS_data = GPS,\n                              diahora_col = \"tStamp\",\n                              formato = \"%Y-%m-%d %H:%M:%S\",\n                              nest_loc=nest_loc,\n                              separador=\"trip_number\")\n\n\n\nCount days üßÆ\nIdeally, you will have a data frame with the date and time information.\nTo add the number of days, we select a column with information from date and time.\nFor the example we will use trip_start and extract the date.\n\nForaging_trips$date<-substr(Foraging_trips$trip_start, start = 1, stop = 10)\n\nNow we use this date as a factor and number it.\n\nForaging_trips$day_number<-as.numeric(as.factor(Foraging_trips$date))\n\nWe can also use this information to see the number of days the individual was tracked.\n\nlength(unique(Foraging_trips$day_number))\n\nLoad the package tidyverse.\n\nlibrary(tidyverse)\n\nSummarize the information per day.\n\nduration_per_day<-Foraging_trips%>%\n  group_by(day_number)%>%\n  summarise(duration_day=mean(duration_h))\n\nIn the plot, you can now see if there were differences in the trip durations among the days that the bird was tracked.\n\nggplot(duration_per_day, aes(x=day_number, y=duration_day)) +\n  geom_segment( aes(x=day_number, xend=day_number, y=0, yend=duration_day), color=\"grey\") +\n  geom_point( color=\"orange\", size=4) +\n  theme_classic() +\n  xlab('Days since begginnig of tracking')+\n  ylab('Mean duration (h)')+\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 3))\n\n\n\nJulian day üìÖ\nLoad package lubridate\n\nlibrary(lubridate)\n\nExtract the date using the function as.Date\n\nForaging_trips$julian_date <- as.Date(Foraging_trips$date, format=c(\"%Y-%m-%d\"))\n\nUse the argument %j to obtain the julian day.\n\nForaging_trips$julian <- as.numeric(format(Foraging_trips$julian_date, \"%j\"))\n\nThe bird was tagged between the day 306 and 309 of the calendar.\n\nrange(Foraging_trips$julian)\n\nSummarize the information per day.\n\nduration_per_julian<-Foraging_trips%>%\n  group_by(julian)%>%\n  summarise(duration_day=mean(duration_h))\n\nThe plot would be more informative for whole seasons, or breeding seasons.\n\nggplot(duration_per_julian, aes(x=julian, y=duration_day)) +\n  geom_segment( aes(x=julian, xend=julian, y=0, yend=duration_day), color=\"grey\") +\n  geom_point( color=\"orange\", size=4) +\n  theme_classic() +\n  xlab('Calendar day')+\n  ylab('Mean duration (h)')+\n  scale_y_continuous(expand = c(0, 0), limits = c(0, 3))+\n  scale_x_continuous(expand = c(0, 0), limits = c(0, 365))\n\n\n\n\n\n\n\n\n\n\n\n\n\nI hope this might help you.\n\n\nMore to read\n\nPistorious et al.¬†2015.\nLerma et al.¬†2020"
  },
  {
    "objectID": "blog/2022-09-13-hr-considerations/hr-considerations.html",
    "href": "blog/2022-09-13-hr-considerations/hr-considerations.html",
    "title": "Kernel UD considerations",
    "section": "",
    "text": "This post is to exemplify some considerations when calculating kernel density analyses.\nBefore start calculating kernel density analyses, its useful to consider some sources of error that might change your results.\nFor the exercises, test data is from masked boobies.  To access the data you have to install the package sula: devtools::install_github(‚ÄúMiriamLL/sula‚Äù)\n\n#devtools::install_github(\"MiriamLL/sula\")\nlibrary(sula)\nGPS_raw<-(GPS_raw)\n\nTo manipulate the data we will use functions from the package tidyverse\n\nlibrary(tidyverse)\n\nFor spatial manipulations we will use functions from the packages sp and sf\n\nlibrary(sp)\nlibrary(sf)\n\nFor creating the polygons of kernel density we will use the package adehabitathr\n\nlibrary(adehabitatHR)\n\n\n\nSome individuals might drive kernel density calculations in one or other direction as effect of different number of recordings (or days recorded) per individual.\n\n\nTo illustrate this, lets see the calculations using together one individual sampled for 1 day and other for 5 days\n\n\n\n\n\n\nID_1day<-GPS_raw %>%\n  filter(IDs=='GPS01') %>%\n  filter(DateGMT %in% c('02/11/2017'))\n\n\n\n\n\n\n\n\nID_5days<-GPS_raw %>%\n  filter(IDs=='GPS03')\n\n\n\n\n\nUnpaired<-rbind(ID_1day,ID_5days)\n\nTransform to spatial object.\n\nUnpaired<-as.data.frame(Unpaired)\ncoordinates(Unpaired) <- c(\"Longitude\", \"Latitude\")\nclass(Unpaired)\n\nCalculate kernelUD.\n\nUnpairedUD<-kernelUD(Unpaired[,3],h='href') \n\nObtain polygons.\n\nUnpairedUD95 <- getverticeshr(UnpairedUD, percent = 95, unout = c(\"m2\"))\nUnpairedUD50 <- getverticeshr(UnpairedUD, percent = 50, unout = c(\"m2\"))\n\nHere you can check on you polygons visually.\n\nUnpaired95<-st_as_sf(UnpairedUD95)\nUnpaired50<-st_as_sf(UnpairedUD50)\n\n\nggplot()+\n  geom_sf(data = Unpaired95,color='#006d77',fill = \"#006d77\",alpha=0.3,size=1)+\n  geom_sf(data = Unpaired50,color='#5f0f40',fill = \"#5f0f40\",alpha=0.3,size=1)+\n  labs(x = \"Longitude\", y=\"Latitude\")+\n  theme_bw()\n\n\n\n\n\nTo compare, lets now see the kernel density calculated with these same individuals but recorded at similar number of days (3 days)\n\nID_01<-GPS_raw %>%\n  filter(IDs=='GPS01') %>%\n  filter(DateGMT %in% c('02/11/2017','03/11/2017','04/11/2017','05/11/2017'))\n\n\nID_03<-GPS_raw %>%\n  filter(IDs=='GPS03') %>%\n  filter(DateGMT %in% c('02/11/2017','03/11/2017','04/11/2017','05/11/2017'))\n\n\nPaired<-rbind(ID_01,ID_03)\n\nTransform to spatial object.\n\nPaired<-as.data.frame(Paired)\ncoordinates(Paired) <- c(\"Longitude\", \"Latitude\")\nclass(Paired)\n\nCalculate kernelUD.\n\nPairedUD<-kernelUD(Paired[,3],h='href') \n\nObtain polygons.\n\nPairedUD95 <- getverticeshr(PairedUD, percent = 95, unout = c(\"m2\"))\nPairedUD50 <- getverticeshr(PairedUD, percent = 50, unout = c(\"m2\"))\n\nHere you can check on you polygons visually.\n\nPaired95<-st_as_sf(PairedUD95)\nPaired50<-st_as_sf(PairedUD50)\n\n\nggplot()+\n  geom_sf(data = Paired95,color='#006d77',fill = \"#006d77\",alpha=0.3,size=1)+\n  geom_sf(data = Paired50,color='#5f0f40',fill = \"#5f0f40\",alpha=0.3,size=1)+\n  labs(x = \"Longitude\", y=\"Latitude\")+\n  theme_bw()\n\nAs you can see the resulting areas would be different.\nTo solve this problem, you might want to make sure to have tracking data of similar number of days or recordings.\n\n\n\n\nDo you have similar recordings in time?\nIf some devices have gaps, or record at different intervals, you might underestimate or overestimate specific areas.\nFor this example, lets see one individuals\n\nGPS01<-GPS_raw %>%\n  filter(IDs=='GPS01')\n\n\n\nUsing the column of hours, lets extract all the recordings after 5 pm.\n\nGPS01$Hour <- as.numeric(substr(GPS01$TimeGMT, 1, 2))\nGaps<-GPS01 %>%\n  filter(Hour <= 17)\n\nTransform to spatial object.\n\nGaps<-as.data.frame(Gaps)\ncoordinates(Gaps) <- c(\"Longitude\", \"Latitude\")\n\nCalculate kernelUD.\n\nGapsUD<-kernelUD(Gaps[,3],h='href') \n\nObtain polygons.\n\nGapsUD95 <- getverticeshr(GapsUD, percent = 95, unout = c(\"m2\"))\nGapsUD50 <- getverticeshr(GapsUD, percent = 50, unout = c(\"m2\"))\n\nHere you can check on you polygons visually.\n\nGaps95<-st_as_sf(GapsUD95)\nGaps50<-st_as_sf(GapsUD50)\n\n\nggplot()+\n  geom_sf(data = Gaps95,color='#006d77',fill = \"#006d77\",alpha=0.3,size=1)+\n  geom_sf(data = Gaps50,color='#5f0f40',fill = \"#5f0f40\",alpha=0.3,size=1)+\n  labs(x = \"Longitude\", y=\"Latitude\")+\n  theme_bw()\n\n\n\n\nIn contrast, the kernel density calculations without gaps would give different results.\n\nComplete<-GPS_raw %>%\n  filter(IDs=='GPS01')\n\nTransform to spatial object.\n\nComplete<-as.data.frame(Complete)\ncoordinates(Complete) <- c(\"Longitude\", \"Latitude\")\n\nCalculate kernelUD.\n\nCompleteUD<-kernelUD(Complete[,3],h='href') \n\nObtain polygons.\n\nCompleteUD95 <- getverticeshr(CompleteUD, percent = 95, unout = c(\"m2\"))\nCompleteUD50 <- getverticeshr(CompleteUD, percent = 50, unout = c(\"m2\"))\n\nHere you can check on you polygons visually.\n\nComplete95<-st_as_sf(CompleteUD95)\nComplete50<-st_as_sf(CompleteUD50)\n\n\nggplot()+\n  geom_sf(data = Complete95,color='#006d77',fill = \"#006d77\",alpha=0.3,size=1)+\n  geom_sf(data = Complete50,color='#5f0f40',fill = \"#5f0f40\",alpha=0.3,size=1)+\n  labs(x = \"Longitude\", y=\"Latitude\")+\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo solve the problem with gaps, you can interpolate the data to fill the gaps and have similar intervals. However, caution should be taken if you have large gaps, it would create a line.\n\n\n\n\nDo you want to know the general areas that the animal used or just where it was feeding?\nIt depends on your question, but if you are interested in specific behaviours, for example feeding areas, the kernel density analyses might be bring very different results than when using all movement data.\n\n\nHere, we are using only areas where the animal was foraging.\nLoad data\n\nGPS_raw<-as.data.frame(GPS_raw)\nGPS01<-subset(GPS_raw,GPS_raw$IDs=='GPS01')\n\nUse an specific period\n\nGPS_bc<-recortar_periodo(GPS_data=GPS01,\n                                inicio='02/11/2017 18:10:00',\n                                final='05/11/2017 14:10:00',\n                                dia_col='DateGMT',\n                                hora_col='TimeGMT',\n                                formato=\"%d/%m/%Y %H:%M:%S\")\n\nConvert to the correct format\n\nGPS_bc$tStamp<-paste(GPS_bc$DateGMT,GPS_bc$TimeGMT)\nGPS_bc$tStamp <- as.POSIXct(strptime(GPS_bc$tStamp,\"%d/%m/%Y %H:%M:%S\"),\"GMT\")\nGPS_bc$lon<- as.numeric(GPS_bc$Longitude)\nGPS_bc$lat<- as.numeric(GPS_bc$Latitude)\nGPS_bc$id <- as.factor(GPS_bc$IDs)\n\nKeep only the important columns\n\nGPS_bc<-GPS_bc %>%\n  dplyr::select('id','tStamp','lon','lat')\n\nLoad the package\n\nlibrary(EMbC)\n\nRun the function\n\nBC_clustering<-EMbC::stbc(GPS_bc[2:4],info=-1) \n\nAdd the behavioral classifications\n\nGPS_bc$Behaviours<-(BC_clustering@A)\n\nRename it so you can understand what each behaviour means\n\nGPS_bc<-mutate(GPS_bc, BC = ifelse(GPS_bc$Behaviours == \"1\", \"Resting\",\n                                        ifelse(GPS_bc$Behaviours == \"2\", \"Intense foraging\",\n                                               ifelse(GPS_bc$Behaviours == \"3\", 'Travelling',\n                                                      ifelse(GPS_bc$Behaviours == \"4\", \"Relocating\", \n                                                             \"Unknown\")))))\n\nFilter to keep only foraging\n\nForaging<-GPS_bc %>%\n  filter(BC=='Intense foraging')\n\nTransform to spatial object\n\nForaging<-as.data.frame(Foraging)\ncoordinates(Foraging) <- c(\"lon\", \"lat\")\n\nCalculate kernelUD.\nNote Here the href is of 0.0048 which is giving the error of subscript out of bounds Lets then better calculate using other h value\n\n#ForagingUD<-kernelUD(Foraging[,3],h='href') \n#ForagingUD95 <- getverticeshr(ForagingUD, percent = 95, unout = c(\"m2\"))\n\nThe new h value is of 0.01\n\nForagingUD<-kernelUD(Foraging[,3],h=0.009) \nForagingUD\n\nObtain polygons.\n\nForagingUD95 <- getverticeshr(ForagingUD, percent = 95, unout = c(\"m2\"))\nForagingUD50 <- getverticeshr(ForagingUD, percent = 50, unout = c(\"m2\"))\n\nHere you can check on you polygons visually.\n\nForaging95<-st_as_sf(ForagingUD95)\nForaging50<-st_as_sf(ForagingUD50)\n\n\nggplot()+\n  geom_sf(data = Foraging95,color='#006d77',fill = \"#006d77\",alpha=0.3,size=1)+\n  geom_sf(data = Foraging50,color='#5f0f40',fill = \"#5f0f40\",alpha=0.3,size=1)+\n  labs(x = \"Longitude\", y=\"Latitude\")+\n  theme_bw()\n\n\n\n\nHere, we are using all the areas.\n\nGPS_bc<-GPS_bc %>%\n  dplyr::select('id','tStamp','lon','lat')\n\n\nBehas<-as.data.frame(GPS_bc)\ncoordinates(Behas) <- c(\"lon\", \"lat\")\n\nCalculate kernelUD.\n\nBehasUD<-kernelUD(Behas,h='href') \nBehasUD\n\nObtain polygons.\n\nBehasUD95 <- getverticeshr(BehasUD, percent = 95, unout = c(\"m2\"))\nBehasUD50 <- getverticeshr(BehasUD, percent = 50, unout = c(\"m2\"))\n\nHere you can check on you polygons visually.\n\nBehas95<-st_as_sf(BehasUD95)\nBehas50<-st_as_sf(BehasUD50)\n\n\nggplot()+\n  geom_sf(data = Behas95,color='#006d77',fill = \"#006d77\",alpha=0.3,size=1)+\n  geom_sf(data = Behas50,color='#5f0f40',fill = \"#5f0f40\",alpha=0.3,size=1)+\n  labs(x = \"Longitude\", y=\"Latitude\")+\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf you want to classify the behaviour, please check the post on EmBC"
  },
  {
    "objectID": "blog/2022-10-04-identify-gaps/identify-gaps.html",
    "href": "blog/2022-10-04-identify-gaps/identify-gaps.html",
    "title": "Identify gaps",
    "section": "",
    "text": "This post is to find and calculate gaps between points.\nFor the exercises, test data is from masked boobies.  To access the data you have to install the package sula: devtools::install_github(‚ÄúMiriamLL/sula‚Äù)\n\n#devtools::install_github(\"MiriamLL/sula\")\nlibrary(sula)\nGPS01<-(GPS01)\n\n\nlibrary(dplyr)\n\nIdentify column with time date data\n\nGPS01$dt <- as.POSIXct(strptime(GPS01$tStamp, \"%Y-%m-%d %H:%M:%S\"))\n\nCheck gaps in time between recordings\n\nGPS01$Gaps_time<-as.numeric(GPS01$dt - lag(GPS01$dt))\n\nClassify gaps\n\nGPS01 <- GPS01 %>%\n  mutate(Gaps_class = case_when(is.na(Gaps_time) ~ 'U',\n                                Gaps_time <= 300 ~ 'Small',\n                                TRUE ~ 'Large'))\n\nCheck gaps between locations\n\nrange(GPS01$Gaps_time,na.rm=TRUE)"
  },
  {
    "objectID": "blog/2022-10-04-identify-gaps/identify-gaps.html#when",
    "href": "blog/2022-10-04-identify-gaps/identify-gaps.html#when",
    "title": "Identify gaps",
    "section": "When?",
    "text": "When?\nWhen did the gap occurred?\nThe result show the latest record, therefore the gap occurred between the previous recording and this one\n\nLarge_gaps<-GPS01_wGap %>%\n  filter(Gaps_class=='Large')\nLarge_gaps\n\nTo see the previous line to see when the gap started you can select this and the previous row\n\nall_rows<-c(Large_gaps$seq,Large_gaps$seq-1)\n\n\nGPS01_wGap %>%\n  filter(seq %in% all_rows)"
  },
  {
    "objectID": "blog/2022-10-04-identify-gaps/identify-gaps.html#how-much",
    "href": "blog/2022-10-04-identify-gaps/identify-gaps.html#how-much",
    "title": "Identify gaps",
    "section": "How much?",
    "text": "How much?\nTo calculate the duration of the gap in hours\n\nGPS01_wGap$Gap_hrs<-GPS01_wGap$Gaps_time/60\n\n\nrange(GPS01_wGap$Gap_hrs,na.rm=TRUE)"
  },
  {
    "objectID": "blog/2022-10-04-identify-gaps/identify-gaps.html#where",
    "href": "blog/2022-10-04-identify-gaps/identify-gaps.html#where",
    "title": "Identify gaps",
    "section": "Where?",
    "text": "Where?\nWhere did the gap occurred?\n\nlibrary(ggplot2)\n\nEach circle is the locations, the size of the circle is the gap between locations\n\nggplot()+\n  geom_point(data = GPS01_wGap,\n            aes(x=Longitude,y = Latitude,size = Gap_hrs),color='red')+\n  geom_path(data = GPS01_wGap,\n            aes(x=Longitude,y = Latitude),color='blue',size = 0.5)+\n  theme_bw()\n\n\nlibrary(plotly)\n\n\nggplotly(ggplot()+\n  geom_point(data = GPS01_wGap,\n            aes(x=Longitude,y = Latitude,size = Gap_hrs, color=Hour))+\n  geom_path(data = GPS01_wGap,\n            aes(x=Longitude,y = Latitude),color='blue',size = 0.5)+\n  theme_bw())"
  },
  {
    "objectID": "blog/2022-11-20-mastodon/mastodon.html",
    "href": "blog/2022-11-20-mastodon/mastodon.html",
    "title": "Mastodon",
    "section": "",
    "text": "Este post es para compartir los pasos que segu√≠ para crear mi cuenta de mastodon."
  },
  {
    "objectID": "blog/2022-11-20-mastodon/mastodon.html#server",
    "href": "blog/2022-11-20-mastodon/mastodon.html#server",
    "title": "Mastodon",
    "section": "Server",
    "text": "Server\nElegir un servidor puede o no ser critico. Como a mi me interesan temas de biolog√≠a eleg√≠ ecoevo.social. Pero al parecer muchas personas con inter√©s en R se fueron a diferentes servidores, como fosstodon. El servidor al final da lo mismo porque puedes seguir a todas las personas desde cualquier servidor. Adem√°s los servidores se ven muy parecidos. Al parecer hay un problema con el conteo de seguidores, pero veremos como evoluciona la plataforma. Si elegir servidor te abruma, te recomiendo elegir uno de los servidores a donde migraron las personas que tal vez segu√≠as en twitter."
  },
  {
    "objectID": "blog/2022-11-20-mastodon/mastodon.html#ecoevo.social",
    "href": "blog/2022-11-20-mastodon/mastodon.html#ecoevo.social",
    "title": "Mastodon",
    "section": "ecoevo.social",
    "text": "ecoevo.social\nEcoevo definitivamente eran mi servidor. As√≠ que le di click en create account (del lado derecho, debajo del sign in).\n\n\n\nMe sali√≥ un aviso de reglas en la plataforma y al final de la pagina le di al bot√≥n de accept.\n\n\n\nAhora si todo listo para registrarme!\n\n\n\nMe lleg√≥ un correo y me hice un perfil."
  },
  {
    "objectID": "blog/2022-11-20-mastodon/mastodon.html#pagina-web",
    "href": "blog/2022-11-20-mastodon/mastodon.html#pagina-web",
    "title": "Mastodon",
    "section": "Pagina web",
    "text": "Pagina web\nPara usar mastodon desde mi computador, me voy al enlace https://ecoevo.social/explore y le doy click en log in\n\n\n\nAhora ya puedo empezar a tootear (escribiendo en el cuadro blanco de la izquierda y dandole al bot√≥n de publicar)"
  },
  {
    "objectID": "blog/2022-11-20-mastodon/mastodon.html#android",
    "href": "blog/2022-11-20-mastodon/mastodon.html#android",
    "title": "Mastodon",
    "section": "Android",
    "text": "Android\nSer√© sincera, mi primer encuentro con mastodon no fue f√°cil. Cuando quise descargar la app en mi celular no estaba disponible.\n\n\n\nTambi√©n intente varias de las aplicaciones recomendadas por la p√°gina.\n\n\n\nEl 80% del tiempo en el que uso redes sociales es mientras estoy en el transporte publico‚Ä¶ por lo que tener mastodon en mi celular es la mejor opci√≥n para mi.\nTermine instalando **tooot*\n\n\n\nLo primero que me pidio la app fue ingresar el servidor donde me registre. Para mi caso fue ecoevo.social\n\n\n\nUna vez ingresado el servidor, lo siguiente es aceptar las reglas de uso.\n\n\n\nY empezar a tootear."
  },
  {
    "objectID": "blog/2022-11-20-mastodon/mastodon.html#ios",
    "href": "blog/2022-11-20-mastodon/mastodon.html#ios",
    "title": "Mastodon",
    "section": "iOS",
    "text": "iOS\nMi otra opci√≥n fue usar iOS.\nEn iOS no tuve ning√∫n problema para descargar la app.\n\n\n\nAs√≠ es la app una vez que la abres.\n\n\n\nPara acceder a tu perfil, primero hay que poner exactamente el nombre del servidor que elegiste.\n\n\n\nUna vez elegido el servidor, puedes acceder a tu cuenta usando tu correo electronico y contrase√±a.\n\n\n\nY listo para tootear"
  },
  {
    "objectID": "blog/2022-11-20-mastodon/mastodon.html#primeras-impresiones",
    "href": "blog/2022-11-20-mastodon/mastodon.html#primeras-impresiones",
    "title": "Mastodon",
    "section": "Primeras impresiones",
    "text": "Primeras impresiones\nHasta ahora lo que m√°s me ha gusto es el contenido dirigido que tiene cada servidor. Tambi√©n agradezco mucho no tener que ver anuncios, ni publicaciones que ‚Äúpodr√≠an gustarme‚Äù. No obstante, dedique mucho tiempo a buscar a las personas que segu√≠a en twitter, aunque afortunadamente muchos pusieron su direcci√≥n de mastodon en su nombre de perfil. Solo falta que entren m√°s personas. Mientras tanto creo que mantendr√© ambas plataformas (twitter y mastodon) para mantenerme actualizada con los temas y sobre las personas que me interesan."
  },
  {
    "objectID": "blog/2022-11-20-mastodon/mastodon.html#leer-m√°s",
    "href": "blog/2022-11-20-mastodon/mastodon.html#leer-m√°s",
    "title": "Mastodon",
    "section": "Leer m√°s",
    "text": "Leer m√°s\nInformacion detallada sobre mastodon -en ingl√©s-\nMastodon para investigadores -en ingl√©s-"
  },
  {
    "objectID": "blog/2022-12-04-day-night/day-night.html",
    "href": "blog/2022-12-04-day-night/day-night.html",
    "title": "Circadian classification",
    "section": "",
    "text": "This post is to create a column day or night.\n\n\nFor the exercises, test data is from masked boobies.  To access the data you have to install the package sula: devtools::install_github(‚ÄúMiriamLL/sula‚Äù)\n\n#devtools::install_github(\"MiriamLL/sula\")\nlibrary(sula)\nGPS01<-(GPS_01)\n\n\n\n\n\nlibrary(dplyr)\n\nIdentify column with time date data\n\nGPS01$dt <- as.POSIXct(strptime(GPS01$tStamp, \"%Y-%m-%d %H:%M:%S\"))\n\n\n\n\nOnce is in time and date format, you can extract just the hours\n\nGPS01$hour <- as.numeric(substr(GPS01$dt, 12, 13))\n\n\n\n\nCreate a classification base on the time of sunset and sunrise.\n\nGPS01<-GPS01 %>%\n mutate(\n    day_night = case_when(\n      hour > 20 |  hour < 6 ~ \"night\",\n      TRUE  ~ \"day\"\n    ))\n\n\n\n\n\nlibrary(tidyverse)\n\nNow you can quantify how much your animals were out at night\n\nGPS01 %>%\n  group_by(day_night)%>%\n  count()%>%\n  pivot_wider(names_from = day_night, values_from = n)\n\nI hope this might help you\n\n\n\nClassify activities at night in penguins"
  },
  {
    "objectID": "blog/2023-01-27-qgispolygon/qgispolygon.html",
    "href": "blog/2023-01-27-qgispolygon/qgispolygon.html",
    "title": "Custom made polygon",
    "section": "",
    "text": "This post is to give you an example on how to create your own polygon using google maps.\n\n\nFor this exercise we used the release candidate of QGIS, but every version has the option to create new layers, so no worries in which version you are using.\n\n\n\n\n\n\n\n\n\nIf you still dont have it, here is the link for download QGIS\n\n\n\nIn earlier QGIS versions, there was a plugin called Open Layers plugin, but is not available anymore (as far as I am aware of).\nNow to add a google satellite map in your QGIS you could do the following:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou need to give it a name and the URL\nThere are many options of maps, you can look at some here: Google URLs\nWe will use Open Street Map: https://tile.openstreetmap.org/{z}/{x}/{y}.png for the example.\n\n\n\n\n\nOnce you have create the connection, double click on the name and the map should be loaded as a layer.\n\n\n\n\n\nReady to Use!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI recommend to click on the three dots to select also the directory\nIn the exercise, we will create a polygon, therefore, select Polygon in Geometry type\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe areas will start to look red\nKeep clicking until you have a more or less the polygon you want\nWhen you finish you should add an id, here I used the number 1 for an example\n\n\n\n\n\nNow you should have a polygon!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n‚Ä¶ Now you are done!\nI hope this helped you.\n\n\n\n\nFor continuing learning, here are other uses of google maps:\n\nMedium\n\nAdd background map\n\nGoogle API\n\nGoogle URLs"
  },
  {
    "objectID": "blog/2023-02-04-subset-shapefile/subset-shapefile.html",
    "href": "blog/2023-02-04-subset-shapefile/subset-shapefile.html",
    "title": "Subset shapefile",
    "section": "",
    "text": "Three steps to subset a shapefile and export a new shapefile with the attributes you are interested in.\n\n\nLoad the package sf to load your shapefile into R\n\nlibrary(sf)\n\nLoad the package here to use your directory (in which folder is your shapefile)\n\nlibrary(here)\n\n\n\n\nLoad your shapefile, be careful with your directory\n\nOld_shapefile<- read_sf(paste0(My_directory,'/original_shapefile.shp'))\n\nCheck the class, theoretically it would show sf\n\nclass(Old_shapefile)\n\nExplore the contents\n\nstr(Old_shapefile)\n\nCheck the values in the column that you are interested to subset, to show unique values use the argument unique and to show them in alphabetic order use sort\n\nsort(unique(Old_shapefile$comuna))\n\n\n\n\nLoad the package tidyverse\n\nlibrary(tidyverse)\n\nUsing the function filter you can subset your old new shapefile and get the new one\nIn the example we used the column comuna and the value we are interested is La Higuera, do not forget to replace those values\n\nNew_shapefile<-Old_shapefile %>%\n  filter(comuna==\"La Higuera\")\n\n\n\n\nCheck the class of your new object\n\nclass(New_shapefile)\n\nExport to your selected directory\n\nst_write(New_shapefile, paste0(My_directory,'/New_shapefile.shp'))"
  },
  {
    "objectID": "blog/2023-03-04-mapping-in-r/mapping-in-r.html",
    "href": "blog/2023-03-04-mapping-in-r/mapping-in-r.html",
    "title": "Mapping in R",
    "section": "",
    "text": "How to create a map in ggplot and add attributes.\n\n\nYou can download shapefiles from: https://www.naturalearthdata.com/downloads/\nCall the package here to work in your directory.\n\nlibrary(here)\n\nCall the package sf to read the shapefiles into R\n\nlibrary(sf)\n\n\n\n\nUse your directory name, and give the name of your shapefile\n\n\n\n\nEurope<-st_read(paste0(Directory,MyShapefileName))\n\n\n\n\nLoad ggplot2\n\nlibrary(ggplot2)\n\nPlot your shapefile\n\nggplot()+  \n  geom_sf(data = Europe)\n\n\n\n\nI copy the hex colors from coolors\n\nggplot()+  \n  geom_sf(data = Europe, \n          colour = \"#edf2f4\", \n          fill = \"#2b2d42\",\n          size=0.5)\n\n\n\n\nYou can eliminate the grids and the change the background color in ggplot\n\nggplot()+  \n  geom_sf(data = Europe, \n          colour = \"#edf2f4\", \n          fill = \"#2b2d42\",\n          size=0.5)+\n  theme(\n        panel.grid.major = element_blank(), \n        panel.grid.minor = element_blank(),\n        panel.background = element_rect(fill = '#edf2f4'),\n        legend.background = element_rect(fill = '#edf2f4'))\n\n\n\n\nReduce to focus in your area of interest\n\nggplot()+  \n  geom_sf(data = Europe, \n          colour = \"#edf2f4\", \n          fill = \"#2b2d42\",\n          size=0.5)+\n  theme(\n        panel.grid.major = element_blank(), \n        panel.grid.minor = element_blank(),\n        panel.background = element_rect(fill = '#edf2f4'),\n        legend.background = element_rect(fill = '#edf2f4'))+\n  \n  coord_sf(xlim = c(9, 31),ylim = c(53, 65))\n\n\n\n\nLoad the package ggspatial to add a scale and an north arrow\n\nlibrary(ggspatial)\n\nbr is from bottom right\nbar_cols is for column colors\ntext_col is for the color of the text\n\nggplot()+  \n  geom_sf(data = Europe, \n          colour = \"#edf2f4\", \n          fill = \"#2b2d42\",\n          size=0.5)+\n  theme(\n        panel.grid.major = element_blank(), \n        panel.grid.minor = element_blank(),\n        panel.background = element_rect(fill = '#edf2f4'),\n        legend.background = element_rect(fill = '#edf2f4'))+\n  \n  coord_sf(xlim = c(9, 31),ylim = c(53, 65))+\n    scale_x_continuous(labels = function(x) paste0(x, '\\u00B0', \"W\")) +\n    scale_y_continuous(labels = function(x) paste0(x, '\\u00B0', \"N\")) +\n  \n  annotation_scale(location = \"br\",bar_cols = c(\"#ef233c\", \"#d90429\"),text_col = '#ef233c')\n\n\n\n\ntl is for top left\nwhich_north preferably true (see why here)\nnorth_arrow_fancy_orienteering (see other styles here)\n\nggplot()+  \n  geom_sf(data = Europe, \n          colour = \"#edf2f4\", \n          fill = \"#2b2d42\",\n          size=0.5)+\n  theme(\n        panel.grid.major = element_blank(), \n        panel.grid.minor = element_blank(),\n        panel.background = element_rect(fill = '#edf2f4'),\n        legend.background = element_rect(fill = '#edf2f4'))+\n  \n  coord_sf(xlim = c(9, 31),ylim = c(53, 65))+\n    scale_x_continuous(labels = function(x) paste0(x, '\\u00B0', \"W\")) +\n    scale_y_continuous(labels = function(x) paste0(x, '\\u00B0', \"N\")) +\n  \n   annotation_scale(location = \"br\",bar_cols = c(\"#ef233c\", \"#d90429\"),text_col = '#ef233c')+\n  \n  annotation_north_arrow(location = \"tl\", style = north_arrow_minimal(text_col = '#ffd60a',line_col = '#ffd60a',fill = '#ffd60a')) \n\n\n\n\n\n\nThats it for now!"
  },
  {
    "objectID": "blog/2023-04-06-gridraster/gridraster.html",
    "href": "blog/2023-04-06-gridraster/gridraster.html",
    "title": "Grid, Raster, Colors",
    "section": "",
    "text": "The goal of this post is to:\n1- Create a grid  2- Extract values per grid  3- Keep only grid cells with values  4- Calculate mean values per grid  5- Customize raster plot \n\n\nFor this example, we will use the data provided in the package sula  The data is from tracked masked boobies at Rapa Nui  The data is already in tidy format \n\nmy_data<-(sula::GPS_preparado)\n\n\n\n\nStart by converting the data from data.frame to an sf object using functions from the package sf\n\nlibrary(sf)\n\nUsing the argument st_as_sf convert the data to a sf object\n\nmy_points<-my_data %>%\n  st_as_sf(coords=c('Longitude','Latitude'),\n           crs=4326,\n           remove=FALSE)\n\nFor plotting the data use the package ggplot2\n\nlibrary(ggplot2)\n\nSince the data is an sf object, use the function geom_sf to plot\n\nggplot()+\n  geom_sf(data=my_points)+\n  theme_minimal()\n\nTo create a grid using the points.\nA common used method is the fish net. By definition, the fish net, or square grids, is a good method of covering a surface. The method is called tessellation, and it converts a surface with no overlaps or gaps, like when using tiles.\nTo create a grid the function st_make_grid can be used \nThe arguments of the function st_make_grid are:  n - an integer of length 1 or 2, which corresponds to the number of grid cells in x and y direction (columns, rows) what - defines if polygons, corners or centers are to be created  square- is set to TRUE creates squares, if set to FALSE creates an hexagonal grid\nTo decide on the size of the grids, check the differences in latitudes and longitudes using the function range\n\nrange(my_points$Latitude)\nrange(my_points$Longitude)\n\n\nmy_grid<-st_make_grid(my_points, \n                       c(0.05, 0.05), \n                       what = \"polygons\",\n                       square = TRUE)\n\nNow that the grid has been calculated, transform the grid to sf using the function st_sf and add an grid_id to the grid cell using the function mutate from the package dplyr\n\nlibrary(dplyr)\n\n\nmy_grid_sf = st_sf(my_grid) %>%\n  mutate(grid_id = 1:length(lengths(my_grid)))\n\nTo plot the recently created grid:\n\nggplot()+\n  geom_sf(data=my_grid_sf)+\n  geom_sf(data=my_points)+\n  theme_minimal()\n\n\n\n\nUsing the function st_intersection the values from the points can be added to the grid\nUsing the argument lenghts the sample number per grid can be calculated\n\nmy_grid_sf$nlocs <- lengths(st_intersects(my_grid_sf, \n                                          my_points))\n\nTo add color to the plot, the package viridis provides the function scale_fill_viridis.\n\nlibrary(viridis)\n\nThe color will correspond to the number of locations (nlocs)\n\nggplot()+\n  geom_sf(data=my_grid_sf,aes(fill=nlocs))+\n  theme_minimal()+\n  scale_fill_viridis(direction = -1) \n\n\n\n\nTo keep only the grid cells that were surveyed, the grid cells that have 0 recording can be removed\n\ngrid_w_data = filter(my_grid_sf, nlocs > 0)\n\nTo check which grid cells were removed, plot the previous and current grid\n\nggplot()+\n  geom_sf(data = my_grid)+\n  geom_sf(data = grid_w_data, colour = \"#42a921\", fill= '#bde0fe',alpha=0.9)+\n  NULL\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo calculate the mean values per grid, functions from the package tidyverse can be used\n\nmy_dens<-my_points\n\nFor the exercise, generate random data using the function runif\n\nmy_dens$densities<-runif(nrow(my_dens), min=0, max=1)\n\nTo transform from data.frame to sf object the function st_as_sf can be used\n\nmy_dens_sf <-my_dens %>% \n  st_as_sf(coords = c(\"Longitude\", \"Latitude\"))\n\nTo assign the coordinate system the function st_set_crs can be used\n\nmy_dens_sf  = st_set_crs(my_dens_sf , \"EPSG:4326\")\n\nUsing the function st_intersection, the grid number to each data point is added\n\ndens_grid <- st_intersection(grid_w_data,my_dens_sf)\n\nWith the function mutate, the mean density per grid can be calculated\n\ndens_mean <- dens_grid %>%\n  st_drop_geometry() %>%\n  group_by(grid_id)%>%\n  mutate(grid_dens_means=mean(densities))\n\nFinally, the mean density can be added to the general grid\n\ngrid_w_dens<-merge(grid_w_data,dens_mean, by='grid_id', all=TRUE)\n\nThere might be more than one value per grid, to have one value per grid the function summarise_at can be used.\n\ngrid_dens<-grid_w_dens %>%\n  group_by(grid_id)%>%\n  summarise_at(vars(grid_dens_means),\n               list(name = mean)) %>%\n  rename(dens_mean=name)\n\nTo remove grid without values, the function drop_na can be used\n\nlibrary(tidyverse)\n\n\ngrid_dens<-grid_dens%>%\n  drop_na(dens_mean)\n\nTo check the values that were removed, plot the data.\n\nggplot()+\n  geom_sf(data = grid_dens,aes(fill = dens_mean))+\n  geom_sf(data= my_dens_sf)+\n    scale_fill_viridis(direction = -1) \n\n\n\n\nThe function geom_sf allows to plot a raster\nAxis labels can be changed using scale_x_continuous and scale_y_continuous\nTo see less distracting colors on the background, theme_minimal is a prefered option\n\nggplot()+\n  geom_sf(data = grid_dens,aes(fill = dens_mean))+\n    scale_fill_viridis(direction = -1) +\n    scale_x_continuous(labels = function(x) paste0(x, '\\u00B0', \"W\")) +\n    scale_y_continuous(labels = function(x) paste0(x, '\\u00B0', \"N\"))+\n  theme_minimal()\n\nTo make a custom raster palette the function scale_fill_gradientn can be used\n\ndens_colors<-c('white','#6CB4D3','#1A89AB','#7CC252','#B2EC2B','#DCF754','#FFE454','#FD9708','#F6640F','#EC2C11')\ndens_breaks<-c(0,0.30,0.60,0.85)\ndens_labels<-c('0','0.30','0.60','> 0.85')\n\nThe plot with custom palette arguments consider: colours the number of colors should correspond to the values  breaks for those numbers that are to be displayed  labels for those labels that are to be displayed limits to set up minimum and maximum values on the scale\nTo customize legend:\nlegend.key can be used\n\nggplot()+\n  geom_sf(data = grid_dens,aes(fill = dens_mean),color='transparent')+\n    \n  scale_fill_gradientn(name='Density',\n    colours = dens_colors,\n    breaks = dens_breaks, \n    labels = dens_labels,\n    limits=c(0,1))+\n  \n  \n    scale_x_continuous(labels = function(x) paste0(x, '\\u00B0', \"W\")) +\n    scale_y_continuous(labels = function(x) paste0(x, '\\u00B0', \"N\"))+\n  \n  theme_bw()+\n  \n  theme(panel.background = element_rect(fill = '#3668b4'),\n        panel.grid.major = element_blank(), \n        panel.grid.minor = element_blank())+\n  \n  \n  theme(\n    legend.key = element_rect(color = \"black\",size=5),\n    legend.key.width = unit(1, \"cm\"),\n    legend.key.height = unit(1, \"cm\")) +\n  \n  guides(fill = guide_colorbar(ticks.colour = \"transparent\"))"
  },
  {
    "objectID": "blog/2023-05-05-github-page/github-page.html",
    "href": "blog/2023-05-05-github-page/github-page.html",
    "title": "Github page presentations",
    "section": "",
    "text": "The goal of this post is to:\nCreate a github page for a presentation\nFor the example, a xaringan presentation is to be deployed as github page for easy access\n\n\nYou need to have a repository, if you are first time creating a reposotory, here are some instructions\n\n\n\nGo to your repository, select settings\nIn the right side of the screen select pages\n\n\n\n\n\n\n\n\n\n\n\n\nLook for build and deployment and in source, move from GitHub Actions to Deploy from branch\n\n\n\n\n\n\n\n\n\n\n\n\nThe branch depends where the html file is, here I have it in the master branch\n\n\n\n\n\n\n\n\n\nThis would depend where you have your html file, but here I have it in the master\n\n\n\n\n\n\n\n\n\n\n\n\nIf everything went well Your site is alive at will appear\n\n\n\n\n\n\n\n\n\n\n\n\nTo access specific slides from different presentations, add the html name at the end of the site.\nFor example:\n\nhttps://miriamll.github.io/R_intro/IntroToR_0604.html#1\n\n\n\n\nThe slides can also be converted to pdf\nInstall package using install.packages(‚Äúrenderthis‚Äù)\n\nlibrary(renderthis)\n\n\nto_pdf(from=\"https://miriamll.github.io/R_intro/DataWrangling_1205.html\")\n\n\n\n\n\nGithub Pages\n\nrenderthis"
  },
  {
    "objectID": "blog/2023-06-01-gganimate/gganimate.html",
    "href": "blog/2023-06-01-gganimate/gganimate.html",
    "title": "gganimate",
    "section": "",
    "text": "How to create a map an animation using gganimate\n\n\nLoad and/or install the following packages:\n\nlibrary(here)\nlibrary(tidyverse)\n\n\n\n\n\nlibrary(sula)\n\n\nExample<-GPS_01\n\n\n\n\nMark a day zero to begging the animation, and the sequence to use\n\nfirst(Example$DateGMT)\n\n\nExample$date_diff <- as.Date(as.character(Example$tStamp), \n                             format=\"%Y-%m-%d\")-\n  as.Date(as.character('2017-11-02'), \n          format=\"%Y-%m-%d\")\n\nCreate number sequence for animation\n\nExample<-Example %>% \n  group_by(IDs) %>%\n  mutate(Secuencia = row_number())\n\n\n\n\nFor creating maps, the package sf is to be called.\n\nlibrary(sf)\n\nNow load your data, here I am giving my directory, you should use the one on your computer.\nTo dowload the shapefile from Chile you can use this this link, this shapefile comes from the DIVA-GIS\n\n\n\n\nCountry<-st_read(paste0(Directory,MyShapefileName))\n\n\n\n\nPlot the area of interest\n\nMy_map<-ggplot(data=Example)  + \n  geom_sf(data = Country,colour = \"#edf2f4\", fill = \"#2b2d42\",)+\n  geom_point(data=Example,aes(x = Longitude, y=Latitude))+\n  geom_path(data=Example,aes(x = Longitude, y=Latitude))+\n  coord_sf(xlim = c(-110,-109), ylim = c(-27.5,-26.5))\nMy_map\n\n\n\n\n\nMy_map<-My_map+\n theme_bw()+\n\n  theme(\n    panel.grid.major = element_blank(), \n    panel.grid.minor = element_blank(),\n    panel.background = element_rect(fill = '#edf2f4'),\n    \n    axis.text.x =  element_text(size=12,color = \"black\"),\n    axis.text.y =  element_text(size=12,color = \"black\"),\n    \n    axis.ticks.x = element_line(color = \"black\"),\n    axis.ticks.y = element_line(color = \"black\"),\n    \n    title = element_text(colour = \"black\"),\n    legend.position = \"none\")+\n  \n    scale_x_continuous(labels = function(x) paste0(x, '\\u00B0', \"W\")) +\n    scale_y_continuous(labels = function(x) paste0(x, '\\u00B0', \"N\"))\nMy_map\n\n\n\n\nTo animate this plot, we will use the package gganimate\n\nlibrary(gganimate)\n\nBecause animations might take some time, I like to use the package beepr to let me know when the animation is ready\n\nlibrary(beepr)\n\ntransition_reveal leaves the track on the back ground so you can keep record where it was\n\nMy_animation<-ggplot(data=Example)  + \n  geom_sf(data = Country,colour = \"#edf2f4\", fill = \"#2b2d42\",)+\n  geom_point(data=Example,aes(x = Longitude, y=Latitude, colour = tStamp))+\n  geom_path(data=Example,aes(x = Longitude, y=Latitude))+\n  coord_sf(xlim = c(-110,-109), ylim = c(-27.5,-26.5))+\n  \n  theme_bw()+\n\n  theme(\n    panel.grid.major = element_blank(), \n    panel.grid.minor = element_blank(),\n    panel.background = element_rect(fill = '#edf2f4'),\n    \n    axis.text.x =  element_text(size=12,color = \"black\"),\n    axis.text.y =  element_text(size=12,color = \"black\"),\n    \n    axis.ticks.x = element_line(color = \"black\"),\n    axis.ticks.y = element_line(color = \"black\"),\n    \n    title = element_text(colour = \"black\"),\n    legend.position = \"none\")+\n  \n    scale_x_continuous(labels = function(x) paste0(x, '\\u00B0', \"W\")) +\n    scale_y_continuous(labels = function(x) paste0(x, '\\u00B0', \"N\")) +\n  \n  transition_reveal(along=tStamp) +\n  shadow_trail(distance = 0.01,\n               alpha = 0.5,\n               shape = 1)\nMy_animation\n\n\n\n\nOther arguments are:\ntransition_time use the information for the transition is labs shows the title with time so you can use as a reference\nshadow_wake is the wake behind the points read more here\n\n\n\nThe package animation allows to save the animation as a file\n\nlibrary(animation)\n\nTo export, you can save the animation as gif\n\nanim_save(\"animation.gif\",My_animation)\nbeep(sound=1,expr=NULL)\n\nOr transform from gif to mp4 using the package av\n\nlibrary(av)\n\n\nav::av_encode_video(\"animation.gif\", \n                     framerate = 5 ,\n                     output = 'animation.mp4')\nbeep(sound=1,expr=NULL)"
  },
  {
    "objectID": "blog/2023-07-13-custompoints/custompoints.html",
    "href": "blog/2023-07-13-custompoints/custompoints.html",
    "title": "Custom points in a map",
    "section": "",
    "text": "Customize your plot using different sizes, shapes and colors in the points of your figures."
  },
  {
    "objectID": "blog/2023-07-13-custompoints/custompoints.html#classify",
    "href": "blog/2023-07-13-custompoints/custompoints.html#classify",
    "title": "Custom points in a map",
    "section": "Classify",
    "text": "Classify\nBased on the range of the densities, define how many classes you want to use and where the cuts will be made.\n\nclass0<-0\nclass1<-1\nclass2<-2.5\nclass3<-5\n\nUsing the function mutate from the package tidyverse add a new column with a classification.\nNote that using alphanumerical order is important for the order in the legend.\n\nlibrary(tidyverse)\n\n\ndensity_df<-density_df %>% \n    mutate(density_class = case_when(\n      densities ==  class0 ~ as.character(\"group0\"),\n      densities >=  class0 & densities <=  class1 ~ as.character(\"group1\"),\n      densities >=  class1 & densities <=  class2 ~ as.character(\"group2\"),\n      densities >=  class2 & densities <=  class3 ~ as.character(\"group3\"),\n      densities >=  class3 ~ as.character(\"group4\"),\n      TRUE~\"U\"))\n\nCheck number of observations to make sure your classification was working and that you have at least one value per group.\n\ndensity_df %>%\n  group_by(density_class)%>%\n  tally()"
  },
  {
    "objectID": "blog/2023-07-13-custompoints/custompoints.html#base-plot",
    "href": "blog/2023-07-13-custompoints/custompoints.html#base-plot",
    "title": "Custom points in a map",
    "section": "Base plot",
    "text": "Base plot\nTo visualize your data, create a base plot with defined shape, size and labels.\nTo define the shape and size, the argument was added inside the aes.\nTo assign the values and labels, fill the arguments scale_shape_manual and scale_size_manual.\n\nggplot()+\n  geom_point(data=density_df,\n          aes(x = longitude,\n              y= latitude,\n              shape = density_class,\n              size= density_class),\n              fill= \"#d00000\")+\n  \n  scale_shape_manual(values = density_shapes,labels=density_labels)+\n  scale_size_manual(values =  density_sizes,labels=density_labels)"
  },
  {
    "objectID": "blog/2023-07-13-custompoints/custompoints.html#add-map",
    "href": "blog/2023-07-13-custompoints/custompoints.html#add-map",
    "title": "Custom points in a map",
    "section": "Add map",
    "text": "Add map\nSince we need reference map, the package sf contains the function geom_sf that allows plotting shapefiles, and the package GermanNorthSea contains shapefiles from the North Sea readily available for use.\nCall (or install) the packages\n\nlibrary(sf)\nlibrary(GermanNorthSea)\n\nSome parameters need to be adjusted first, such as which CRS to use, and the limits on the map.\nFor more details go to: Mapping in R and GermanNorthSea\nHere the parameters define that we are going to use CRS 4326, color the land in yellow and the water in blue, and define the coordinates to plot.\n\nmy_CRS<-4326\nEuropa<-sf::st_transform(German_land, my_CRS)\nEEZ<-sf::st_transform(German_EEZ, my_CRS)\ncolor_land='#f7bf54'\ncolor_water='#3668b4'\nxval<-c(3,9)\nyval<-c(53,56)\n\nCreate a base map.\n\nbase_plot<-ggplot2::ggplot()+\n    # maps\n    ggplot2::geom_sf(data = EEZ, colour = 'black', fill = color_water)+\n    ggplot2::geom_sf(data = Europa, colour = 'black', fill = color_land)+ \n    ggplot2::coord_sf(xlim = xval, ylim = yval)+\n\n    NULL\nbase_plot"
  },
  {
    "objectID": "blog/2023-07-13-custompoints/custompoints.html#add-dots",
    "href": "blog/2023-07-13-custompoints/custompoints.html#add-dots",
    "title": "Custom points in a map",
    "section": "Add dots",
    "text": "Add dots\nNow add the density data on top of the base map.\n\ndensity_wmap<-base_plot+\n  geom_point(data=density_df,\n          aes(x = longitude,\n              y= latitude,\n              shape = density_class,\n              size= density_class),\n              fill= \"#d00000\")+\n  \n  scale_shape_manual(values = density_shapes,labels=density_labels)+\n  scale_size_manual(values =  density_sizes,labels=density_labels)\ndensity_wmap\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow you have a base map with density information on different shape and size."
  },
  {
    "objectID": "blog/2023-08-02-customlegend/customlegend.html",
    "href": "blog/2023-08-02-customlegend/customlegend.html",
    "title": "Custom legends in a map",
    "section": "",
    "text": "Customize the legend of your plot."
  },
  {
    "objectID": "blog/2023-08-02-customlegend/customlegend.html#load-data",
    "href": "blog/2023-08-02-customlegend/customlegend.html#load-data",
    "title": "Custom legends in a map",
    "section": "Load data",
    "text": "Load data\nThe package contains data from a random generated density data frame that can be used for the exercise.\nIf you want to create this map from scratch visit: create a map with custom points.\n\nclass0<-0\nclass1<-1\nclass2<-2.5\nclass3<-5\ndensity_df<-density_df %>% \n    dplyr::mutate(density_class = dplyr::case_when(\n      densities ==  class0 ~ as.character(\"group0\"),\n      densities >=  class0 & densities <=  class1 ~ as.character(\"group1\"),\n      densities >=  class1 & densities <=  class2 ~ as.character(\"group2\"),\n      densities >=  class2 & densities <=  class3 ~ as.character(\"group3\"),\n      densities >=  class3 ~ as.character(\"group4\"),\n      TRUE~\"U\"))\n\n\nlibrary(ggplot2)\nlibrary(GermanNorthSea)\n\n\ndensity_wmap<-ggplot2::ggplot()+\n    # maps\n    ggplot2::geom_sf(data = sf::st_transform(GermanNorthSea::German_EEZ,4326), colour = 'black', fill = '#3668b4')+\n    ggplot2::geom_sf(data = sf::st_transform(GermanNorthSea::German_land,4326), colour = 'black', fill = '#f7bf54')+ \n    ggplot2::coord_sf(xlim = c(3,9), ylim = c(53,56))+\n    geom_point(data=density_df,\n          aes(x = longitude,\n              y= latitude,\n              shape = density_class,\n              size= density_class),\n              fill= \"#d00000\")+\n  \n  scale_shape_manual(values = c(\"group0\"=3, \"group1\"=21,\"group2\"=21, \"group3\"=21, \"group4\"=21),\n                     labels=c('0','> 0-1','> 1-2.5','> 2.5-5','> 5'))+\n  scale_size_manual(values =  c(\"group0\"=0.5, \"group1\"=1,\"group2\"=2, \"group3\"=3, \"group4\"=5),\n                    labels=c('0','> 0-1','> 1-2.5','> 2.5-5','> 5'))\n\n\ndensity_wmap"
  },
  {
    "objectID": "blog/2023-08-02-customlegend/customlegend.html#add_legend",
    "href": "blog/2023-08-02-customlegend/customlegend.html#add_legend",
    "title": "Custom legends in a map",
    "section": "add_legend",
    "text": "add_legend\nI create this function to include the legend inside the plot, the function is available on the package SeaDens.\nThe function removes the background of the legend making it transparent, and includes the legend inside the plot based on the coordinates provided.\n\nadd_legend<-function(plot_wbreaks=plot_wbreaks,\n                     legxy=legxy){\n  plot_wlegend<-plot_wbreaks+\n    ggplot2::theme(\n      legend.position = legxy,\n      legend.title = ggplot2::element_blank(),\n      legend.text= ggplot2::element_text(size=10,color=\"#343a40\",family='sans'),\n      legend.spacing.y =  ggplot2::unit(0.01, 'cm'),\n      legend.spacing.x =  ggplot2::unit(0.2, 'cm'),\n      legend.background = ggplot2::element_rect(fill='transparent',colour =\"transparent\"),\n      legend.box.background = ggplot2::element_rect(fill='transparent',colour =\"transparent\"),\n      legend.key = ggplot2::element_rect(fill = \"transparent\", colour = \"transparent\"),\n      legend.key.size =  ggplot2::unit(0.7, 'cm'))\n  return(plot_wlegend)\n}\n\nHere, the arguments inside legxy are referring to where the legend will appear.\n\ndensity_wlegend<-add_legend(\n  plot_wbreaks=density_wmap,\n  legxy=c(0.11, 0.21))\ndensity_wlegend\n\nTo add the title of the legend, I used the function annotate and a specific expression since I am using superscript.\n\ndensity_wlegend<-density_wlegend+\n  ggplot2::theme(legend.key.size = ggplot2::unit(0.4, \"cm\"))+\n  ggplot2::annotate(geom=\"text\",\n                      x=3.0, y=54.0,\n                      label=expression(atop(\"Density\"), paste(\"[ind/k\", m^2,\"]\")),\n                      color=\"#343a40\",hjust = 0)\n\ndensity_wlegend"
  },
  {
    "objectID": "blog/2023-08-02-customlegend/customlegend.html#add_theme",
    "href": "blog/2023-08-02-customlegend/customlegend.html#add_theme",
    "title": "Custom legends in a map",
    "section": "add_theme",
    "text": "add_theme\nThis function changes the x and y axis legends to Capitalized words and includes the symbol of degree on the plot. Removes the gray background and adds a white line on the panel border. It is also available in the package SeaDens, but I am including it here in case you want to customize it.\n\nadd_theme<-function(plot_wlegend=plot_wlegend){\n\n  plot_wtheme<-plot_wlegend+\n    ggplot2::xlab('Longitude')+\n    ggplot2::ylab('Latitude')+\n    ggplot2::scale_x_continuous(labels = function(x) paste0(x, '\\u00B0', \"W\")) +\n    ggplot2::scale_y_continuous(labels = function(x) paste0(x, '\\u00B0', \"N\"))+\n    ggplot2::theme(\n      panel.border = ggplot2::element_rect(colour = \"black\", fill=NA, linewidth = 1),\n      panel.grid.major = ggplot2::element_blank(),\n      panel.grid.minor = ggplot2::element_blank(),\n      panel.background = ggplot2::element_blank())\n  return(plot_wtheme)\n}\n\nTo run the function just add your plot.\n\ndensity_wtheme<-add_theme(plot_wlegend = density_wlegend)\ndensity_wtheme\n\nYou can theoretically use the function add_theme with any other map."
  },
  {
    "objectID": "blog/2023-09-01-patchwork-legend/custom-legend.html",
    "href": "blog/2023-09-01-patchwork-legend/custom-legend.html",
    "title": "Reference legend multiplots",
    "section": "",
    "text": "For this example, we will use the data provided in the package sula  The data is from tracked masked boobies at Rapa Nui  The data is already in tidy format \n\nmy_data<-(sula::GPS_preparado)"
  },
  {
    "objectID": "blog/2023-09-01-patchwork-legend/custom-legend.html#grid",
    "href": "blog/2023-09-01-patchwork-legend/custom-legend.html#grid",
    "title": "Reference legend multiplots",
    "section": "Grid",
    "text": "Grid\nThe steps on this parts are on ‚Äúhow to create grid‚Äù\nPackages to use:\n\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(ggplot2)\n\nRun to create a reference grid.\n\nmy_points<-my_data %>%\n  st_as_sf(coords=c('Longitude','Latitude'),\n           crs=4326,\n           remove=FALSE)\n\nmy_grid<-st_make_grid(my_points, \n                       c(0.05, 0.05), \n                       what = \"polygons\",\n                       square = TRUE)\n\nmy_grid_sf = st_sf(my_grid) %>%\n  mutate(grid_id = 1:length(lengths(my_grid)))\n\nmy_grid_sf$nlocs <- lengths(st_intersects(my_grid_sf, \n                                          my_points))\n\nFor the exercices, we want to create plots per individual.\nSo lets first check the name of the individuals.\n\nunique(my_data$IDs)\n\nTo count number of locations per grid and add it as a column in the original grid functions from the package tidyverse can be used.\n\nGPS01_subset<- my_data %>%\n  filter(IDs=='GPS01')\n\nGPS01_sf<-GPS01_subset %>%\n  st_as_sf(coords=c('Longitude','Latitude'),\n           crs=4326,\n           remove=FALSE)\n\nmy_grid_sf$GPS01_nlocs<- lengths(st_intersects(my_grid_sf, \n                                          GPS01_sf))\n\n\nGPS02_subset<- my_data %>%\n  filter(IDs=='GPS02')\n\nGPS02_sf<-GPS02_subset %>%\n  st_as_sf(coords=c('Longitude','Latitude'),\n           crs=4326,\n           remove=FALSE)\n\nmy_grid_sf$GPS02_nlocs<- lengths(st_intersects(my_grid_sf, \n                                          GPS02_sf))"
  },
  {
    "objectID": "blog/2023-09-01-patchwork-legend/custom-legend.html#custom-palette",
    "href": "blog/2023-09-01-patchwork-legend/custom-legend.html#custom-palette",
    "title": "Reference legend multiplots",
    "section": "Custom palette",
    "text": "Custom palette\nNow to create a plot, lets select your palette based on the number of locations.\n\nrange(my_grid_sf$GPS01_nlocs)\nrange(my_grid_sf$GPS02_nlocs)\n\nBecause the palette is between 0 and 16, we will manually create the palette using characters.\n\nmy_palette <- c(\"1\" = \"#FFCF70\",\n                \"2\" = \"#FFC242\",\n                \"3\" = \"#FFBE33\",\n                \"4\" = \"#F5A300\",\n                \"5\" = \"#FD9A21\",\n                \"6\" = \"#FA8C02\",\n                \"7\" = \"#FF740A\",\n                \"8\" = \"#F56A00\",\n                \"9\" = \"#CEA7EE\",\n                \"10\" = \"#C698EB\",\n                \"11\" = \"#B376E5\",\n                \"12\" = \"#9D4EDD\",\n                \"13\" = \"#9643DB\",\n                \"14\" = \"#72369D\",\n                \"15\" = \"#6E3498\",\n                \"16\" = \"#3B194D\")\n\nTo create the plot:\n- Subset only to grids with data\n- Convert the locations into character\n- Add palette in scale_fill_manual\n4. Remove legend\n\nGPS01_plot<-ggplot()+\n  geom_sf(data=subset(my_grid_sf,GPS01_nlocs != 0),\n                      aes(fill=as.character(GPS01_nlocs)))+\n  theme_bw()+\n  scale_fill_manual(name = \"no.locs\",values = my_palette)+\n  theme(legend.position = 'none')+\n  coord_sf(xlim = c(-110, -108),ylim = c(-28, -26))+  \n  scale_x_continuous(labels = function(x) paste0(x, '\\u00B0', \"W\")) +\n  scale_y_continuous(labels = function(x) paste0(x, '\\u00B0', \"N\"))\nGPS01_plot\n\n\nGPS02_plot<-ggplot()+\n  geom_sf(data=subset(my_grid_sf,GPS02_nlocs != 0),\n                      aes(fill=as.character(GPS02_nlocs)))+\n  theme_bw()+\n  scale_fill_manual(name = \"no.locs\",values = my_palette)+\n  theme(legend.position = 'none')+\n  coord_sf(xlim = c(-110, -108),ylim = c(-28, -26))+  \n  scale_x_continuous(labels = function(x) paste0(x, '\\u00B0', \"W\")) +\n  scale_y_continuous(labels = function(x) paste0(x, '\\u00B0', \"N\"))\nGPS02_plot"
  },
  {
    "objectID": "blog/2023-10-02-inside-legend/inside-legend.html",
    "href": "blog/2023-10-02-inside-legend/inside-legend.html",
    "title": "Inside legend",
    "section": "",
    "text": "For this example, we will use the data provided in the package sula  The data is from tracked masked boobies at Rapa Nui  The data is already in tidy format \n\nmy_data<-(sula::GPS_preparado)\n\n\ncolor1<-'#ff595e'\ncolor2<-'#ff924c'\ncolor3<-'#ffca3a'\ncolor4<-'#8ac926'\ncolor5<-'#52a675'\ncolor6<-'#1982c4'\ncolor7<-'#4267ac'\ncolor8<-'#6a4c93'"
  },
  {
    "objectID": "blog/2023-10-02-inside-legend/inside-legend.html#inside-legend",
    "href": "blog/2023-10-02-inside-legend/inside-legend.html#inside-legend",
    "title": "Inside legend",
    "section": "Inside legend",
    "text": "Inside legend\nSelect the coordinates for the legend\n\nlegx<- -109.90\nlegy<- -27.4\n\nAdd text\n\nmy_plot_wtext<-my_plot + \n\n  annotate(geom=\"text\",x= legx, y=legy-0.1, label=\"GPS01\",color=\"#343a40\",hjust = 0, size=2)+\n  annotate(geom=\"text\",x= legx, y=legy-0.15, label=\"GPS02\",color=\"#343a40\",hjust = 0, size=2)+\n  annotate(geom=\"text\",x= legx, y=legy-0.2, label=\"GPS03\",color=\"#343a40\",hjust = 0, size=2)+\n  annotate(geom=\"text\",x= legx, y=legy-0.25, label=\"GPs04\",color=\"#343a40\",hjust = 0, size=2)+\n  annotate(geom=\"text\",x= legx, y=legy-0.3, label=\"GPS05\",color=\"#343a40\",hjust = 0, size=2)+\n  annotate(geom=\"text\",x= legx, y=legy-0.35, label=\"GPS06\",color=\"#343a40\",hjust = 0, size=2)\nmy_plot_wtext\n\nAdd segment\n\nmy_plot_wtext +\n  annotate(\"segment\", x = legx-0.01, xend = legx-0.04, y = legy-0.1, yend = legy-0.1,color = color1,linewidth=1)+\n  annotate(\"segment\", x = legx-0.01, xend = legx-0.04, y = legy-0.15, yend = legy-0.15,color = color2,linewidth=1)+\n  annotate(\"segment\", x = legx-0.01, xend = legx-0.04, y = legy-0.2, yend = legy-0.2,color = color3,linewidth=1)+\n  annotate(\"segment\", x = legx-0.01, xend = legx-0.04, y = legy-0.25, yend = legy-0.25,color = color4,linewidth=1)+\n  annotate(\"segment\", x = legx-0.01, xend = legx-0.04, y = legy-0.3, yend = legy-0.3,color = color5,linewidth=1)+\n  annotate(\"segment\", x = legx-0.01, xend = legx-0.04, y = legy-0.35, yend = legy-0.35,color = color6,linewidth=1)\n\nAdd rectangle\n\nmy_plot_wtext +\n  annotate(\"rect\", xmin = legx-0.01, xmax = legx+0.08, ymin = legy-0.09, ymax = legy-0.12,color = color1,linewidth=1, fill=\"transparent\")+\n  annotate(\"rect\", xmin = legx-0.01, xmax = legx+0.08, ymin = legy-0.14, ymax = legy-0.17,color = color2,linewidth=1, fill=\"transparent\")+\n  annotate(\"rect\", xmin = legx-0.01, xmax = legx+0.08, ymin = legy-0.19, ymax = legy-0.22,color = color3,linewidth=1, fill=\"transparent\")+\n  annotate(\"rect\", xmin = legx-0.01, xmax = legx+0.08, ymin = legy-0.24, ymax = legy-0.27,color = color4,linewidth=1, fill=\"transparent\")+\n  annotate(\"rect\", xmin = legx-0.01, xmax = legx+0.08, ymin = legy-0.29, ymax = legy-0.32,color = color5,linewidth=1, fill=\"transparent\")+\n  annotate(\"rect\", xmin = legx-0.01, xmax = legx+0.08, ymin = legy-0.34, ymax = legy-0.37,color = color6,linewidth=1, fill=\"transparent\")\n\n\n\n\n\n\n\n\n\nYou can of course use the legend, but this option is for me more easy to custom and move around the plot. Moreover, it allows you to include all kinds of annotations inside the plot."
  },
  {
    "objectID": "blog/2023-11-02-secondaryxtitle/secondaryxtitle.html",
    "href": "blog/2023-11-02-secondaryxtitle/secondaryxtitle.html",
    "title": "secondary x title",
    "section": "",
    "text": "This post is to show how to create a secondary x title in a ggplot"
  },
  {
    "objectID": "blog/2023-11-02-secondaryxtitle/secondaryxtitle.html#theme",
    "href": "blog/2023-11-02-secondaryxtitle/secondaryxtitle.html#theme",
    "title": "secondary x title",
    "section": "Theme",
    "text": "Theme\nNow lets remove the legend and the title of the x axis.\nLets also replace the text in the x axis.\n\nplot_b<-plot_a+\n  theme(legend.position = \"none\",\n        axis.title.x = element_blank())+\n  scale_x_discrete(labels=  c(\"F\", \"M\", \"F\", \"M\"))\nplot_b"
  },
  {
    "objectID": "blog/2023-11-02-secondaryxtitle/secondaryxtitle.html#increase-coord",
    "href": "blog/2023-11-02-secondaryxtitle/secondaryxtitle.html#increase-coord",
    "title": "secondary x title",
    "section": "Increase coord",
    "text": "Increase coord\nNow, the purpose of the exercise is to add a secondary axis.\nTo do this, we will expand the space on the y axis.\nBy doing so we will have more space for the secondary text. Note that it might be difficult to see at first grasp, but there is some empty space.\nThe arguments to increase the space are:\n- coord_cartesian and clip off\n- considering the y limit\n- change the plot.margin\n\nplot_c<-plot_b+\n  coord_cartesian(clip = \"off\",ylim = c(10, 80))+\n  scale_y_continuous(breaks=c(20,40,60,80), \n                     limits=c(-10,80))+\n  theme(plot.margin=unit(c(0,0.1,2,0.2),\"cm\"))\nplot_c"
  },
  {
    "objectID": "blog/2023-11-02-secondaryxtitle/secondaryxtitle.html#add-segments-and-text",
    "href": "blog/2023-11-02-secondaryxtitle/secondaryxtitle.html#add-segments-and-text",
    "title": "secondary x title",
    "section": "Add segments and text",
    "text": "Add segments and text\nNow in the space created under the y axis, we can add the subtitles using the annotation arguments.\n\nplot_c+\n  annotate(geom = \"text\",x = 1.5,y = -5, label = \"Group 1\",size = 4)+\n  annotate(\"segment\",y = 0, yend = 0,x = 1, xend = 2,colour = \"black\")+\n  \n  annotate(geom = \"text\",x = 3.5,y = -5, label = \"Group 2\",size = 4)+\n  annotate(\"segment\",y = 0, yend = 0,x = 3, xend = 4,colour = \"black\")\n\n\n\n\n\n\n\n\n\nThat was it, I hope it helps :)"
  },
  {
    "objectID": "blog/2023-12-04-arrows/arrows.html",
    "href": "blog/2023-12-04-arrows/arrows.html",
    "title": "using arrows",
    "section": "",
    "text": "This post is to create a plot that has arrows indicating the direction\nIn the example, we use sample data, but if you know where you event starts and ends you can skip these steps and go directly to the final section."
  },
  {
    "objectID": "blog/2023-12-04-arrows/arrows.html#calculate-gaps",
    "href": "blog/2023-12-04-arrows/arrows.html#calculate-gaps",
    "title": "using arrows",
    "section": "Calculate gaps",
    "text": "Calculate gaps\nUsing the information from time, we will check when there were gaps and based on where a gap was, identify different events\nLoad tidyverse package to use some functions\n\nlibrary(tidyverse)\n\nCheck that your time data is in the correct format\n\nsurvey_data$dt <- as.POSIXct(strptime(survey_data$timestamps, \"%Y-%m-%d %H:%M:%S\"))\n\nThis function uses the times to identify where there was a gap, assuming that the data is sorted\n\ncalculate_gaps<-function(my_data=my_data){\n  time1<-my_data$dt\n  time2<-lag(time1)\n  time_dif<-as.numeric(difftime(time1,time2, units=\"mins\"))\n  my_data$time_dif<-as.numeric(time_dif)\n  return(my_data)\n}\n\nAfter running the function, a new data frame will be created which includes a column named time_dif\n\nsurvey_data_gaps<-calculate_gaps(survey_data)\n\nHere we will define, how many minutes should be considered a gap\n\nsurvey_data_gaps<-survey_data_gaps %>%\n  mutate(gap_event = case_when(is.na(time_dif) ~ 'N',\n                                time_dif >= 2 ~ 'Y',\n                                TRUE ~ 'N'))"
  },
  {
    "objectID": "blog/2023-12-04-arrows/arrows.html#identify-events",
    "href": "blog/2023-12-04-arrows/arrows.html#identify-events",
    "title": "using arrows",
    "section": "Identify events",
    "text": "Identify events\nTo add a number to each event in order to be able to identify them separately, we use the following function\n\nidentify_events<-function(my_data=my_data){\n  num_seq<-nrow(my_data)\n  num_seq<-as.numeric(num_seq)\n  my_data$num_seq<-as.numeric(paste(seq(1:num_seq)))\n  subset_data<-subset(my_data,my_data$gap_event != \"Y\")\n  subset_data$num_seq<-as.integer(subset_data$num_seq)\n  subset_data$event_number<-(cumsum(c(1L, diff(subset_data$num_seq)) != 1L))\n  subset_data$event_number<-subset_data$event_number+1\n  subset_data$event_number<-stringr::str_pad(subset_data$event_number, 3, pad = \"0\")\n  subset_data$event_number<-paste0(\"event_\",subset_data$event_number)\n  subset_data<-subset_data%>%select(num_seq,event_number)\n  my_data_events<-full_join(my_data,subset_data,by='num_seq')\nreturn(my_data_events)\n}\n\nThe function will return a data frame with a new column called event_number\n\nsurvey_data_events<-identify_events(my_data=survey_data_gaps)"
  },
  {
    "objectID": "blog/2023-12-04-arrows/arrows.html#start-and-time-of-the-events",
    "href": "blog/2023-12-04-arrows/arrows.html#start-and-time-of-the-events",
    "title": "using arrows",
    "section": "Start and time of the events",
    "text": "Start and time of the events\nUsing the classification of the events, we will extract the first and the last location per event, which would become the start and end of the arrow on the plot\n\nsurvey_time_events<-survey_data_events %>%\n  group_by(event_number)%>%\n  summarise(first_lat=first(latitude),\n            last_lat=last(latitude),\n            first_lon=first(longitude),\n            last_lon=last(longitude))%>%\n  drop_na()"
  },
  {
    "objectID": "blog/2023-12-04-arrows/arrows.html#plot",
    "href": "blog/2023-12-04-arrows/arrows.html#plot",
    "title": "using arrows",
    "section": "Plot",
    "text": "Plot\nTo plot we use the function geom_segment and the additional argument arrow\n\nggplot(survey_time_events,\n       aes(x = first_lon, y = first_lat)) +\n  geom_segment(aes(xend = last_lon, yend = last_lat), arrow = arrow())"
  },
  {
    "objectID": "blog/2023-12-04-arrows/arrows.html#group-by-event",
    "href": "blog/2023-12-04-arrows/arrows.html#group-by-event",
    "title": "using arrows",
    "section": "Group by event",
    "text": "Group by event\nUse the function group_by and summarise to identify the start and end of the events, now with the rescaling there would be more events\n\nsurvey_rescale_arrows<-survey_rescale %>%\n  group_by(event_number2)%>%\n  summarise(first_lat=first(latitude),\n            last_lat=last(latitude),\n            first_lon=first(longitude),\n            last_lon=last(longitude))%>%\n  drop_na()\n\nSimilarly to above we use the function geom_segment and the argument arrow\n\nggplot(survey_rescale_arrows,\n       aes(x = first_lon, y = first_lat)) +\n  geom_segment(aes(xend = last_lon, yend = last_lat), \n               arrow = arrow())"
  },
  {
    "objectID": "blog/2023-12-04-arrows/arrows.html#further-reading",
    "href": "blog/2023-12-04-arrows/arrows.html#further-reading",
    "title": "using arrows",
    "section": "Further reading",
    "text": "Further reading\nTo change the shape, size and form of the arrow visit geom_segment"
  },
  {
    "objectID": "blog/2024-01-15-calendar/calendar.html",
    "href": "blog/2024-01-15-calendar/calendar.html",
    "title": "Create a calendar",
    "section": "",
    "text": "Intro\nThis post is to create a calendar to check when some events were more likely to occur.\n\n\nPackages\n\nlibrary(tidyverse)\n\n\n\nData\nCreate a data frame with a sequence of days\n\nfirstday<- as.Date(\"2020-05-01\")\nlastday <- as.Date(\"2020-08-31\")\ndays_seq <- seq(firstday, lastday, by = \"day\")\ndays_df<-as.data.frame(days_seq)\n\nSeparate months and days\n\ndays_df$month<-substr(days_df$days, start = 6, stop = 7)\ndays_df$day<-substr(days_df$days, start = 9, stop = 10)\n\nAdd values\n\nmy_values<-sample(1:7, 123, replace=TRUE)\ndays_df$events<-as.factor(my_values[1:123])\n\nSeparate months\n\nmay<-days_df %>%\n  filter(month=='05')\n\nCreate x and y axis\n\ncalen_xs<-rep(c(1:7), times = 5)\ncalen_ys<-rep(c(5:1), each = 7)\n\n\nmay$calen_xs<-calen_xs[1:31]\nmay$calen_ys<-calen_ys[1:31]\n\nSelect color palette\n\nmy_palette <- c(\"1\" = '#577590', \n                \"2\" = '#43aa8b', \n                \"3\" = '#90be6d', \n                \"4\" = \"#f9c74f\", \n                \"5\" = \"#f8961e\", \n                \"6\" = \"#f3722c\", \n                \"7\" = \"#f94144\") \n\n\n\nPlot\n\nggplot(may,aes(x=calen_xs,y=calen_ys,color=events))+\n  geom_point(size=25,shape=15)+\n\n  scale_x_continuous(limits=c(0.5,7.5))+\n  scale_y_continuous(limits=c(0.5,5.5))+\n  \n  # remove background colors\n  theme_void()+\n  \n  # adds texts\n  geom_text(aes(label=day),color='white') +\n  \n  # sets the legend below\n  theme(legend.position = 'top')+\n   \n  # lines the legend\n  guides(colour = guide_legend(override.aes = list(size=6),nrow = 1))+\n  \n  # uses palette\n  scale_color_manual(name = \"May no. events\",values = my_palette)\n\n\n\n\n\n\n\n\n\nI used this to see which dates there were more surveys occurring, hope it helps!"
  },
  {
    "objectID": "blog/2024-02-06-environmentalvariables/environmentalvariables.html",
    "href": "blog/2024-02-06-environmentalvariables/environmentalvariables.html",
    "title": "Environmental variables",
    "section": "",
    "text": "This post is to create a map with environmental variables.\n\nIdentify the data you want to download\nDownload data from the server\nCreate a basic map with the values"
  },
  {
    "objectID": "blog/2024-02-06-environmentalvariables/environmentalvariables.html#load-data",
    "href": "blog/2024-02-06-environmentalvariables/environmentalvariables.html#load-data",
    "title": "Environmental variables",
    "section": "Load data",
    "text": "Load data\nLoad the package rerddap\n\nlibrary(\"rerddap\")\n\nCheck the list of available servers.\nFor the example, we are interested in the Pacific Ocean, therefore I would use NOAA.\n\nservers()\n\nI want to download sea surface temperature (SST) data, therefore I will use erdMH1sstdmday\n\nsstInfo <- info('erdMH1sstdmday')\n\nTo check the specifications use browse\n\nbrowse('erdMH1sstdmday') \n\nIt takes some time to download.\n\nSST03.2017<-griddap(sstInfo, latitude = c(ylim1, ylim2), longitude = c(xlim1, xlim2), time = c(time1,time2), fields = 'sst')\n\nTo use ggplot, the format in dataframe works better.\n\nSST03.2017dt<-SST03.2017$data\n\nClear NaNs\n\nlibrary(tidyverse)\n\n\nSST03.2017dt_clean<-SST03.2017dt %>%\n  filter(sst!='NaN')\n\nCreate plot\n\nggplot(SST03.2017dt_clean) +\n geom_raster(aes(x=longitude, y=latitude, fill = sst))+ \n  scale_fill_viridis_c(option = \"H\")"
  },
  {
    "objectID": "blog/2024-02-06-environmentalvariables/environmentalvariables.html#add-land-for-reference",
    "href": "blog/2024-02-06-environmentalvariables/environmentalvariables.html#add-land-for-reference",
    "title": "Environmental variables",
    "section": "Add land for reference",
    "text": "Add land for reference\nLoad the package rworldmap this includes shapefiles of countries\n\nlibrary(rworldmap)\n\nThe function getMap() loads the map in your environment\n\nworldMap <- getMap()\n\nLoad the package tidyverse\nUse the function fortify to be able to plot the map using ggplot\n\nworld.points <- fortify(worldMap)\n\nTo plot using ggplot a data frame is recommended\n\nworld.points$region <- world.points$id\nworld.df <- world.points[,c(\"long\",\"lat\",\"group\", \"region\")]\n\nCreate plot using ggplot\n\nggplot(SST03.2017dt) +\n  geom_tile(aes(x=longitude, y=latitude, fill = sst))+ #geom_raster before\n  geom_polygon(data = world.df, aes(x = long, y = lat, group = group), colour = '#403d39', fill = \"#e5e5e5\") +\n  theme(\n    axis.title = element_blank(),\n    panel.border = element_rect(colour = \"#495057\", fill=NA, size=1),\n    panel.grid = element_blank(), \n    panel.spacing = unit(0, \"lines\"), \n    plot.background = element_blank())+\n    coord_sf(xlim = c(xlim1+2,xlim2-2), \n             ylim = c(ylim1+2,ylim2-2))+ \n  scale_fill_viridis_c(option = \"H\")\n\n\n\n\n\n\n\n\n\nI hope the server did not failed you, sometimes is not working, also welcome geom_tile! I was using geom_raster before, which it works but why not joining the new way?"
  },
  {
    "objectID": "blog/2024-03-11-year-sst/year-sst.html",
    "href": "blog/2024-03-11-year-sst/year-sst.html",
    "title": "Secondary-axis environmental plot",
    "section": "",
    "text": "This post is to create a plot with environmental variables, in one axis the sea surface temperature and in the other axis the chlorophyll-a concentration.\n\nDownload data from the server\nCalculate average values\nCreate a secondary-axis plot with the values"
  },
  {
    "objectID": "blog/2024-03-11-year-sst/year-sst.html#add-legend",
    "href": "blog/2024-03-11-year-sst/year-sst.html#add-legend",
    "title": "Secondary-axis environmental plot",
    "section": "Add legend",
    "text": "Add legend\nUsing annotate the legend would be included inside the plot.\n\nplot_SST_wlegend<-plot_SST+\n  annotate(\"text\", x = c(1.9), y = c(34), label = c(\"SST\") , color=\"black\", size=5)+ \n  annotate(\"segment\", x = 1.0, xend = 1.4, y = 34, yend = 34, colour = \"red\", size=1, alpha=1)+\n  \n  annotate(\"text\", x = c(1.9), y = c(32), label = c(\"CHL\") , color=\"black\", size=5)+ \n  annotate(\"segment\", x = 1.0, xend = 1.4, y = 32, yend = 32, colour = \"blue\", size=1, alpha=1)+\n  NULL\nplot_SST_wlegend"
  },
  {
    "objectID": "blog/2024-04-04-buffer/buffer.html",
    "href": "blog/2024-04-04-buffer/buffer.html",
    "title": "Create a buffer",
    "section": "",
    "text": "In this blog, a buffer subsetting environmental data would be created and the average values within the buffer calculated."
  },
  {
    "objectID": "blog/2024-04-04-buffer/buffer.html#map",
    "href": "blog/2024-04-04-buffer/buffer.html#map",
    "title": "Create a buffer",
    "section": "Map",
    "text": "Map\nCheck data downloaded using ggplot.\n\nlibrary(ggplot2)\n\nDownload data from land from the package rworldmap.\n\nlibrary(rworldmap)\n\nThe function getMap() loads the map in your environment.\n\nworld_map <- getMap()\n\nTo plot using ggplot a data frame is recommended. Use the function fortify to be able to get the data in a data frame format.\n\nworld_points <- fortify(world_map)\nworld_points$region <- world_points$id\nworld_df <-world_points[,c(\"long\",\"lat\",\"group\", \"region\")]\n\n\nggplot() +\n geom_raster(data=SST_dfclean,aes(x=longitude, y=latitude, fill = sst))+ scale_fill_viridis_c(option = \"H\")+\n geom_polygon(data = world_df, aes(x = long, y = lat, group = group), colour = '#403d39', fill = \"#e5e5e5\") +\n coord_sf(xlim = c(-109.7,-109.1),ylim = c(24.6,25.2))"
  },
  {
    "objectID": "blog/2024-04-04-buffer/buffer.html#map-1",
    "href": "blog/2024-04-04-buffer/buffer.html#map-1",
    "title": "Create a buffer",
    "section": "Map",
    "text": "Map\nUse ggplot to create the map.\nUse the functions geom_raster to plot the SST data.\nThe function geom_polygon to plot the base maps data.\nThe function geom_polygon to plot the buffer.\nAdjust to your corresponding area on the coord_sf.\n\nggplot() +\n geom_raster(data=SST_dfclean,aes(x=longitude, y=latitude, fill = sst))+ scale_fill_viridis_c(option = \"H\")+\n geom_polygon(data = world_df, aes(x = long, y = lat, group = group), colour = '#403d39', fill = \"#e5e5e5\") +\n geom_sf(data = This_buffer, \n          color = \"black\", \n          fill = NA,  # equivalent to 'transparent'\n          linetype = \"dashed\")+\n geom_point(data=This_point, aes(x=Longitude, y=Latitude), colour = \"black\", size = 4)+\n coord_sf(xlim = c(-109.7,-109.1),ylim = c(24.6,25.2))"
  },
  {
    "objectID": "blog/2024-04-04-buffer/buffer.html#subset",
    "href": "blog/2024-04-04-buffer/buffer.html#subset",
    "title": "Create a buffer",
    "section": "Subset",
    "text": "Subset\nTo plot the SST data, select the information from the new data frame SST_inside and the function geom_raster to plot the information.\n\nggplot() +\n  geom_raster(data=SST_inside,aes(x=longitude, y=latitude, fill = sst))+ scale_fill_viridis_c(option = \"H\")+\n  geom_polygon(data = world_df, aes(x = long, y = lat, group = group), colour = '#403d39', fill = \"#e5e5e5\") +\n  \n  geom_sf(data = This_buffer, \n          color = \"black\", \n          fill = NA,  # equivalent to 'transparent'\n          linetype = \"dashed\")+\n  geom_point(data=This_point, aes(x=Longitude, y=Latitude), colour = \"black\", size = 4)+\n  theme(panel.background = element_blank(),\n        panel.border = element_rect(colour = \"black\", fill='transparent'))+\n  coord_sf(xlim = c(-109.7,-109.1),ylim = c(24.6,25.2))+ \n  NULL"
  },
  {
    "objectID": "blog/2024-04-04-buffer/buffer.html#calculate-mean-and-sd",
    "href": "blog/2024-04-04-buffer/buffer.html#calculate-mean-and-sd",
    "title": "Create a buffer",
    "section": "Calculate mean and sd",
    "text": "Calculate mean and sd\nUse the values inside the buffer to calculate the average SST.\n\nmean(SST_inside$sst)\nsd(SST_inside$sst)\n\n\n\n\nMean 20.61 and sd 1.65, well done!"
  },
  {
    "objectID": "blog/2024-05-02-imagesforpublication/imagesforpublication.html",
    "href": "blog/2024-05-02-imagesforpublication/imagesforpublication.html",
    "title": "Using magick for image manipulation",
    "section": "",
    "text": "This post is to read and edit images in R.\nUsing R assures that your image would not be compress as happens when you open it with some other programs.\nThe blog consist of two parts:\n1. Add letter to a picture and export\n2. Merge two pictures into one and export\n\n\n\n\nUse the package magick to process images in R.\nFor more information: https://docs.ropensci.org/magick/articles/intro.html#read-and-write\nTo install the package\n\ninstall.packages(\"magick\")\n\nTo call the package\n\nlibrary(magick)\n\nWarning: package 'magick' was built under R version 4.4.3\n\n\nLinking to ImageMagick 6.9.12.98\nEnabled features: cairo, freetype, fftw, ghostscript, heic, lcms, pango, raw, rsvg, webp\nDisabled features: fontconfig, x11\n\n\n\n\n\nSelect your directory. In the example, as My_directory.\n\nlibrary(here)\nMy_directory<-here()\n\n\n\n\nCheck if you gave the correct path by using the function list.files.\nIt should show the images you want to use.\nRead images using the function image_read.\n\nFig1_original<- image_read(Fig1_link)\n\nThe function image_draw will show the picture in the Viewer.\nMoreover, it gives information on the width and height of the picture.\n\nFig1_draw<-image_draw(Fig1_original)\nFig1_draw\n\n\n\n\n\nTo add text use the function image_annotate\nTo add the text in the right bottom use the information from the dimensions above to define the xaxis and yaxis.\n\nFig1_text<-image_annotate(Fig1_draw, \"(a)\",  location = \"+1199+999\", font = 'Arial', size = 100, color='white')\n\n\n\nhere() starts at C:/Users/lerma/OneDrive/Documents/03Academico/02Proyectos-Postdoc/2025/1Programming/1Quarto/quarto_webpage\n\n\n\n\n\n\n\n\nTo add the text in the left top part you can use define the xaxis and yaxis as 100.\n\nFig1_text<-image_annotate(Fig1_draw, \"(a)\",  location = \"+50+50\", font = 'Arial', size = 100, color='white')\n\n\n\n\n\n\n\n\n\n\nUse the function image_write to export.\n\nimage_write(Fig1_text, path = paste0(My_directory,\"/Fig1_tl.png\"), format = \"png\")"
  },
  {
    "objectID": "blog/2024-05-02-imagesforpublication/imagesforpublication.html#add-border",
    "href": "blog/2024-05-02-imagesforpublication/imagesforpublication.html#add-border",
    "title": "Using magick for image manipulation",
    "section": "Add border",
    "text": "Add border\nUse the function image_border to add some space between the pictures.\n\nFig1_border<-image_border(image_background(Fig1_text, \"transparent\"), \"white\", \"40x10\")\nFig1_border\n\n\nFig2_border<-image_border(image_background(Fig2_text, \"transparent\"), \"white\", \"40x10\")\nFig2_border"
  },
  {
    "objectID": "blog/2024-05-02-imagesforpublication/imagesforpublication.html#combine",
    "href": "blog/2024-05-02-imagesforpublication/imagesforpublication.html#combine",
    "title": "Using magick for image manipulation",
    "section": "Combine",
    "text": "Combine\nUse the function image_append to have both pictures side by side.\n\nimage_append(c(Fig1_border,Fig2_border))"
  },
  {
    "objectID": "blog/2024-05-02-imagesforpublication/imagesforpublication.html#export-1",
    "href": "blog/2024-05-02-imagesforpublication/imagesforpublication.html#export-1",
    "title": "Using magick for image manipulation",
    "section": "Export",
    "text": "Export\nUse the function image_write to export the picture.\n\n\n\n\nimage_write(image_append(c(Fig1_border,Fig2_border)), path = paste0(My_directory,\"/Fig1_append.png\"), format = \"png\")"
  },
  {
    "objectID": "blog/2024-06-04-pointsdistance/pointsdistance.html",
    "href": "blog/2024-06-04-pointsdistance/pointsdistance.html",
    "title": "Distance from point",
    "section": "",
    "text": "This post is about how to calculate distance from a point"
  },
  {
    "objectID": "blog/2024-06-04-pointsdistance/pointsdistance.html#plot-with-curves",
    "href": "blog/2024-06-04-pointsdistance/pointsdistance.html#plot-with-curves",
    "title": "Distance from point",
    "section": "Plot with curves",
    "text": "Plot with curves\nAdd the reference point to be able to plot\n\ncolonies_sub$reference_long<-reference$lon\ncolonies_sub$reference_lat<-reference$lat\n\nUse the function geom_curve to create lines between the reference point and the other points.\n\ncurves_plot<-base_plot+\n  geom_curve(data= subset(colonies_sub,colonies_sub$name != 'Helgoland'),\n             aes(x = reference_long, y = reference_lat, \n                 xend = colony_long, yend = colony_lat),  \n                 color = '#faa307',\n                 curvature = 0.05, alpha = 0.5)\ncurves_plot\n\nAdd the other points using geom_point\n\npoints_plot<-curves_plot+\n  geom_point(data=colonies_sub,\n             aes(x = colony_long,y= colony_lat), \n             color='#faa307', fill='#ffba08',shape=16,size=2,stroke=1.5)+\n  \n    geom_point(data=reference,\n             aes(x = long,y= lat), \n             color='#ff5400', fill='#ff5400',shape=16,size=4,stroke=1.5)\npoints_plot\n\n\nletters_plot<-points_plot+\n  annotate(\"text\", y = 54.15-0.21, x = -0.17+2.5, \n           label = \"Bempton Cliff \\n (525 km)\",\n           size=3.5,color='#0d3b66')+\n  annotate(\"text\", y = 56.08-0.21, x = -2.64+2.5, \n           label = \"Bass Rock \\n (701 km)\",\n           size=3.5,color='#0d3b66')+\n  annotate(\"text\", y = 57.69-0.21, x = -2.29+2.0, \n           label = \"Troup Head \\n (523 km)\",\n           size=3.5,color='#0d3b66')+\n  annotate(\"text\", y = 54.18-0.21, x = 7.89-1.9, \n           label = \"Helgoland \\n\",\n           size=3.5,color='red')+\nNULL\nletters_plot"
  },
  {
    "objectID": "blog/2024-07-05-interpolate/interpolate.html",
    "href": "blog/2024-07-05-interpolate/interpolate.html",
    "title": "Interpolate a path",
    "section": "",
    "text": "This post is about how to linear interpolate points from a trip"
  },
  {
    "objectID": "blog/2024-07-05-interpolate/interpolate.html#interpolate-to-1-minute",
    "href": "blog/2024-07-05-interpolate/interpolate.html#interpolate-to-1-minute",
    "title": "Interpolate a path",
    "section": "Interpolate to 1 minute",
    "text": "Interpolate to 1 minute\n\nID01_interpolated1m<-interpolate_trips(GPS_data=ID01_track,\n                                     interval='60 sec',\n                                     column_date='DateGMT',\n                                     column_time='TimeGMT',\n                                     column_trip='trip_number',\n                                     column_lat='Latitude',\n                                     column_lon='Longitude',\n                                     datetime_format<-\"%d/%m/%Y %H:%M:%S\")\n\nYou can see that after the function you have more data points.\nThis is because the original data was collected every 5 minutes, and the interpolation added locations every one minute.\n\nnrow(ID01_track)\nnrow(ID01_interpolated1m)\n\nPlot the interpolated data set to see the difference.\n\nInterpolated_1m<-ggplot(ID01_interpolated1m, aes(x=Longitude, y=Latitude, color=trip_number)) + \n  geom_point()+\n  ggtitle('Interpolated to 1 min')+\n  theme_bw()+\n  theme(legend.position='none')+\n  scale_x_continuous(labels = function(x) paste0(-x, '\\u00B0')) +\n  scale_y_continuous(labels = function(x) paste0(-x, '\\u00B0'))  +\n  xlab('Longitude')+ylab('Latitude')+\n  theme(\n    panel.background = element_rect(fill = '#edf2f4'),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),legend.position='none',\n    panel.border = element_rect(colour = \"black\", fill=NA, size=1.5)\n  )+\n  geom_point(data=ID01_nest,aes(x = Longitude,y= Latitude), \n             color=\"black\", fill=\"black\",shape=16,size=5,stroke=1.5)\nInterpolated_1m"
  },
  {
    "objectID": "blog/2024-07-05-interpolate/interpolate.html#interpolate-to-15-minutes",
    "href": "blog/2024-07-05-interpolate/interpolate.html#interpolate-to-15-minutes",
    "title": "Interpolate a path",
    "section": "Interpolate to 15 minutes",
    "text": "Interpolate to 15 minutes\nTo interpolate to 15 minutes, change the interval to 900 sec.\n\nID01_interpolated15m<-interpolate_trips(GPS_data=ID01_track,\n                                     column_trip='trip_number',\n                                     column_lat='Latitude',\n                                     column_lon='Longitude',\n                                     column_date='DateGMT',\n                                     column_time='TimeGMT',\n                                     datetime_format<-\"%d/%m/%Y %H:%M:%S\",\n                                     interval='900 sec')\n\nYou can see that after the function you have less data points.\nThis is because the original data was collected every 5 minutes, and the interpolation added locations every 15 minutes.\n\nnrow(ID01_track)\nnrow(ID01_interpolated15m)\n\nPlot to see the difference.\n\nInterpolated_15m<-ggplot(ID01_interpolated15m, aes(x=Longitude, y=Latitude, color=trip_number)) + \n  geom_point()+\n  theme_bw()+\n  ggtitle('Interpolated to 15 mins')+\n  theme_bw()+\n  theme(legend.position='none')+\n  scale_x_continuous(labels = function(x) paste0(-x, '\\u00B0')) +\n  scale_y_continuous(labels = function(x) paste0(-x, '\\u00B0'))  +\n  xlab('Longitude')+ylab('Latitude')+\n  theme(\n    panel.background = element_rect(fill = '#edf2f4'),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),legend.position='none',\n    panel.border = element_rect(colour = \"black\", fill=NA, size=1.5)\n  )+\n  geom_point(data=ID01_nest,aes(x = Longitude,y= Latitude), \n             color=\"black\", fill=\"black\",shape=16,size=5,stroke=1.5)\nInterpolated_15m"
  },
  {
    "objectID": "blog/2024-08-01-removelocs/removelocs.html",
    "href": "blog/2024-08-01-removelocs/removelocs.html",
    "title": "Remove undesired locations",
    "section": "",
    "text": "Intro\nWhen studying animals using GPSs, we often need to remove their central location. Here, I am sharing a function I created to eliminate all the locations within an area.\n\n\nData\nFor the exercises, test data is from masked boobies.  To access the data you have to install the package sula: devtools::install_github(‚ÄúMiriamLL/sula‚Äù)\n\n#devtools::install_github(\"MiriamLL/sula\")\nlibrary(sula)\n\nThis data frame contains data from 10 individuals.\n\nunique(sula::GPS_raw$IDs)\n\nTo load it into the environment.\n\nGPS_ten<-GPS_raw\n\nPlot your data\n\nlibrary(tidyverse)\n\nHere you can see all the recorded locations using the GPSs.\n\nOriginal_plot<-ggplot()+\n  geom_point(data = GPS_ten,\n            aes(x=Longitude,y = Latitude),color='red', size=0.5)+\n  scale_x_continuous(labels = function(x) paste0(-x, '\\u00B0')) +\n  scale_y_continuous(labels = function(x) paste0(-x, '\\u00B0'))  +\n  xlab('Longitude')+ylab('Latitude')+\n  theme(\n    panel.background = element_rect(fill = '#edf2f4'),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),legend.position='none',\n    panel.border = element_rect(colour = \"black\", fill=NA, size=1.5)\n  )\nOriginal_plot\n\n\n\nCreate a buffer\nSelect a location\n\nThis_point<-data.frame(Longitude=-109.5,Latitude=-27.2)\n\nCreate a buffer\nI created this function to create a buffer around a point\n\ncreate_buffer<-function(central_point=central_point, buffer_km=buffer_km){\n  central_spatial<- sp::SpatialPoints(cbind(central_point$Longitude,central_point$Latitude)) \n  sp::proj4string(central_spatial)= sp::CRS(\"+init=epsg:4326\") \n  central_spatial <- sp::spTransform(central_spatial, sp::CRS(\"+init=epsg:4326\"))\n  central_spatial<-sf::st_as_sf(central_spatial)\n  buffer_dist<-buffer_km*1000\n  central_buffer<-sf::st_buffer(central_spatial, buffer_dist)\n  return(central_buffer)\n  }\n\n\n\n\nThe parameters to give are the kilometers and the central point\n\nThis_buffer<-create_buffer(central_point=This_point,buffer_km=20)\n\n\nclass(This_buffer)\n\nHere you can see the buffer you created using the point (or central location)\n\nBuffer_plot<-ggplot()+\n  geom_point(data = GPS_ten,\n            aes(x=Longitude,y = Latitude),color='red',size=0.5)+\n  geom_point(data=This_point,\n             aes(x=Longitude,y=Latitude),color='blue')+\n  geom_sf(data=This_buffer,colour='blue', fill='transparent', linetype='dashed')+\n  scale_x_continuous(labels = function(x) paste0(-x, '\\u00B0')) +\n  scale_y_continuous(labels = function(x) paste0(-x, '\\u00B0'))  +\n  xlab('Longitude')+ylab('Latitude')+\n  theme(\n    panel.background = element_rect(fill = '#edf2f4'),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),legend.position='none',\n    panel.border = element_rect(colour = \"black\", fill=NA, size=1.5)\n  )\nBuffer_plot\n\nUsing the function from the package sp you can create an spatial object using your GPS data\n\nGPS_sp <- GPS_ten\nsp::coordinates(GPS_sp) <- ~Longitude + Latitude\nsp::proj4string(GPS_sp) = sp::CRS(\"+init=epsg:4326\")\nGPS_sp<-sf::st_as_sf(GPS_sp)\n\n\nclass(GPS_sp)\nclass(This_buffer)\n\nHere the function over identifies which location intersect with the buffer.\n\nGPS_over<-sapply(sf::st_intersects(GPS_sp,This_buffer), function(z) if (length(z)==0) NA_integer_ else z[1])\n\nThis information can be added as a column in the data frame.\n\nGPS_ten$In_or_out <- as.numeric(GPS_over)\n\nTo remove the locations that were within the buffer you can use the function filter and is.na from the package tidyverse\n\nGPS_without <- GPS_ten %>%\n  filter(is.na(In_or_out)==TRUE)\n\nHere you can see that the locations inside the buffer were removed.\n\nFiltered_plot<-ggplot()+\n  geom_point(data = GPS_without,\n            aes(x=Longitude,y = Latitude),color='red',size=0.5)+\n  geom_point(data=This_point,\n             aes(x=Longitude,y=Latitude),color='blue')+\n  geom_sf(data=This_buffer,colour='blue', fill='transparent', linetype='dashed')+\n  scale_x_continuous(labels = function(x) paste0(-x, '\\u00B0')) +\n  scale_y_continuous(labels = function(x) paste0(-x, '\\u00B0'))  +\n  xlab('Longitude')+ylab('Latitude')+\n  theme(\n    panel.background = element_rect(fill = '#edf2f4'),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),legend.position='none',\n    panel.border = element_rect(colour = \"black\", fill=NA, size=1.5)\n  )\nFiltered_plot\n\nThis function can be used to remove all the nest locations within a distance buffer. You could also replace the polygon (here the buffer) for some land shapefiles.\n\n\nCompare\nUsing the package patchwork we can see the difference side by side.\n\nlibrary(patchwork)\n\n\nOriginal_plot+Buffer_plot+Filtered_plot\n\n\n\n\n\n\n\n\n\n\n\nFurther reading\nOther functions that did the job:\ngBuffer from rgeos deprecated\nRead more about package sf"
  },
  {
    "objectID": "blog/2024-09-19-identifyevents/identifyevents.html",
    "href": "blog/2024-09-19-identifyevents/identifyevents.html",
    "title": "Identify events",
    "section": "",
    "text": "Intro\nThis post shows an option to assign a trip number to locations of animals.\nThis same method could be use to identify events on spatial data.\n\n\nData\nFor the exercises, test data is from Masked boobies. \n\n#devtools::install_github(\"MiriamLL/sula\")\nlibrary(sula)\n\nThis data frame contains data from 10 individuals.\n\nunique(sula::GPS_raw$IDs)\n\nUsing functions from the package tidyverse, one of the individuals can be selected.\n\nlibrary(tidyverse)\n\n\nGPS_one<-GPS_raw %>% filter(IDs=='GPS08')\n\nThe original data can be checked using functions from the package ggplot2.\n\nlibrary(ggplot2)\n\nIn the plot all locations are presented, but events can not be identify yet.\n\nPlot_original<-ggplot(GPS_one, aes(x=Longitude, y=Latitude)) + \n  geom_point()+\n  scale_x_continuous(labels = function(x) paste0(-x, '\\u00B0')) +\n  scale_y_continuous(labels = function(x) paste0(-x, '\\u00B0'))  +\n  ggtitle('Tracking data')+xlab('Longitude')+ylab('Latitude')+\n  theme_bw()+\n  theme(\n    legend.position='none',\n    panel.background = element_rect(fill = '#edf2f4'),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.border = element_rect(colour = \"black\", fill=NA, size=1.5))\nPlot_original\n\n\n\nRemove central locations\nAn event would be defined as each time the animal leaves its central location.\nThe information about the central location is needed.\n\nCentral_location<-data.frame(Longitude=-109.4531, Latitude=-27.20097)\n\nThe locations are to be transform into spatial data.\n\nGPS_spatial <- GPS_one\nsp::coordinates(GPS_spatial) <- ~Longitude + Latitude\nsp::proj4string(GPS_spatial) = sp::CRS(\"+init=epsg:4326\")\nGPS_spatial<-sf::st_as_sf(GPS_spatial)\n\nThe buffer function is explained in the previous post.\nThe function uses the central location to create a buffer.\nA number ‚Äú1‚Äù shows that the location is inside the 1 km buffer and an NA that is outside the buffer.\nThe information is added on a column in the data frame.\n\ncreate_buffer<-function(central_point=central_point, buffer_km=buffer_km){\n  central_spatial<- sp::SpatialPoints(cbind(central_point$Longitude,central_point$Latitude)) \n  sp::proj4string(central_spatial)= sp::CRS(\"+init=epsg:4326\") \n  central_spatial <- sp::spTransform(central_spatial, sp::CRS(\"+init=epsg:4326\"))\n  central_spatial<-sf::st_as_sf(central_spatial)\n  buffer_dist<-buffer_km*1000\n  central_buffer<-sf::st_buffer(central_spatial, buffer_dist)\n  return(central_buffer)\n  }\nThis_buffer<-create_buffer(central_point=Central_location,buffer_km=1)\nGPS_over<-sapply(sf::st_intersects(GPS_spatial,This_buffer), function(z) if (length(z)==0) NA_integer_ else z[1])\nGPS_one$trip <- as.numeric(GPS_over)\n\nThe NAs (when the animal is outside the buffer) can be replaced for a 0.\nThis is not strictly necessary but facilitates the interpretation of the column.\n\nGPS_one$trip[is.na(GPS_one$trip)] <- 0\n\nAlternatively, text can be added.\n\nGPS_one$trip <- gsub(\"1\", \"At_central_locations\", GPS_one$trip)\nGPS_one$trip <- gsub(\"0\", \"At_trip\", GPS_one$trip)\n\n\n\nAssign trip number\nTo assign the trip number, the first step was adding a new column with a sequential number.\n\nGPS_one$sequential_number<-as.integer(paste(seq(1:as.numeric(nrow(GPS_one)))))\n\nAfterwards, all the locations inside the central locations were removed.\n\nGPS_trips<-subset(GPS_one, GPS_one$trip == \"At_trip\")\n\nBy removing the locations inside the central locations, we end up with gaps in the sequence number.\nHere, I added a number of event everytime that the sequence was broken.\n\nGPS_trips$trip_number <- (cumsum(c(1L, diff(GPS_trips$sequential_number)) != 1L))+ 1\n\nIn case there might be more than ten trips, adding more zeros using the function str_pad might be useful.\n\nGPS_trips$trip_number <- stringr::str_pad(GPS_trips$trip_number ,  2, pad = \"0\")\n\nFor easier interpretation, text can be added.\n\nGPS_trips$trip_number<-paste0(\"Trip_\", GPS_trips$trip_number )\n\nUsing the function unique the number of events (or trips) can be checked.\n\nunique(GPS_trips$trip_number)\n\n\n\nPlot\nThe different events can now be easily observed by adding the argument color=trip_number in the plot.\n\nPlot_trips<-ggplot(GPS_trips, aes(x=Longitude, y=Latitude, color=trip_number)) + \n  geom_point()+\n  geom_point(data=Central_location,aes(x = Longitude,y= Latitude), \n             color=\"black\", fill=\"black\",shape=16,size=5,stroke=1.5)+\n  theme_bw()+\n  scale_x_continuous(limits=c(-109.7,-108.9),labels = function(x) paste0(-x, '\\u00B0')) +\n  scale_y_continuous(labels = function(x) paste0(-x, '\\u00B0'))  +\n  ggtitle('Trip number')+xlab('Longitude')+ylab('Latitude')+labs(color='')+\n  theme(\n    panel.background = element_rect(fill = '#edf2f4'),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.border = element_rect(colour = \"black\", fill=NA, size=1.5),\n    legend.background = element_rect(colour = \"transparent\", fill = \"transparent\"),\n    legend.position = c(0.12,0.75))\nPlot_trips\n\n\n\n\n\n\n\n\n\n\n\nFurther reading\nFunctions count_trips from the package sula can be used to run loops."
  },
  {
    "objectID": "blog/2024-10-08-distancepoints/distancepoints.html",
    "href": "blog/2024-10-08-distancepoints/distancepoints.html",
    "title": "Distance between consecutive points",
    "section": "",
    "text": "Calculate distance between points between consecutive locations.\nOne of the uses in animal movements it to calculate how much distance an animal covers on one trip."
  },
  {
    "objectID": "blog/2024-10-08-distancepoints/distancepoints.html#further-reading",
    "href": "blog/2024-10-08-distancepoints/distancepoints.html#further-reading",
    "title": "Distance between consecutive points",
    "section": "Further reading",
    "text": "Further reading\nThe function dist_points from the package sula runs this function in loop.\nThis helps when there are more than one trip and several individuals."
  },
  {
    "objectID": "blog/2024-11-05-completeorincomplete/completeorincomplete.html",
    "href": "blog/2024-11-05-completeorincomplete/completeorincomplete.html",
    "title": "Complete or incomplete trips",
    "section": "",
    "text": "Intro\nWhen tracking animals, there may be times when they enter areas with no reception.\nIf a large part of a trip takes place in such areas, you should consider whether to include this data in your calculations.\nFor instance, long gaps could lead to an underestimation of the actual distance traveled by the animal.\nIn this post, I‚Äôll walk you through the steps I used to determine whether trips are complete or incomplete.\nThis post has three parts:\n- Create a gap\n- Calculate gaps\n- Identify if our trips are complete or incomplete\n\n\nData\nFor the exercises, test data is from masked boobies.  To access the data you have to install the package sula: devtools::install_github(‚ÄúMiriamLL/sula‚Äù)\n\nlibrary(sula)\n\nUse the function select from tidyverse to keep the columns ID, latitude, longitude, date, time, and trip number.\n\nlibrary(tidyverse)\nData_1original<-GPS_preparado %>% select(IDs,Latitude,Longitude,DateGMT,TimeGMT,trip_number)\n\n\n\nCreating a gap\nIn this part we would eliminate some locations to create an artificial gap\n\nlibrary(sf)\n\nSelect a location with ‚Äúlow reception‚Äù and remove all the locations to create the gaps\n\nThis_area<-data.frame(Longitude=-109.4,Latitude=-27.6)\n\ncreate_buffer<-function(central_point=central_point, buffer_km=buffer_km){\n  central_spatial<- sp::SpatialPoints(cbind(central_point$Longitude,central_point$Latitude)) \n  sp::proj4string(central_spatial)= sp::CRS(\"+init=epsg:4326\") \n  central_spatial <- sp::spTransform(central_spatial, sp::CRS(\"+init=epsg:4326\"))\n  central_spatial<-sf::st_as_sf(central_spatial)\n  buffer_dist<-buffer_km*1000\n  central_buffer<-sf::st_buffer(central_spatial, buffer_dist)\n  return(central_buffer)\n}\n\nThis_buffer<-create_buffer(central_point=This_area,buffer_km=20)\n\nData_2spatial <- Data_1original\nsp::coordinates(Data_2spatial) <- ~Longitude + Latitude\nsp::proj4string(Data_2spatial) = sp::CRS(\"+init=epsg:4326\")\nData_2spatial <-sf::st_as_sf(Data_2spatial)\nData_3creategap<-sapply(sf::st_intersects(Data_2spatial ,This_buffer), function(z) if (length(z)==0) NA_integer_ else z[1])\nData_1original$trip <- as.numeric(Data_3creategap)\nData_4withgap <- Data_1original %>%\n  filter(is.na(trip)==TRUE)\n\nPlot the area with low reception\n\nPlot_locations<-ggplot()+\n  geom_point(data = Data_4withgap,aes(x=Longitude,y = Latitude),color=\"#6a994e\",size=0.5)+\n  scale_x_continuous(labels = function(x) paste0(-x, '\\u00B0')) +\n  scale_y_continuous(labels = function(x) paste0(-x, '\\u00B0'))  +\n  xlab('Longitude')+ylab('Latitude')+\n  theme(\n    panel.background = element_rect(fill = '#edf2f4'),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),legend.position='none',\n    panel.border = element_rect(colour = \"black\", fill=NA, size=1.5))+\n  geom_sf(data=This_buffer,colour='blue', fill='transparent', linetype='dashed')+\n  geom_text(data=This_area, aes(x=Longitude,y=Latitude,label=\"No reception\"),hjust=+0.46, vjust=0, size=3)\nPlot_locations\n\n\n\nCalculate gaps\nA column in the format POSIXct is needed for this example.\n\nData_4withgap <- Data_4withgap %>%\n  mutate(dt= as.POSIXct(strptime(paste0(DateGMT,\" \",TimeGMT), format=\"%d/%m/%Y %H:%M:%S\")))\n\nChecking gaps in time on one individual trip.\n\nData_5oneindividual<-Data_4withgap %>% filter(IDs=='GPS09') %>% filter(trip_number=='trip_2')\n\n\nData_5oneindividual<-Data_5oneindividual %>%\n  mutate(times_lag=lag(dt))%>%\n  mutate(time_dif=as.numeric(difftime(dt, times_lag, units = \"mins\")))%>%\n  mutate(time_dif_mins = round(time_dif,2))\n\nThis trip has a large gap: 4 - 57.70.\n\nrange(Data_5oneindividual$time_dif_mins,na.rm=TRUE)\n\nCreate a loop to calculate gaps separated by individuals and trips.\n\ncalculate_gaps<-function (this_data = this_data, \n                          column_datetime = column_datetime, \n                          column_separator = column_separator){\n  # to standardize the column names\n  this_data$column_separator<- this_data[[column_separator]]\n  this_data$column_datetime <- this_data[[column_datetime]]\n  trips_list <- split(this_data, this_data$column_separator)\n    gaps_list <- list()\n    for (i in seq_along(trips_list)) {\n        trip_df <- trips_list[[i]]\n        trip_df<-trip_df %>%\n          mutate(times_lag=lag(dt))%>%\n          mutate(time_dif=as.numeric(difftime(dt, times_lag, units = \"mins\")))%>%\n          mutate(time_dif_mins = round(time_dif,2))\n        gaps_list[[i]] <- trip_df}\n    gaps_df <- do.call(\"rbind\", gaps_list)\n    return(gaps_df)\n}\n\nFor this, would help to have an unique ID, which helps separate the individual and their trips.\n\nData_5uniqueIds <- Data_4withgap %>%\n  mutate(unique_id=paste0(IDs,'_',trip_number))\n\nTo run the function, provide the data frame, the information for separating, and the name of the column where the date and time are provided.\n\nData_6uniqueIds<-calculate_gaps(this_data=Data_5uniqueIds,\n                                column_separator='unique_id',\n                                column_datetime='dt')\n\n\n\nComplete or incomplete\nBy using the function summarise, we can see which trips have large gaps.\n\nData_7gaps<-Data_6uniqueIds %>%\n  group_by(unique_id)%>%\n  summarise(min_gap=min(time_dif_mins,na.rm = TRUE),\n            max_gap=max(time_dif_mins,na.rm = TRUE))\n\nBased on the gaps during the trips, the trips could be classified as complete or incomplete.\nFor example, here an incomplete trip would be any trip that had a gap of more than 30 minutes.\n\nData_7gaps <- Data_7gaps%>%\n  mutate(trip_class = case_when(max_gap <= 30 ~ 'Complete',\n                                TRUE ~ 'Incomplete'))\n\nUse this table to identify those trips that were incomplete.\n\nunique_incomplete<-unique((subset(Data_7gaps,Data_7gaps$trip_class=='Incomplete')$unique_id))\n\nUse the information above, to add the classification on the tracking locations.\n\nData_8gaps <- Data_6uniqueIds %>%\n  mutate(trip_class = case_when(unique_id %in% unique_incomplete ~ 'Incomplete',\n                                TRUE ~ 'Complete'))\n\nPlot incomplete trips.\n\nPlot_trips<-ggplot()+\n  geom_point(data = Data_8gaps,aes(x=Longitude,y = Latitude,color=trip_class),size=0.5)+\n  scale_x_continuous(labels = function(x) paste0(-x, '\\u00B0')) +\n  scale_y_continuous(labels = function(x) paste0(-x, '\\u00B0'))  +\n  xlab('Longitude')+ylab('Latitude')+\n  theme(\n    panel.background = element_rect(fill = '#edf2f4'),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),legend.position='none',\n    panel.border = element_rect(colour = \"black\", fill=NA, size=1.5)\n  )+\n  geom_sf(data=This_buffer,colour='blue', fill='transparent', linetype='dashed')+\n  geom_text(data=This_area, aes(x=Longitude,y=Latitude,label=\"No reception\"),hjust=+0.46, vjust=0, size=3)+\n  theme(\n    legend.background = element_rect(colour = \"transparent\", fill = \"transparent\"),\n    legend.position.inside = c(0.22,0.15))+\n  scale_colour_manual(name='trip',values = c(\"#6a994e\", \"#fca311\"))+ \n  guides(color = guide_legend(override.aes = list(size = 2)))\nPlot_trips\n\n\n\n\n\n\n\n\n\n\n\nFurther reading\nAnother way to check for gaps, using only time in this post."
  },
  {
    "objectID": "blog/2024-12-02-tmap/tmap.html",
    "href": "blog/2024-12-02-tmap/tmap.html",
    "title": "tmap",
    "section": "",
    "text": "When analyzing tracking data in R, you may want to explore the locations. One option is to export the cleaned data set and open it a GIS program. However, R also offers interactive mapping features. In this post, I‚Äôll walk you through the steps I used to create interactive maps with my GPS data."
  },
  {
    "objectID": "blog/2024-12-02-tmap/tmap.html#transform",
    "href": "blog/2024-12-02-tmap/tmap.html#transform",
    "title": "tmap",
    "section": "Transform",
    "text": "Transform\nThe function fortify helps the data frame to be more easily be plotted.\n\nlibrary(tidyverse)\n\n\nData_2fortify<-fortify(Data_1original)\n\nMake sure your lat and lon are numerical\n\nData_2fortify$lat<-as.numeric(Data_2fortify$Latitude)\nData_2fortify$lon<-as.numeric(Data_2fortify$Longitude)\n\nTransform to spatial.\n\nlibrary(sf)\n\nSelect which CRS you will like to use.\n\nData_3spatial <- st_as_sf(Data_2fortify, coords = c(\"lon\", \"lat\"),crs = 4326, agr = \"constant\")\n\nSelect the columns that are of interest.\n\nData_4info<-Data_3spatial[,c(\"IDs\",\"trip_number\",\"dia_hora\")]"
  },
  {
    "objectID": "blog/2025-01-15-bathymetry/bathymetry.html",
    "href": "blog/2025-01-15-bathymetry/bathymetry.html",
    "title": "Bathymetry",
    "section": "",
    "text": "Intro\nBathymetry gives us information on the water depth around an area.\nThis post includes:\n- Download raster data\n- Read and subset raster data\n- Plot raster data\n\n\nDownload raster data\nGEBCO: General Bathymetry Chart of the Oceans provides information from bathymetry in the ocean.\nTo download visit webpage\nGo to:\n- Download data for user-defined areas\n- Use the application\n- Add your coordinates -here I use 1 to 10 and 50 to 60-\n- Add to basket and download\n\n\nLoad\nTo download test data in tif format click here.\nSelect the directory where the information is stored, or as here, use the data directly form the repository.\n\nBath_tif<-'https://github.com/MiriamLL/data_supporting_webpage/raw/refs/heads/main/Blog/2025/Bathymetry/gebco_2024_n60.0_s50.0_w1.0_e9.0.tif'\n\nLoad the terra package for reading raster data\n\nlibrary(terra)\n\nThe function rast helps to read raster data - replacing package raster\n\nBath_file<-rast(Bath_tif)\n\nChange to data frame\n\nBath_dataframe <- as.data.frame(Bath_file, xy = TRUE)\n\nAlternatively, use the test information included in the package GermanNorthSea\n\n##devtools::install_github(\"MiriamLL/GermanNorthSea\")\nlibrary(GermanNorthSea)\n\n\nBath_dataframe<-GermanNorthSea::German_bath\n\nLoad the package tidyverse\n\nlibrary(tidyverse)\n\nUse filter to subset your data\n\nBath_dataframe_sub <-Bath_dataframe  %>%\n  filter(x > 2 & x < 10)%>%\n  filter(y > 52 & y < 57)%>%\n  rename(Bathymetry=3) %>%\n  filter(Bathymetry < 10)\n\n\n\nPlot\nLoad the package ggplot2\n\nlibrary(ggplot2)\n\nPlot your data using geom_raster\n\nggplot() +\n  geom_raster(data = Bath_dataframe_sub , aes(x = x, y = y, fill = Bathymetry)) +\n  scale_fill_viridis_c(option = \"mako\")+\n  theme_void()+\n  theme(legend.position='bottom')+\n  xlab('Longitude')+ylab('Latitude')+\n  coord_sf(xlim = c(3,9), ylim = c(53,56),\n                    label_axes = list(top = \"E\", left = \"N\", bottom = 'E', right='N'))\n\nLoad the package sf\n\nlibrary(sf)\n\nUse the function st_transform to convert to the same CRS\n\nGerman_land<-st_transform(GermanNorthSea::German_land, 4326)\n\nAdd the land to the plot using geom_sf\n\nPlot_bath<-ggplot() +\n  geom_raster(data = Bath_dataframe_sub , aes(x = x, y = y, fill = Bathymetry)) +\n  geom_sf(data = German_land, colour = 'black', fill = '#ffffbe')+\n  scale_fill_viridis_c(option = \"mako\")+\n  theme_void()+\n  theme(legend.position='bottom')+\n  xlab('Longitude')+ylab('Latitude')+\n  coord_sf(xlim = c(3,9), ylim = c(53,56),\n                    label_axes = list(top = \"E\", left = \"N\", bottom = 'E', right='N'))\nPlot_bath\n\n\n\n\n\n\nMore details about how to add features to a map here\n\n\n\n\n\nFurther reading\n\nPackage GermanNorthSea\nPackage terra\nPackage sf\nGEBCO download"
  },
  {
    "objectID": "blog/2025-02-15-distancetocoast/distancetocoast.html",
    "href": "blog/2025-02-15-distancetocoast/distancetocoast.html",
    "title": "Distance to coast",
    "section": "",
    "text": "Intro\nDistance to coast gives us information on the distance (in meters) from one point at sea to the nearest coast.\nThis post includes:\n- Download raster data\n- Read and subset raster data\n- Plot raster data\n\n\nDistance to coast\nTo download:\n- Access OceanColor NASA\n- Select the interpolated 0.01-degree GeoTiff packed together with a brief description file.\n- Unzip information.\n\n\nRead and subset\nTo read from file.\nSelect the directory where the information is.\n\nthis_folder<-here()\nthis_file<-paste0(this_folder,\"/GMT_intermediate_coast_distance_01d.tif\")\nthis_raster<-rast(this_file)\n\n\n\n\nAlternatively, use the data directly from the repository.\n\nDistCoast_tif<-\"https://github.com/MiriamLL/data_supporting_webpage/raw/refs/heads/main/Blog/2025/DistanceToCoast/Subset_GMT_intermediate_coast_distance_01d.tif\"\n\nUse the package terra to use the function rast.\nThen convert to data frame.\n\nlibrary(terra)\nDistCoast_file<-rast(DistCoast_tif)\n\n\nDistCoast_dataframe <- as.data.frame(DistCoast_file, xy = TRUE)\n\nThe file is quite large, so I recommend to subset the data to the area of interest.\nHere I select the area close to the German North Sea.\n\nlibrary(tidyverse)\nDistCoast_dataframe_sub <-DistCoast_dataframe  %>%\n  filter(x > 2 & x < 10)%>%\n  filter(y > 52 & y < 57)%>%\n  rename(Dist=3) %>%\n  mutate(Dist = as.numeric(Dist))\n\nTo save as rda would make the reading a lot faster.\n\nGerman_distancecoast<-DistCoast_dataframe_sub\nsave(German_distancecoast, file=\"German_distancecoast.rda\")\n\n\n\nPlot\nTo plot adding land.\n\nlibrary(sf)\n\nMake sure is in the same CRS.\n\nGerman_land<-st_transform(GermanNorthSea::German_land, 4326)\n\nTo exclude information on land.\n\nlibrary(tidyverse)\n\n\nDistCoast_dataframe_sub<-DistCoast_dataframe_sub %>%\n  filter(Dist > -20)\n\nUse ggplot to create your plot.\n\nPlot_distance<-ggplot() +\n  geom_raster(data = DistCoast_dataframe_sub, aes(x = x, y = y, fill = Dist)) +\n  geom_sf(data = German_land, colour = 'black', fill = '#ffffbe')+\n  scale_fill_viridis_c(option = \"rocket\")+\n  theme_void()+\n  theme(legend.position='bottom')+\n  xlab('Longitude')+ylab('Latitude')+\n  coord_sf(xlim = c(3,9), ylim = c(53,56),\n                    label_axes = list(top = \"E\", left = \"N\", bottom = 'E', right='N'))\nPlot_distance+\n  guides(fill=guide_legend(title=\"Distance to coast\"))\n\n\n\n\n\n\n\n\n\n\n\nFurther reading\n\nPackage GermanNorthSea\nPackage terra\nPackage sf\nOceanColor NASA"
  },
  {
    "objectID": "blog/2025-03-03-fishingdata/fishingdata.html",
    "href": "blog/2025-03-03-fishingdata/fishingdata.html",
    "title": "Fishing effort",
    "section": "",
    "text": "Global Fishing Watch map is a open-access online tool designed for the visualization and analysis of vessel-based human activity at sea. It allows anyone with an internet connection to access the map and monitor global fishing activity from 2012 to the present. The map tracks more than 65,000 commercial fishing vessels, which are responsible for a significant portion of the global seafood catch.\nThe data is broadcast through the automatic identification system (AIS) and collected via satellites and terrestrial receivers. This information is then combined with vessel monitoring system data provided by partner countries. A fishing detection algorithm is applied to determine the ‚Äúapparent fishing effort‚Äù based on changes in vessel speed and direction. The heat map grid cell colors indicate the level of fishing activity in each area, allowing for precise comparisons."
  },
  {
    "objectID": "blog/2025-03-03-fishingdata/fishingdata.html#plot-1",
    "href": "blog/2025-03-03-fishingdata/fishingdata.html#plot-1",
    "title": "Fishing effort",
    "section": "Plot",
    "text": "Plot\nShapefiles of the German North Sea are accessible in my package GermanNorthSea.\n\ninstall.packages(\"devtools\")\ndevtools::install_github(\"MiriamLL/GermanNorthSea\")\nlibrary(GermanNorthSea)\n\nThe package sf helps to convert the CRS.\n\nlibrary(sf)\n\nTo transform to the appropriate CRS, use the function st_transform.\n\nGerman_land<-st_transform(GermanNorthSea::German_land, 4326)\nGerman_EEZ<-st_transform(GermanNorthSea::German_EEZ, 4326)\nGerman_SCA<-st_transform(GermanNorthSea::German_SCA, 4326)\nGerman_natura<-st_transform(GermanNorthSea::German_natura, 4326)\n\nUse ggplot to create your plot. Each dot is a value of fishing effort.\n\nFishing_plot<-ggplot() +\n  geom_tile(data = Fishing_sub, aes(x = x, y = y, fill = FishingEffort)) +\n  theme_bw()+\n  coord_sf(xlim = c(3,9), ylim = c(53,56),\n                    label_axes = list(top = \"E\", left = \"N\", bottom = 'E', right='N'))\n\nChange plot style\n\nFishing_plot<-ggplot() +\n  geom_tile(data = Fishing_sub, aes(x = x, y = y, fill = FishingEffort)) +\n  geom_sf(data = German_EEZ, colour = 'black', fill = 'transparent')+\n  geom_sf(data = German_land, colour = 'black', fill = '#edede9')+\n  geom_sf(data = German_natura, colour = 'transparent', fill = '#3d6d22',alpha=0.2)+\n  theme_void()+\n  xlab('Longitude')+ylab('Latitude')+\n  coord_sf(xlim = c(3,9), ylim = c(53,56),\n                    label_axes = list(top = \"E\", left = \"N\", bottom = 'E', right='N'))+\n  geom_tile(data = Fishing_sub, aes(x = x, y = y, fill = FishingEffort)) +\n  theme(legend.background = element_rect(colour = \"transparent\", fill = \"transparent\"),\n        legend.position = c(0.30,0.30),\n        panel.background = element_rect(fill = '#edf2f4'),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        panel.border = element_rect(colour = \"black\", fill=NA, size=1.5))+\n  scale_fill_gradient(low = \"#fcbf49\", high = \"#d62828\")+ \n  guides(fill=guide_legend(title=\"GFW \\nFishing effort \\nApr May 2018\"))\nFishing_plot\n\n\n\n\n\n\n\nNotes\nThis data is part of an exercise using information from the platform, and the details provided have not been verified or checked for accuracy. The figures and patterns observed are based on the data from Global Fishing Watch, but they may not represent the final, validated insights.\nNo guarantee is made regarding the accuracy or reliability of this data."
  },
  {
    "objectID": "blog/2025-04-15-copernicus-sst/copernicus-sst.html",
    "href": "blog/2025-04-15-copernicus-sst/copernicus-sst.html",
    "title": "Sea surface temperature",
    "section": "",
    "text": "The Copernicus Marine Service (CMS), also known as the Copernicus Marine Environment Monitoring Service, is the marine component of the European Union‚Äôs Copernicus Programme.\nIt delivers free, regular, and systematic information on the state of the ocean, encompassing the Blue (physical), White (sea ice), and Green (biogeochemical) components, both globally and regionally.\nFunded by the European Commission (EC) and implemented by Mercator Ocean International, the service is designed to support EU policies and international legal commitments related to Ocean Governance. It also addresses the global need for ocean knowledge and fosters the Blue Economy across all maritime sectors by providing cutting-edge ocean data and information at no cost.\nThis post includes:\n- Download raster data\n- Read and subset raster data\n- Plot raster data"
  },
  {
    "objectID": "blog/2025-04-15-copernicus-sst/copernicus-sst.html#read-data",
    "href": "blog/2025-04-15-copernicus-sst/copernicus-sst.html#read-data",
    "title": "Sea surface temperature",
    "section": "Read data",
    "text": "Read data\nSelect the directory where the information is stored, or as here, use the data directly form the repository.\n\nSST_nc<-\"https://github.com/MiriamLL/data_supporting_webpage/raw/refs/heads/main/Blog/2025/SST/cmems_mod_glo_phy_my_0.083deg-climatology_P1M-m_1729785319560.nc\"\n\nLoad the terra package for reading raster data.\n\nlibrary(terra)\n\nThe function rast helps to read raster data - replacing package raster.\n\nSST_file<-rast(SST_nc)"
  },
  {
    "objectID": "blog/2025-04-15-copernicus-sst/copernicus-sst.html#subset-raster-data",
    "href": "blog/2025-04-15-copernicus-sst/copernicus-sst.html#subset-raster-data",
    "title": "Sea surface temperature",
    "section": "Subset raster data",
    "text": "Subset raster data\nChange to data frame for data wrangling.\n\nSST_dataframe <- as.data.frame(SST_file, xy = TRUE)\n\nLoad the package tidyverse.\n\nlibrary(tidyverse)\n\nUse filter to subset the data to a specific geographical area.\n\nSST_sub <-SST_dataframe  %>%\n  filter(x > 2 & x < 10)%>%\n  filter(y > 52 & y < 57)\n\nObtain mean values per latitude and longitude\nThere are many columns with data per depth, as data was collected almost every meter.\n\nncol(SST_sub)\n\nTo keep columns with the depth area use the functions select and starts_with.\n\nSST_depth<-SST_sub %>%\n  select(starts_with(\"thetao\"))\n\nCheck the depths were the data was collected.\n\nDepths<-colnames(SST_depth)\nhead(Depths)\n\nUsing functions from tidyverse such as rowwise, summarise the information per depth.\n\nSST_depth_perloc<-SST_depth %>%\n  rowwise()%>%\n  mutate(mean_SST = mean(c_across(where(is.numeric)),na.rm=TRUE),\n         min_SST = min(c_across(where(is.numeric)),na.rm=TRUE),\n         max_SST = max(c_across(where(is.numeric))),na.rm=TRUE)%>%\n  relocate(mean_SST,min_SST,max_SST)\n\nThe function arrange from the package tidyverse allows to see the columns of interest first.\n\nfirst_column<-SST_depth[1,]\nlong_values<-first_column %>% \n  pivot_longer(\n    cols = 1:228, \n    names_to = \"type\",\n    values_to = \"value\"\n)\narrange_values<-arrange(long_values, desc(value))\n\n\n\n\nNow there is a value per latitude and longitude of the sea surface temperature, summarizing the first 60 m of the water column.\n\nSST_sub$SST<-SST_depth_perloc$mean_SST\n\n\nmean(SST_sub$SST)"
  },
  {
    "objectID": "blog/2025-05-05-lightpollution/lightpollution.html",
    "href": "blog/2025-05-05-lightpollution/lightpollution.html",
    "title": "Light pollution",
    "section": "",
    "text": "The Visible Infrared Imaging Radiometer Suite (VIIRS) is aboard the joint NASA/NOAA Suomi National Polar-orbiting Partnership (Suomi NPP) and‚ÄØNOAA-platforms. VIIRS collects visible and infrared imagery along with global observations of Earth‚Äôs land, atmosphere, cryosphere, and ocean."
  },
  {
    "objectID": "blog/2025-05-05-lightpollution/lightpollution.html#data-frame",
    "href": "blog/2025-05-05-lightpollution/lightpollution.html#data-frame",
    "title": "Light pollution",
    "section": "Data frame",
    "text": "Data frame\nTo manipulate convert to data frame.\n\nLight_pollution_df <- as.data.frame(Light_pollution, xy = TRUE)\nbeepr::beep(sound=1)\n\nThe function rename, allows to change the name of the column. The radiance information is in the third column.\n\nLight_pollution_radiance<-Light_pollution_df %>%\n  rename(radiance=3)\n\nCheck if the radiance values are plausible.\n\nrange(Light_pollution_radiance$radiance)\n\n\nBasic plot\nUse the function geom_spatraster to plot the radiance data.\n\nggplot() +\n  geom_spatraster(data = Light_pollution) +\n  \n  coord_sf(xlim = c(4.5,9), ylim = c(53,56),\n           label_axes = list(top = \"E\", left = \"N\", bottom = 'E', right='N'),\n           default_crs = sf::st_crs(4326))+\n  scale_fill_gradient(name='Light pollution \\n in the North Sea \\n Radiance ',\n                      limits = c(0,1),\n                      low = 'black', high = '#f9c74f', \n                      na.value = \"grey93\", \n                      breaks = c(0.02,0.20, 0.40, 0.60,0.75, 0.90)\n                      )+\n  NULL\n\n\n\nChange theme\nChange the arguments inside theme to adjust the looks of your plot.\n\nggplot() +\n  geom_spatraster(data = Light_pollution) +\n  coord_sf(xlim = c(3,9), ylim = c(53,56),\n           label_axes = list(top = \"E\", left = \"N\", bottom = 'E', right='N'),\n           default_crs = sf::st_crs(4326))+\n  scale_fill_gradient(name='Light pollution \\n in the North Sea \\n Radiance ',\n                      limits = c(0,1),\n                      low = 'black', high = '#f9c74f', \n                      na.value = \"grey93\", \n                      breaks = c(0.02,0.20, 0.40, 0.60,0.75, 0.90)\n                      )+\n  theme_void()+\n    theme(legend.background = element_rect(colour = \"transparent\", fill = \"transparent\"),\n        legend.position = c(0.20,0.30),\n        panel.background = element_rect(fill = 'black'),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        panel.border = element_rect(colour = \"black\", fill=NA, size=1.5),\n        legend.text=element_text(color='#f9c74f',size=12),\n        legend.title=element_text(color='#f9c74f',size=12))+ \n  NULL\n\n\n\nChange fill\nSelect some colors create a color palette.\n\ncolor_NA <-\"#000000\"\ncolor_K <-\"#ffff3f\"\ncolor_J <-\"#eeef20\"\ncolor_I <-\"#dddf00\"\ncolor_H <-\"#d4d700\"\ncolor_G <-\"#bfd200\"\ncolor_F <-\"#aacc00\"\ncolor_E <-\"#80b918\"\ncolor_D <-\"#55a630\"\ncolor_C <-\"#2b9348\"\ncolor_B <-\"#007f5f\"\ncolor_A <-\"#548c2f\"\nyour_palette<-c(color_NA,color_A,color_B,color_C,color_D,color_E,color_F,color_G,color_H,color_I,color_J,color_K)\n\nInclude scale_fill_gradientn to use the color palette.\n\nggplot() +\n  geom_spatraster(data = Light_pollution) +\n \n  coord_sf(xlim = c(3,9), ylim = c(53,56),\n           label_axes = list(top = \"E\", left = \"N\", bottom = 'E', right='N'),\n           default_crs = sf::st_crs(4326))+\n \n  theme_void()+\n    theme(legend.background = element_rect(colour = \"transparent\", fill = \"transparent\"),\n        legend.position = c(0.20,0.30),\n        panel.background = element_rect(fill = 'black'),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        panel.border = element_rect(colour = \"black\", fill=NA, size=1.5),\n        legend.text=element_text(color='#f9c74f',size=12),\n        legend.title=element_text(color='#f9c74f',size=12))+\n  \n  scale_fill_gradientn(name='Light pollution \\n in the North Sea \\n Radiance ',\n                      limits = c(0,1),\n                      colours = your_palette,\n                      na.value = \"grey93\", \n                      breaks = c(0.02,0.20, 0.40, 0.60,0.75, 0.90)\n                      )+\n  NULL\n\n\n\nAdd text\nAdd text using the function annotate for reference.\n\nggplot() +\n  geom_spatraster(data = Light_pollution) +\n \n  coord_sf(xlim = c(3,9), ylim = c(53,56),\n           label_axes = list(top = \"E\", left = \"N\", bottom = 'E', right='N'),\n           default_crs = sf::st_crs(4326))+\n \n  theme_void()+\n    theme(legend.background = element_rect(colour = \"transparent\", fill = \"transparent\"),\n        legend.position = c(0.20,0.30),\n        panel.background = element_rect(fill = 'black'),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        panel.border = element_rect(colour = \"black\", fill=NA, size=1.5),\n        legend.text=element_text(color='#f9c74f',size=12),\n        legend.title=element_text(color='#f9c74f',size=12))+\n  \n  scale_fill_gradientn(name='Light pollution \\n in the North Sea \\n Radiance ',\n                      limits = c(0,1),\n                      colours = your_palette,\n                      na.value = \"grey93\", \n                      breaks = c(0.02,0.20, 0.40, 0.60,0.75, 0.90)\n                      )+\nannotate(\"text\", x = 7.885143539318454-1.6, y = 54.181291760152874,\n           label = \"Helgoland\",size=5,color='#d6d6d6',hjust = 0)"
  },
  {
    "objectID": "blog/2025-06-02-shippingtraffic/shippingtraffic.html",
    "href": "blog/2025-06-02-shippingtraffic/shippingtraffic.html",
    "title": "Shipping traffic",
    "section": "",
    "text": "The Vessel Density maps in the EU are created since the 2019 by Cogea for the European Marine Observation and Data Network EMODnet. The dataset is updated every year and is available for viewing and download on EMODnet Human Activities web portal (https://emodnet.ec.europa.eu/en/human-activities).\nThe maps are based on AIS data yearly purchased from Collecte Localisation Satellites (CLS) and ORBCOMM. The maps, GeoTIFF format, show shipping density in 1x1km cells of a grid covering all EU waters and some neighbouring areas.\nDensity is expressed as hours per square kilometre per month. The following ship types are available:0 Other, 1 Fishing, 2 Service, 3 Dredging or underwater ops, 4 Sailing, 5 Pleasure Craft, 6 High speed craft, 7 Tug and towing, 8 Passenger, 9 Cargo, 10 Tanker, 11 Military and Law Enforcement, 12 Unknown and All ship types.\nData are available by month of year. Yearly averages are also available.\n\n\nTo download go to EMODnet Map Viewer > Catalogue > EMODnet Human Activities > Vessel density > Monthly totals 2017-2023 > All Types > Click on the ‚Äúi‚Äù icon > Select Download.\nA zip file named ‚ÄúEMODnet_HA_Vessel_Density_all_2017-2023 would be downloaded. For the period of December 2023, the raster information is under vesseldensity_all_20231201.tif.\n\n\n\nTo download test data in tif format click here.\nUse the package terra to use the function rast.\n\nlibrary(terra)\n\nThe function rast reads your file as a formal class SpatRaster. Here I am using the file directly from the repository.\n\nShippingTraffic_tif<-'https://github.com/MiriamLL/data_supporting_webpage/raw/refs/heads/main/Blog/2025/ShippingTraffic/ShippingTraffic_crop.tif'\n\n\nShippingTraffic<-rast(ShippingTraffic_tif)\n\n\ncrs(ShippingTraffic)\n\n\nggplot2::ggplot() +\n  tidyterra::geom_spatraster(data = ShippingTraffic) +\n  NULL\n\n\n\n\n\nlibrary(tidyverse)\n\n\nShippingTraffic_df <- as.data.frame(ShippingTraffic, xy = TRUE)\nbeepr::beep(sound=1)\n\nThe function rename, allows to change the name of the column. The density information is in the third column.\n\nShippingTraffic_df<-ShippingTraffic_df %>%\n  rename(vessel_density=3)\n\nCheck if the density values are plausible.\n\nrange(ShippingTraffic_df$vessel_density)\n\nValues distribution\n\nhist(ShippingTraffic_df$vessel_density)\n\n\nShippingTraffic_class<-ShippingTraffic_df %>%\n mutate(\n    density_class = case_when(\n      vessel_density <= 0  ~ \"class_A_0\",\n      vessel_density > 0 &  vessel_density < 1 ~ \"class_A_0_1\",\n      vessel_density > 1 &  vessel_density < 2 ~ \"class_A_1_2\",\n      vessel_density > 2 &  vessel_density < 3 ~ \"class_A_2_3\",\n      vessel_density > 3 &  vessel_density < 4 ~ \"class_A_3_4\",\n      vessel_density > 4 &  vessel_density < 5 ~ \"class_A_4_5\",\n      vessel_density > 5 &  vessel_density < 6 ~ \"class_A_5_6\",\n      vessel_density > 6 &  vessel_density < 7 ~ \"class_A_6_7\",\n      vessel_density > 7 &  vessel_density < 8 ~ \"class_A_7_8\",\n      vessel_density > 8 &  vessel_density < 9 ~ \"class_A_8_9\",\n      vessel_density > 9 &  vessel_density < 10 ~ \"class_A_9_10\",\n      \n      vessel_density >= 10 &  vessel_density < 100 ~ \"class_B_10_100\",\n      vessel_density >= 100 &  vessel_density < 1000 ~ \"class_C_100_1000\",\n      vessel_density >= 1000 &  vessel_density < 10000 ~ \"class_D_1000_10000\",\n      vessel_density >= 10000 &  vessel_density < 100000 ~ \"class_E_10000_100000\",\n      TRUE  ~ \"unknown\"\n    ))\n\nThe majority of values are between 0 and 1\n\n\n\n\n\n\nUse the function geom_spatraster to plot the vessel density data.\n\nlibrary(tidyterra)\n\n\nggplot() +\n  geom_spatraster(data = ShippingTraffic)\n\n\n\n\nAdd land for reference using geom_sf and the package GermanNorthSea.\n\ninstall.packages(\"devtools\")\ndevtools::install_github(\"MiriamLL/GermanNorthSea\")\nlibrary(GermanNorthSea)\n\n\nShippingTraffic_01plot<-ggplot() +\n  geom_spatraster(data = ShippingTraffic) +\n  geom_sf(data = GermanNorthSea::German_EEZ, color='grey',fill='transparent',alpha=0.1, size = 1)+\n  geom_sf(data = GermanNorthSea::German_land, colour = 'black', fill = '#e5e5e5')+\n  coord_sf(xlim = c(3820000,4250000), ylim = c(3370000,3660000),\n                    label_axes = list(top = \"E\", left = \"N\", bottom = 'E', right='N'))\nShippingTraffic_01plot\n\n\n\n\nChange background colors using the arguments on theme.\n\nShippingTraffic_02plot<-ShippingTraffic_01plot+\n  theme_void()+\n    theme(panel.background = element_blank(),\n          panel.grid.major = element_blank(),\n          panel.grid.minor = element_blank(),\n          panel.border = element_rect(colour = \"black\", fill=NA, size=1.5))\nShippingTraffic_02plot\n\n\n\n\nLow traffic\n\nLowShippingTraffic_03plot<-ShippingTraffic_02plot+\n    \n  scale_fill_gradientn(name='Low Vessel density \\n Dec 2023',\n                      na.value = \"transparent\", \n                      colours = palette_yellow<-c(\"#ffff3f\",\"#eeef20\",\"#dddf00\",\"#d4d700\",\"#bfd200\",\"#aacc00\",\"#80b918\",\"#55a630\",\"#2b9348\",\"#007f5f\"),\n                      limits = c(0.00001,10),\n                      breaks = c(2,4,6,8,10),\n                      )\nLowShippingTraffic_03plot\n\nMedium traffic\n\nMediumShippingTraffic_04plot<-ShippingTraffic_02plot+\n  \n    scale_fill_gradientn(name='Medium Vessel density \\n Dec 2023',\n                      na.value = \"transparent\", \n                      colours = palette_green<-c(\"#d8f3dc\",\"#b7e4c7\",\"#95d5b2\",\"#74c69d\",\"#52b788\",\"#40916c\",\"#2d6a4f\",\"#1b4332\",\"#081c15\"),\n                      limits = c(5,100),\n                      breaks = c(5,20,40,60,80,100),\n                      )\nMediumShippingTraffic_04plot  \n\nHigh traffic\n\nHighShippingTraffic_06plot<-ShippingTraffic_02plot+\n  scale_fill_gradientn(name='High Vessel density \\n Dec 2023 \\n (hrs per km2)',\n                      na.value = \"transparent\", \n                      colours = palette_red<-c(\"#e01e37\",\"#da1e37\",\"#c71f37\",\"#bd1f36\",\"#b21e35\",\"#a71e34\",\"#a11d33\",\"#85182a\",\"#6e1423\",\"#641220\"),\n                      limits = c(100,30000),\n                      breaks = c(0,1000,10000,20000,30000),\n                      )\nHighShippingTraffic_06plot\n\n\n\n\n\nyour_palette<-c(\"transparent\", \"#d8f3dc\",\n                \"#b7e4c7\",\"#95d5b2\",\"#74c69d\",\"#52b788\",\"#aacc00\",\n                \"#bfd200\",\"#d4d700\",\"#dddf00\",\"#eeef20\",\"#ffff3f\", \n                \"#e01e37\",\"#da1e37\",\"#c71f37\", \"#bd1f36\",\"#b21e35\",\n                \"#a71e34\",\"#a11d33\",\"#85182a\",\"#6e1423\",\"#641220\")\n\nUse scale_fill_gradientn and rescale to adjust the palette and the legend\n\nShippingTraffic_07plot<-ShippingTraffic_02plot+\n  \n  scale_fill_gradientn(name='Vessel density \\n Dec 2023 \\n hrs per km2',\n                      na.value = \"transparent\", \n                      colours = your_palette,\n                      limits = c(0,30000),\n                      breaks = c(0.05,0.1,0.2,0.5,2,5,10,20,100,1000),\n                      values = scales::rescale(c(0,0.01,0.05,0.1,0.2,0.5,2,5,10,20,100,1000)), \n                      guide = \"legend\"\n                      )\nShippingTraffic_07plot\n\nUse labels inside scale_fill_gradient to make the legend more legible\n\nShippingTraffic_08plot<-ShippingTraffic_02plot+\n  scale_fill_gradientn(name='Vessel density \\n Dec 2023 \\n hrs per km2',\n                      na.value = \"transparent\", \n                      colours = your_palette,\n                      limits = c(0,30000),\n                      breaks = c(0.05,0.1,0.2,0.5,2,5,10,20,100,1000),\n                      values = scales::rescale(c(0,0.01,0.05,0.1,0.2,0.5,2,5,10,20,100,1000)), \n                      guide = \"legend\",\n                      labels = c(\"0 - 0.05\",\"> 0.1\",\"> 0.2\",\"> 0.5\",\"> 2\",\"> 5\",\"> 10\",\"> 20\", \"> 100\",\"> 1,000\") )\nShippingTraffic_08plot\n\nInclude the legend inside the plot and change the theme, also change panel.background\n\nShippingTraffic_09plot<-ShippingTraffic_08plot+\n  theme(legend.position = c(0.20,0.50),\n          legend.background = element_rect(colour = FALSE, fill = FALSE),\n          legend.title=element_text(color='black',size=16),\n          legend.text=element_text(color='black',size=12),\n          legend.key = element_rect(colour = 'transparent', fill = 'transparent'),\n          legend.key.height = unit(3, \"mm\"))\nShippingTraffic_09plot"
  },
  {
    "objectID": "blog/2025-07-01-owf/owf.html",
    "href": "blog/2025-07-01-owf/owf.html",
    "title": "Offshore Wind Farms",
    "section": "",
    "text": "An Offshore Wind Farm (OWF) is defined as a group of wind turbines placed in the ocean to generate electricity using the power of the wind.\n- Wind turbines are installed on foundations anchored to the seabed (or floating, in deeper waters).\n- Blades spin when the wind blows, turning a generator.\n- The electricity generated is sent back to land through underwater power cables.\n- Offshore wind farms have high upfront costs and engineering complexity, produce visual and noise problems, and might have an impact on marine ecosystems and birds.\n\n\n  \n\n\nAlpha Ventus Windmills\nSource: Wikipedia"
  },
  {
    "objectID": "blog/2025-07-01-owf/owf.html#status",
    "href": "blog/2025-07-01-owf/owf.html#status",
    "title": "Offshore Wind Farms",
    "section": "Status",
    "text": "Status\nIn the context of Offshore Wind Farms (OWF), the terms ‚ÄúProduction‚Äù, ‚ÄúApproved‚Äù, and ‚ÄúPlanned‚Äù refer to the development status or stage of a wind farm project.\n- Production is when the wind farm is fully built and actively generating electricity;\n- Approved is when the wind farm project has received all the necessary legal and environmental permits from authorities but construction has not yet started; and\n- Planned is when the wind farm is in the early stages of development, often proposed or under review, but not yet approved.\n\nunique(OWF_EMODnet$STATUS)\n\nTo only use active OWF the best is to filter using the status and selecting Production.\n\nOWF_Production<-OWF_EMODnet%>%\n  filter(STATUS == 'Production')\n\nWe can also filter the information by using year. Here, we can see that data includes OWF from 2009 to 2020.\n\nunique(OWF_Production$YEAR)\n\nHere, lets separate those OWF before 2016 from the ones after.\n\nOWF_Before2016<-OWF_Production %>%\n  filter(YEAR <= 2016)\n\n\nOWF_After2016<-OWF_Production %>%\n  filter(YEAR > 2016)\n\nPlot using different colors for OWF before 2016 and after 2016.\n\nOWF_1plot<-ggplot(OWF_EMODnet) + # Gives CRS\n  \n  # Fill colors\n  geom_sf(data = GermanNorthSea::German_EEZ, colour = \"black\", fill= '#56C1D5', lwd = 0.5)+\n  geom_sf(data = GermanNorthSea::German_natura, colour = 'transparent', fill= '#84a98c', alpha=0.5,lwd = 0.5)+\n  geom_sf(data = GermanNorthSea::German_SCA, colour = 'transparent', fill= '#84a98c', alpha=0.5,lwd = 0.5)+\n  geom_sf(data = GermanNorthSea::German_land, colour = '#9a8c98', fill = '#9a8c98')+\n \n  # Line colors\n  geom_sf(data = GermanNorthSea::German_EEZ, colour = \"black\", fill= NA, lwd = 0.5)+\n  geom_sf(data = GermanNorthSea::German_coast, colour = \"black\", fill= NA,alpha=0.9, lwd = 0.5,linetype=\"dashed\")+\n  geom_sf(data = GermanNorthSea::German_land, colour = '#9a8c98', fill = '#9a8c98')+\n\n  ## OWF\n  geom_sf(data = OWF_After2016,  colour = NA,fill= \"#bb3e03\",alpha=0.9, size=1,linetype=\"dashed\")+  \n  geom_sf(data = OWF_Before2016,  colour = \"#ffb703\",fill= \"#ffb703\",alpha=0.9, size=1)+ \n  \n  \n  coord_sf(xlim = c(3900000,4250000), ylim = c(3350000,3680000),\n                    label_axes = list(left = \"N\", bottom = 'E'))\nOWF_1plot"
  },
  {
    "objectID": "blog/2025-07-01-owf/owf.html#names",
    "href": "blog/2025-07-01-owf/owf.html#names",
    "title": "Offshore Wind Farms",
    "section": "Names",
    "text": "Names\nThere is an option using ggrepel, but here I manually include names of the OWF using annotation.\nFirst, create a data frame with the coordinates and the segment.\n\nLabels<-data.frame(text_x=c(4010000,4010000,4141000,4179000,4211000,4211000,4211000,4010000,4010000,4010000,4010000),\n           text_y= c(3479000,3494000,3605000,3585000,3494000,3486000,3478000,3449000,3439000,3429000,3405000),\n           text_label=c(\"BARD\",\"GTI\",\"DT\",\"BT\",\"AMW\",\"NSO\",\"MSO\",\"TRI\",\"AV\",\"BR\",\"RG\"),\n           segment_xstart=c(4020000,4018000,4141000,4179000,4178000,4177000,4178000,4020000,4020000,4020000,4020000),\n           segment_xend=c(4055000,4081000,4141000,4179000,4201000,4201000,4201000,4083000,4097000,4089000,4085000),\n           segment_ystart=c(3479000,3494000,3578000,3558000,3492000,3486000,3479000,3444000,3439000,3435000,3405000),\n           segment_yend=c(3479000,3494000,3594000,3574000,3492000,3486000,3479000,3444000,3439000,3435000,3405000)\n)\n\nThen add it one by one to the plot. You can skip this step if you dont need the names.\n\nOWF_2plot<-OWF_1plot + \n  #BARD\n  annotate(\"text\", x = Labels$text_x[1], y = Labels$text_y[1], label = Labels$text_label[1],size=3)+\n  annotate(\"segment\", x = Labels$segment_xstart[1], xend = Labels$segment_xend[1],\n           y = Labels$segment_ystart[1], yend = Labels$segment_yend[1],colour = \"black\")+\n  #GTI\n  annotate(\"text\", x = Labels$text_x[2], y = Labels$text_y[2], label = Labels$text_label[2],size=3)+\n  annotate(\"segment\", x = Labels$segment_xstart[2], xend = Labels$segment_xend[2],\n           y = Labels$segment_ystart[2], yend = Labels$segment_yend[2],colour = \"black\")+\n  #Dan Tysk\n  annotate(\"text\", x = Labels$text_x[3], y = Labels$text_y[3], label = Labels$text_label[3],size=3)+\n  annotate(\"segment\", x = Labels$segment_xstart[3], xend = Labels$segment_xend[3],\n           y = Labels$segment_ystart[3], yend = Labels$segment_yend[3],colour = \"black\")+\n  #Butendiek\n  annotate(\"text\", x = Labels$text_x[4], y = Labels$text_y[4], label = Labels$text_label[4],size=3)+\n  annotate(\"segment\", x = Labels$segment_xstart[4], xend = Labels$segment_xend[4],\n           y = Labels$segment_ystart[4], yend = Labels$segment_yend[4],colour = \"black\")+\n  #Amrum bank west\n  annotate(\"text\", x = Labels$text_x[5], y = Labels$text_y[5], label = Labels$text_label[5],size=3)+\n  annotate(\"segment\", x = Labels$segment_xstart[5], xend = Labels$segment_xend[5],\n           y = Labels$segment_ystart[5], yend = Labels$segment_yend[5],colour = \"black\")+\n  # NSO\n  annotate(\"text\", x = Labels$text_x[6], y = Labels$text_y[6], label = Labels$text_label[6],size=3)+\n  annotate(\"segment\", x = Labels$segment_xstart[6], xend = Labels$segment_xend[6],\n           y = Labels$segment_ystart[6], yend = Labels$segment_yend[6],colour = \"black\")+\n  # MSO\n  annotate(\"text\", x = Labels$text_x[7], y = Labels$text_y[7], label = Labels$text_label[7],size=3)+\n  annotate(\"segment\", x = Labels$segment_xstart[7], xend = Labels$segment_xend[7],\n           y = Labels$segment_ystart[7], yend = Labels$segment_yend[7],colour = \"black\")+\n  # TRI\n  annotate(\"text\", x = Labels$text_x[8], y = Labels$text_y[8], label = Labels$text_label[8],size=3)+\n  annotate(\"segment\", x = Labels$segment_xstart[8], xend = Labels$segment_xend[8],\n           y = Labels$segment_ystart[8], yend = Labels$segment_yend[8],colour = \"black\")+\n  # AV\n  annotate(\"text\", x = Labels$text_x[9], y = Labels$text_y[9], label = Labels$text_label[9],size=3)+\n  annotate(\"segment\", x = Labels$segment_xstart[9], xend = Labels$segment_xend[9],\n           y = Labels$segment_ystart[9], yend = Labels$segment_yend[9],colour = \"black\")+\n  # BR\n  annotate(\"text\", x = Labels$text_x[10], y = Labels$text_y[10], label = Labels$text_label[10],size=3)+\n  annotate(\"segment\", x = Labels$segment_xstart[10], xend = Labels$segment_xend[10],\n           y = Labels$segment_ystart[10], yend = Labels$segment_yend[10],colour = \"black\")+\n  # RG\n  annotate(\"text\", x = Labels$text_x[11], y = Labels$text_y[11], label = Labels$text_label[11],size=3)+\n  annotate(\"segment\", x = Labels$segment_xstart[11], xend = Labels$segment_xend[11],\n           y = Labels$segment_ystart[11], yend = Labels$segment_yend[11],colour = \"black\")+\n  NULL\nOWF_2plot"
  },
  {
    "objectID": "blog/2025-07-01-owf/owf.html#theme",
    "href": "blog/2025-07-01-owf/owf.html#theme",
    "title": "Offshore Wind Farms",
    "section": "Theme",
    "text": "Theme\nTo reduce noise from the grid, the background colors and the labels, give elements in the theme().\n\nOWF_3plot<-OWF_2plot + \n  scale_x_continuous(breaks = c(4,6,8),labels = function(x) paste0(x, '\\u00B0')) +\n  scale_y_continuous(breaks = c(53.5,54.5,55.5),labels = function(x) paste0(x, '\\u00B0'))  +\n  \n  theme(\n  panel.grid.major = element_blank(),\n  panel.grid.minor = element_blank(),\n  panel.background = element_rect(fill = '#AFDEE8'),\n  panel.border = element_rect(colour = \"black\", fill=NA, size=1.5),\n  \n  axis.text.x = element_text(size=10,vjust = 12,color='#3d5a80'),\n  axis.text.y = element_text(color='#3d5a80',size=10,margin = margin(0,-1.30,0,1, unit = 'cm')),\n  axis.title = element_blank(),\n  axis.ticks.length=unit(-0.20, \"cm\"),\n  \n  legend.position='none',\n  legend.spacing.y = unit(0.05, 'cm'),\n  legend.text=element_text(size=10),\n  legend.background = element_rect(fill='transparent',colour =\"transparent\"),\n  legend.box.background = element_rect(fill='transparent',colour =\"transparent\"),\n  legend.key = element_rect(fill = \"transparent\", colour = \"transparent\")\n  )+\n  \n  NULL\nOWF_3plot"
  },
  {
    "objectID": "blog/2025-07-01-owf/owf.html#title",
    "href": "blog/2025-07-01-owf/owf.html#title",
    "title": "Offshore Wind Farms",
    "section": "Title",
    "text": "Title\nUsing the package ggtext, we can add a text with different colors.\n\nlibrary(ggtext)\n\n\nOWF_3plot +\n  geom_richtext(aes(x =  3895000, y = 3669000,\n  label = \"Offshore Wind farms in production\n  <span style='color:#ffb400'>from 2009 to 2016</span>\n  and\n  <span style='color:#bb3e03'>from 2017 to 2020</span>\"), \n  size=4, \n  fill = NA, \n  label.color = NA, # remove background and outline\n  hjust = 0,\n  vjust= 0,\n  inherit.aes = TRUE\n  )+\n  NULL"
  },
  {
    "objectID": "blog/2025-08-04-oil/oil.html",
    "href": "blog/2025-08-04-oil/oil.html",
    "title": "Oil and Gas Offshore Installations",
    "section": "",
    "text": "In this month‚Äôs blog post, I dive into the world of oil and gas infrastructure in the German North Sea. Using openly available geospatial data from EMODnet, I downloaded and analyzed datasets related to offshore installations and pipelines. Step by step, I walk through the process of transforming raw data into a map. Creating this visualization not only helped me better understand the spatial layout of these industrial structures, but also shed light on why a particular proposed site has drawn criticism. The proximity to ecologically sensitive areas like Borkum Reef raises important questions, questions that are best understood when we can actually see the data."
  },
  {
    "objectID": "blog/2025-08-04-oil/oil.html#map",
    "href": "blog/2025-08-04-oil/oil.html#map",
    "title": "Oil and Gas Offshore Installations",
    "section": "Map",
    "text": "Map\nUse ggplot to visualize the information where this infrastructures occur.\n\nlibrary(ggplot2)\n\n\nggplot() +\n  geom_sf(data = Oil_shapefile)"
  },
  {
    "objectID": "blog/2025-08-04-oil/oil.html#filter",
    "href": "blog/2025-08-04-oil/oil.html#filter",
    "title": "Oil and Gas Offshore Installations",
    "section": "Filter",
    "text": "Filter\nThe OSPAR commission source covers data for Germany, Ireland, Spain (Atlantic Sea), while for Italy data have been collected and harmonized from the Italian Ministry of Economic Development, for Denmark from the Danish Energy Agency, for the Netherlands from the TNO - Geological Survey of the Netherlands, for Croatia from the Croatian Hydrocarbon Agency, for Norway from the Norwegian Petroleum Directorate, for the UK from the Oil and Gas Authority (surface infrastructures), for Polish and Russian installations in the Baltic Sea from Marine Traffic and Helcom, finally from Marine Traffic come the data for Bulgarian, Russian and Ukrainian installations in the Black Sea and for Lybian and Spanish installations in the Mediterranean Sea.\n\nunique(Oil_shapefile$COUNTRY)\n\nLoad tidyverse to make a filter.\n\nlibrary(tidyverse)\n\nKeep only Germany data.\n\nOil_germany<-Oil_shapefile %>%\n  filter(COUNTRY == 'Germany')\n\nUse geom_sf to visualize the points. There are 3 data points for Germany.\n\nggplot() +\n  geom_sf(data = Oil_germany)"
  },
  {
    "objectID": "blog/2025-08-04-oil/oil.html#places",
    "href": "blog/2025-08-04-oil/oil.html#places",
    "title": "Oil and Gas Offshore Installations",
    "section": "Places",
    "text": "Places\nCreate a base map using shapefiles from the package GermanNorthSea.\n\nlibrary(GermanNorthSea)\n\nAdd the attributes and the theme to your base map.\n\nOil_germany<-st_transform(Oil_germany,4326)\nGerman_EEZ<-st_transform(German_EEZ,4326)\nGerman_land<-st_transform(German_land,4326)\nGerman_SCA<-st_transform(German_SCA,4326)\nGerman_natura<-st_transform(German_natura,4326)\n\n\nBase_map<-ggplot() +\n  geom_sf(data = Oil_germany)+ \n  # Fill colors\n  geom_sf(data = German_EEZ, color='#43585E',fill='transparent',alpha=0.1, linewidth = 1)+\n  geom_sf(data = German_land, colour = '#43585E', fill = '#43585E')+\n  \n  geom_sf(data = German_SCA, colour = '#43585E', fill = '#40916c', \n          linewidth=0.1, linetype = \"dashed\",alpha=0.3)+\n  geom_sf(data = German_natura, colour = '#43585E', fill = '#40916c', \n          linewidth=0.1, linetype = \"dashed\",alpha=0.3)+\n  \n  scale_x_continuous(breaks = c(4,6,8),labels = function(x) paste0(x, '\\u00B0')) +\n  scale_y_continuous(breaks = c(53.5,54.5,55.5),labels = function(x) paste0(x, '\\u00B0'))  +\n  \n  theme(\n  axis.text.x = element_text(size=10,vjust = 12,color='black'),\n  axis.text.y = element_text(color='black',size=10,margin = margin(0,-1.30,0,1, unit = 'cm')),\n  axis.title = element_blank(),\n  axis.ticks.length=unit(-0.20, \"cm\"),\n  panel.grid.major = element_blank(),\n  panel.grid.minor = element_blank(),\n  panel.background = element_rect(fill = '#F2F2F2'))+\n  \n  xlab('Longitude')+ylab('Latitude')+\n  \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, linewidth = 1.5))+\n  coord_sf(ylim = c(53,56), xlim = c(3,9),\n                    label_axes = list(left = \"N\", bottom = 'E'))\n\nUsing annotate, add the names of the platforms.\n\nOil_1plot<-Base_map+\n  annotate(\"text\", \n           x = 3.98639-0.95, y = 55.82222, label = \"A6-A\",size=5,colour =\"#bb3e03\")+\n  annotate(\"segment\", \n           x = 3.98639, xend = 3.98639-0.7,\n           y =  55.82222-0.02, yend = 55.82222-0.02,colour = 'black', linewidth=1)+\n  annotate(\"text\", \n           x = 8.73111-1, y = 54.02583, label =\"Mittelplate A\",size=5,color=\"#ffb400\")+\n  annotate(\"segment\", \n           x =  8.73111, xend = 8.73111-0.4,\n           y = 54.02583, yend =  54.02583, color= 'black', linewidth=1)+\n  NULL\n\nMittleplate A\nMittelplate is Germany‚Äôs largest oil field, located 7 km (4.3 mi) offshore in the ecologically sensitive tidal flats of the Schleswig-Holstein Wadden Sea National Park. The field was developed by a joint venture between RWE Dea and Wintershall. By the 20th anniversary of production, the field had yielded approximately 20 million tonnes (22 million tons), or about 146 million barrels, of crude oil. Mittelplate contains nearly 65% of Germany‚Äôs total crude oil reserves. Source: Wikipedia\n\n\n  \n\n\nImage showing Mittleplate A oil field.\nA6-A\nA6/B4 is Germany‚Äôs only operational offshore gas field, located about 300 km off the coast in the North Sea, within Germany‚Äôs exclusive economic zone. Discovered in 1974 and producing since 2000, it supplies around 5% of Germany‚Äôs natural gas. By the end of 2006, it had produced 6.7 billion cubic meters. Operated by the German North Sea Consortium, with Wintershall Noordzee B.V. managing production, the platform sits in 48 meters of water and typically hosts ten workers. Gas and condensate are piped to a Dutch platform, where the condensate is shipped and the gas sent to the mainland via the NOGAT pipeline. Source: Wikipedia\n\n\n  \n\n\nImage showing A6-A Offshore gas field."
  },
  {
    "objectID": "blog/2025-08-04-oil/oil.html#filter-1",
    "href": "blog/2025-08-04-oil/oil.html#filter-1",
    "title": "Oil and Gas Offshore Installations",
    "section": "Filter",
    "text": "Filter\nThe pipelines data set from EMODnet contains different types.\n\nunique(Pipelines_shapefile$MEDIUM)\n\nFor this exercise select only those containing gas.\n\nPipelines_gas<-Pipelines_shapefile %>%\n  filter(MEDIUM %in% c(\"Gas\", \"Gas, Water, Air\",\"Gas, Water\",\"Oil\",\"Gas, Oil\"))\n\nThe data set also contains data from different countries.\n\nunique(Pipelines_gas$COUNTRY)\n\nFor this exercise, select Germany and surrounding countries.\n\nPipelines_crossing_germany<-Pipelines_gas %>%\n  filter(COUNTRY %in% c(\"Germany, Russia\", \"Germany\",\n                        \"Netherlands\",\"United Kingdom\"))"
  },
  {
    "objectID": "blog/2025-08-04-oil/oil.html#map-1",
    "href": "blog/2025-08-04-oil/oil.html#map-1",
    "title": "Oil and Gas Offshore Installations",
    "section": "Map",
    "text": "Map\nAdd a geom_sf in the previous plot to visualize the gas pipelines.\n\nOil_2plot<-Oil_1plot +\n  geom_sf(data = Pipelines_gas, alpha=0.08, colour =\"#bb3e03\")+\n  coord_sf(ylim = c(53,56), xlim = c(3,9),\n                    label_axes = list(left = \"N\", bottom = 'E'))"
  },
  {
    "objectID": "blog/2025-08-04-oil/oil.html#text",
    "href": "blog/2025-08-04-oil/oil.html#text",
    "title": "Oil and Gas Offshore Installations",
    "section": "Text",
    "text": "Text\nThe package ggtext allows to add colors into labels.\n\nlibrary(ggtext)\n\nAdd the title on the map.\n\nOil_3plot<-Oil_2plot +\n  geom_richtext(aes(x =  4.5, y = 55.5,\n  label = \"Offshore installations for exploration, <br> \n  exploitation or transportation of<br>\n  <span style='color:#ffb400'>Oil</span>\n  and\n  <span style='color:#bb3e03'>Gas (including pipelines) </span> <br>\n  in the German North Sea\"), \n  size = 5, \n  fill = NA, \n  label.color = NA, # remove background and outline\n  hjust = 0,\n  vjust= 0,\n  inherit.aes = TRUE\n  )+\n  NULL"
  },
  {
    "objectID": "blog/2025-08-04-oil/oil.html#borkum-n05-a",
    "href": "blog/2025-08-04-oil/oil.html#borkum-n05-a",
    "title": "Oil and Gas Offshore Installations",
    "section": "Borkum + N05-A",
    "text": "Borkum + N05-A\nOn July 2, 2025, the German federal cabinet approved a treaty that permits Dutch-led natural gas extraction extending into German territorial waters near Borkum. The initiative is intended to enhance energy security and meet commitments outlined in the governing coalition‚Äôs energy strategy. However, environmental organizations have raised concerns, warning that the project poses risks to the Wadden Sea, undermines climate objectives, and lacks adequate public scrutiny and legal oversight. The agreement still requires legislative ratification and is subject to ongoing judicial review. Source: Tagesschau.\nThe N05-A platform is situated in Dutch waters, approximately 1.5 kilometers from the German maritime border. By autumn 2024, the first well is expected to be drilled, enabling natural gas extraction from the Dutch sector of the North Sea. Source: Project GEMS, Spiegel.\nThe proposed gas field is located in close proximity to the Borkum Reef Ground NCA. This area is the smallest of three designated nature conservation areas within Germany‚Äôs Exclusive Economic Zone (EEZ) in the North Sea. It has been recognized as a Special Area of Conservation (SAC) under the EU Habitats Directive, and was officially designated a German NCA in 2017. Sources: Borkum Reef Ground NCA, Oceana.\n\nOil_4plot<-Oil_3plot+\n  geom_point(aes(x = 6.3620, y = 53.67800), color = 'orange',size=4,shape=17)+\n    annotate(\"text\", \n           x = 6.3620-0.5, y = 53.678, label = \"N05-A\",size=4,colour ='orange')+\n    annotate(\"segment\", \n           x = 6.3620, xend = 6.3620-0.2,\n           y =  53.678, yend = 53.678,colour = 'orange', linewidth=1)+\n  \n  annotate(\"text\", \n           x = 6.70-1.6, y = 53.89, label = \"Borkum Reef Ground\",size=4,colour ='#2d6a4f')+\n  annotate(\"segment\", \n           x = 6.70-0.4, xend = 6.70-0.8,\n           y =  53.89, yend = 53.89,colour = '#2d6a4f', linewidth=1)\nOil_4plot"
  },
  {
    "objectID": "blog/2025-09-01-cables/cables.html",
    "href": "blog/2025-09-01-cables/cables.html",
    "title": "Underwater Power and Telecomunication Cables",
    "section": "",
    "text": "In this month‚Äôs blog post, I take a closer look at the network of underwater cables stretching across the German North Sea. Using openly available geospatial data from EMODnet, I downloaded and worked with datasets covering both telecommunication and power cables. With R as my main analysis tool, I walk you through the process of exploring, cleaning, and visualizing the data. Building this map deepened my understanding of how these often-invisible infrastructures are distributed across the seafloor.\n\n\nUnderwater (submarine, or undersea) cables include cables use for telecommunication and for power. Although limited impacts have been found, the disturbance of the seabed during installation can disrupt benthic communities. Power cables additionally emit electromagnetic fields (EMFs) which might affect sensitive species such as migratory animals. Furthermore, these cables can warm the water surrounding them, but their effects by this are poorly known (see compilation of effects of cables in: Lloret et al.¬†2022, Hale et al.¬†2024)\n\n\n   \n\n\nImage from a underwater cable from BBC\nWhile it‚Äôs difficult to pinpoint an exact annual number, estimates suggest that hundreds of kilometers of new submarine cables are installed each year to meet the growing global demand for internet and telecommunications. However, the number of new cables installed varies significantly each year, with the total number of operational and planned cables exceeding 600 in early 2025.\n\n\n  \n\n\nImage from the installation of undersea cable in waters from the Hiddensee island at Germany Mecklenburg-Western Pomerania Baltic Sea from Energy Industry Review"
  },
  {
    "objectID": "blog/2025-09-01-cables/cables.html#effects",
    "href": "blog/2025-09-01-cables/cables.html#effects",
    "title": "Underwater Power and Telecomunication Cables",
    "section": "Effects",
    "text": "Effects\n\nViking Link 2017\nFarr et al.¬†2021\nLloret et al.¬†2022\nMiddleton et al 2023\nHale et al 2024\nBuck et al 2024"
  },
  {
    "objectID": "blog/2025-09-01-cables/cables.html#telecommuncations",
    "href": "blog/2025-09-01-cables/cables.html#telecommuncations",
    "title": "Underwater Power and Telecomunication Cables",
    "section": "Telecommuncations",
    "text": "Telecommuncations\n\nOcean Cables Map - Submarine networks\nIOEMA Fibre optic"
  },
  {
    "objectID": "blog/2025-09-01-cables/cables.html#power",
    "href": "blog/2025-09-01-cables/cables.html#power",
    "title": "Underwater Power and Telecomunication Cables",
    "section": "Power",
    "text": "Power\n\nPower cable installations connected to Offshore Wind farms\nNordLink"
  },
  {
    "objectID": "blog/2025-09-01-cables/cables.html#both-1",
    "href": "blog/2025-09-01-cables/cables.html#both-1",
    "title": "Underwater Power and Telecomunication Cables",
    "section": "Both",
    "text": "Both\n\nSubmarine cable map - How do the submarine cables get installed - Video\nCable instalation"
  },
  {
    "objectID": "blog/2025-10-13-ezz/eez.html",
    "href": "blog/2025-10-13-ezz/eez.html",
    "title": "Exclusive Economic Zones (EEZ)",
    "section": "",
    "text": "Intro\nMaritime borders are the divisions of the Earth‚Äôs water surface areas using physiographic or geopolitical criteria. They define the spatial limits of a country‚Äôs jurisdiction and rights over maritime resources and activities.\nTerritorial waters. This is the area of sea right next to a country‚Äôs coast, stretching up to 12 miles out. In this zone, the country has the same rights as it does on land, it controls the water, the air above it, and the seabed.\nEEZ. The Exclusive Economic Zone (EEZ) extends from 12 to 200 nautical miles from a country‚Äôs coastline, where the coastal state has exclusive rights to explore, exploit, manage, and conserve natural resources such as fish, oil, and gas. However, it cannot restrict the passage or overflight of foreign ships and aircraft unless such movement directly affects its economic interests.\n\n\nData\nTo download data from the EEZ and territorial waters from Germany: go to GeoSeaPortal>In the theme gallery>move to Seegrenzen.\nOnce there, click on Was mochsten Sie tun? then Inhaltsbaum on the bottom, and in Kartenebenen, click on the tool sign, and then in the download sign. When it ask WFS download, you can choose shapefile for example. Download Seevermessung_DeutscheSeegrenzen:MaritimeBoundaryTerritorialSea and Seevermessung_DeutscheSeegrenzen:AWZ.\n\n\n\n\n\n\n\nRead\nPrepare to read shapefiles, by loading the packages and providing the folder where the data is stored.\n\nlibrary(here)\nlibrary(sf)\n\n\nThis_directory<-here()\n\nLoad the corresponding shapefiles. Now they should be in your R environment.\n\nGermany_eez<-st_read(paste0(This_directory,\"/MaritimeBoundaryAWZ.shp\"))\nGermany_mts<-st_read(paste0(This_directory,\"/MaritimeBoundaryTerritorialSea.shp\"))\n\n\n\nBase Map\nLoad the package ggplot2 to create plots.\n\nlibrary(ggplot2)\n\nUse the function geom_sf to visualize the shapefiles.\n\nMap_eez<-ggplot() + \n  geom_sf(data = Germany_eez, color='#c1121f',linewidth=1.5) + \n  geom_sf(data = Germany_mts, color='#780000',linewidth=1,linetype=\"dotted\")\nMap_eez\n\nUse the package GermanNorthSea to add the land.\n\nlibrary(GermanNorthSea)\n\n\nMap_eez<- Map_eez + \n  geom_sf(data = GermanNorthSea::German_EEZ, colour = '#43585E', fill = 'transparent')+\n  geom_sf(data = GermanNorthSea::German_land, colour = '#43585E', fill = '#43585E')+\n  coord_sf(xlim = c(3,9),\n           ylim = c(53,56),\n           label_axes = list(left = \"N\", bottom = 'E'))\nMap_eez\n\nAdd the attributes and the theme to your base map.\n\nMap_eez<- Map_eez +\n  \n  theme(\n  axis.text.x = element_text(size=10,vjust = 12,color='#3d5a80'),\n  axis.text.y = element_text(color='#3d5a80',size=10,margin = margin(0,-1.30,0,1, unit = 'cm')),\n  axis.title = element_blank(),\n  axis.ticks.length=unit(-0.20, \"cm\"),\n  panel.grid.major = element_blank(),\n  panel.grid.minor = element_blank(),\n  panel.background = element_rect(fill = '#F2F2F2'))+\n  \n  xlab('Longitude')+ylab('Latitude')+\n  \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, linewidth=1.5))+\n  \n  scale_x_continuous(breaks = c(4,6,8)) +\n  scale_y_continuous(breaks = c(53.5,54.5,55.5))\nMap_eez\n\nAdd legend\n\nMap_eez +\n  annotate(\"text\", x = 3.1, y = 54.28, colour = \"black\", label = \"Maritime Boundaries\", size=6, hjust=0)+\n  \n  annotate(\"segment\", x = 3.1, xend = 3.5,y = 54.1, yend = 54.1, \n           colour = '#780000', size=1, linetype = \"dotted\")+\n  annotate(\"text\", x = 3.6, y = 54.1, colour = \"black\", label = \"Territorial waters\", size=4, hjust=0)+\n  \n  annotate(\"segment\", x = 3.1, xend = 3.5,y = 54.0, yend = 54.0, \n           colour = '#c1121f', size=1.2, linetype = \"solid\")+\n  annotate(\"text\", x = 3.6, y = 54.0, colour = \"black\", label = \"Economic Exclusive Zone (EEZ)\", size=4, hjust=0)\n\n\n\n\n\n\n\n\n\n\n\nUsing a package\nThe R package rgeoboundaries provides country political administrative boundaries.\nTo install the package\n\ninstall.packages(\"mregions2\")\n\nTo load the package\n\nlibrary(mregions2)\n\nTo explore the info containing\n\nregions<-gaz_search_by_type(\"EEZ\") #this might take some time, be patience\n\nLoad tidyverse to filter the country boundaries of interest.\n\nlibrary(tidyverse)\n\nWe know that Germany borders with Denmark, Netherlands and Norway at sea, so we will download those borders.\n\nborders<-regions %>%\n  filter(preferredGazetteerName %in% c(\"German Exclusive Economic Zone\",\n                                       \"Danish Exclusive Economic Zone\",\n                                       \"British Exclusive Economic Zone\",\n                                       \"Norwegian Exclusive Economic Zone\",\n                                       \"Dutch Exclusive Economic Zone\"\n                                       ))\n\nThese are the identifiers to download the border geometries.\n\nborders$MRGID\n\nGet geometry\n\nGermany<-gaz_geometry(5669, format = \"sfc\")\nDenmark<-gaz_geometry(5674, format = \"sfc\")\nNorway<-gaz_geometry(5686, format = \"sfc\")\nUK<-gaz_geometry(5696, format = \"sfc\")\nNetherlands<-gaz_geometry(5668, format = \"sfc\")\n\nExport\n\nunique(st_geometry_type(Germany))\nGermany_clean <- Germany[st_geometry_type(Germany) != \"GEOMETRYCOLLECTION\", ]\nGermany_cast <- st_collection_extract(Germany, \"POLYGON\")  \nst_write(Germany_cast,dsn = file.path(paste0(This_directory,\"/Germany.shp\")))\n\nunique(st_geometry_type(Denmark))\nDenmark_clean <- Denmark[st_geometry_type(Denmark) != \"GEOMETRYCOLLECTION\", ]\nDenmark_cast <- st_collection_extract(Denmark, \"POLYGON\")  \nst_write(Denmark_cast,dsn = file.path(paste0(This_directory,\"/Denmark.shp\")))\n\nunique(st_geometry_type(Norway))\nNorway_clean <- Norway[st_geometry_type(Norway) != \"GEOMETRYCOLLECTION\", ]\nNorway_cast <- st_collection_extract(Norway, \"POLYGON\")  \nst_write(Norway_cast,dsn = file.path(paste0(This_directory,\"/Norway.shp\")))\n\nunique(st_geometry_type(UK))\nUK_clean <- UK[st_geometry_type(UK) != \"GEOMETRYCOLLECTION\", ]\nUK_cast <- st_collection_extract(UK, \"POLYGON\")  \nst_write(UK,dsn = file.path(paste0(This_directory,\"/UK.shp\")))\n\nunique(st_geometry_type(Netherlands))\nNetherlands_clean <- Netherlands[st_geometry_type(Netherlands) != \"GEOMETRYCOLLECTION\", ]\nNetherlands_cast <- st_collection_extract(Netherlands, \"POLYGON\")  \nst_write(Netherlands,dsn = file.path(paste0(This_directory,\"/Netherlands.shp\")))\n\n\n\nRead\nBase map\n\nBoundaries_plot<-ggplot() + \n  geom_sf(data = Germany, color='#c1121f',linewidth=1.5)+\n  geom_sf(data = Netherlands, color='#e76f51',linewidth=1.5)+\n  geom_sf(data = Denmark, color='#ffc857',linewidth=1.5)+\n  geom_sf(data = Norway, color='#177e89',linewidth=1.5)+\n  geom_sf(data = UK, color='#084c61',linewidth=1.5)\n\nLand reference\n\nBoundaries_plot<- Boundaries_plot+\n  geom_sf(data = GermanNorthSea::German_land, colour = '#43585E', fill = '#43585E')+\n  coord_sf(xlim = c(2,9),\n           ylim = c(53,58),\n           label_axes = list(left = \"N\", bottom = 'E'))\nBoundaries_plot\n\nAdd theme\n\nBoundaries_plot<- Boundaries_plot+\n  theme(\n  axis.text.x = element_text(size=10,vjust = 12,color='#3d5a80'),\n  axis.text.y = element_text(color='#3d5a80',size=10,margin = margin(0,-1.30,0,1, unit = 'cm')),\n  axis.title = element_blank(),\n  axis.ticks.length=unit(-0.20, \"cm\"),\n  panel.grid.major = element_blank(),\n  panel.grid.minor = element_blank(),\n  panel.background = element_rect(fill = '#F2F2F2'))+\n  \n  xlab('Longitude')+ylab('Latitude')+\n  \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, linewidth=1.5))+\n  \n  scale_x_continuous(breaks = c(4,6,8)) +\n  scale_y_continuous(breaks = c(53.5,54.5,55.5))\nBoundaries_plot\n\nAdd legends\n\nBoundaries_plot<- Boundaries_plot+ \n  \n  annotate(\"text\", x = 2.1, y = 57.9, colour = \"black\", label = \"Maritime Boundaries\", size=6, hjust=0)+\n  \n    annotate(\"segment\", x = 2.1, xend = 2.6,y = 57.6, yend = 57.6, \n           colour = '#ffc857', size=1.2)+\n  annotate(\"text\", x = 2.7, y = 57.6, colour = \"black\", label = \"Denmark Border\", size=3, hjust=0)+\n  \n  annotate(\"segment\", x = 2.1, xend = 2.6,y = 57.4, yend = 57.4, \n           colour = '#e76f51', size=1.2)+\n  annotate(\"text\", x = 2.7, y = 57.4, colour = \"black\", label = \"Netherlands Border\", size=3, hjust=0)+\n  \n  annotate(\"segment\", x = 2.1, xend = 2.6,y = 57.2, yend = 57.2, \n           colour = '#084c61', size=1.2)+\n  annotate(\"text\", x = 2.7, y = 57.2, colour = \"black\", label = \"United Kingdom Border\", size=3, hjust=0)+\n  \n  annotate(\"segment\", x = 2.1, xend = 2.6,y = 57, yend = 57, colour = '#177e89', size=1.2)+\n  annotate(\"text\", x = 2.7, y = 57, colour = \"black\", label = \"Norway Border\", size=3, hjust=0)+\n\n  annotate(\"text\", x = 4.9, y = 54.55, colour = \"black\", label = \"Netherlands\", size=3, hjust=0, angle=-45+10)+\n  annotate(\"text\", x = 5.1, y = 54.7, colour = \"black\", label = \"Germany\", size=3, hjust=0, angle=-45+10)+\n  \n  annotate(\"text\", x = 6.9, y = 55.4, colour = \"black\", label = \"Denmark\", size=3, hjust=0, angle=-45+25)+\n  annotate(\"text\", x = 6.7, y = 55.25, colour = \"black\", label = \"Germany\", size=3, hjust=0, angle=-45+25)+\n  \n  annotate(\"text\", x = 2.8, y = 53.5, colour = \"black\", label = \"UK\", size=3, hjust=0, angle=45+55)+\n  annotate(\"text\", x = 3.2, y = 53.3, colour = \"black\", label = \"Netherlands\", size=3, hjust=0, angle=45+55)+\n  \n  annotate(\"text\", x = 3.1, y = 55.7, colour = \"black\", label = \"UK\", size=3, hjust=0, angle=45+30)+\n  annotate(\"text\", x = 3.5, y = 55.81, colour = \"black\", label = \"Germany\", size=3, hjust=0, angle=-45+10)+\n  \n  annotate(\"text\", x = 6, y = 56.8, colour = \"black\", label = \"Denmark\", size=3, hjust=0, angle=30)+\n  annotate(\"text\", x = 5.8, y = 56.95, colour = \"black\", label = \"Norway\", size=3, hjust=0, angle=30)+\n  NULL\nBoundaries_plot\n\n\n\n\n\n\n\n\nFurther reading\n\nBSH\nRgeoboundaries Package\nMarine regions\nMarine Spatial Planning Europe\nEMODnet\n\n\n\n\nCitations: For package rgeoboundaries, please cite: Runfola D, Anderson A, Baier H, Crittenden M, Dowker E, Fuhrig S, et al.¬†(2020) geoBoundaries: A global database of political administrative boundaries. PLoS ONE 15(4): e0231866. https://doi.org/10.1371/journal.pone.0231866"
  },
  {
    "objectID": "blog/2025-11-09-MPAs/protected.html",
    "href": "blog/2025-11-09-MPAs/protected.html",
    "title": "Marine Protected Areas",
    "section": "",
    "text": "Marine Protected Areas (MPAs) are sections of the ocean where human activities are regulated or restricted to conserve marine biodiversity, ecosystems, and cultural resources. They aim to protect habitats, species, and natural processes from threats like overfishing, pollution, and habitat destruction. MPAs vary in size, purpose, and level of protection, ranging from fully protected no-take zones to areas allowing sustainable use."
  },
  {
    "objectID": "blog/2025-11-09-MPAs/protected.html#spas",
    "href": "blog/2025-11-09-MPAs/protected.html#spas",
    "title": "Marine Protected Areas",
    "section": "SPAs",
    "text": "SPAs\nSpecial Protection Areas (SPAs) at sea are marine zones designated under the European Union‚Äôs Birds Directive to protect habitats critical for wild bird species, particularly those that are rare, threatened, or migratory. In Germany, these areas form part of the Natura 2000 network and often overlap with Marine Protected Areas (MPAs) under other environmental directives, such as the Habitats Directive.\nTo download data from the EEZ and territorial waters from Germany: go to GeoSeaPortal>In the theme gallery>move to Seegrenzen.\nAlternativaly, go to GeoSeaPortal. The zip contains several shapefiles including NatureConservation.\nOther option is eea."
  },
  {
    "objectID": "blog/2025-11-09-MPAs/protected.html#scas",
    "href": "blog/2025-11-09-MPAs/protected.html#scas",
    "title": "Marine Protected Areas",
    "section": "SCAs",
    "text": "SCAs\nSpecial Areas of Conservation (SACs), sometimes referred to as SCAs in Germany, are protected sites designated under the EU Habitats Directive to conserve important natural habitats and species (excluding birds). In marine areas, they help protect features like reefs, sandbanks, and marine mammals, forming part of the Natura 2000 network alongside Special Protection Areas (SPAs).\nTo download the data go to: Europen Environment Agency. This file contains a more complete data from the natura 2000 sites."
  },
  {
    "objectID": "blog/2025-12-04-countour/countour.html",
    "href": "blog/2025-12-04-countour/countour.html",
    "title": "Contour lines",
    "section": "",
    "text": "This months blog post is about how to create contour lines from a raster file, and how to add labels using the package shadowtext.\nA contour line (also isoline, isopleth, isoquant or isarithm) of a function of two variables is a curve along which the function has a constant value, so that the curve joins points of equal value (Wikipedia).\nIn cartography, a contour line (often just called a ‚Äúcontour‚Äù) joins points of equal elevation (height) above a given level, such as mean sea level. A contour map is a map illustrated with contour lines, for example a topographic map, which thus shows valleys and hills, and the steepness or gentleness of slopes. The contour interval of a contour map is the difference in elevation between successive contour lines (Wikipedia)."
  },
  {
    "objectID": "blog/2025-12-04-countour/countour.html#lines",
    "href": "blog/2025-12-04-countour/countour.html#lines",
    "title": "Contour lines",
    "section": "Lines",
    "text": "Lines\n\nBath_5df <- as.data.frame(Bath_1raster, xy = TRUE)\n\n\nlibrary(tidyverse)\n\n\nBath_6sub <- Bath_5df  %>%\n  filter(x > 2 & x < 10)%>%\n  filter(y > 52 & y < 57)%>%\n  rename(Bathymetry=3) %>%\n  filter(Bathymetry < 10)\n\n\nBath_7centroids <- Bath_4lines %>%\n  group_by(level) %>%\n  summarise(geometry = st_centroid(st_union(geometry)))\n\n\nBath_8plot<-ggplot() +\n  geom_raster(data = Bath_6sub , aes(x = x, y = y, fill = Bathymetry)) +\n  scale_fill_viridis_c(option = \"mako\")+\n  geom_sf(data = Bath_4lines, color = \"grey\", size = 0.3) +\n  geom_sf(data = GermanNorthSea::German_land , color='#ffffbe', fill='#ffffbe')+\n  geom_sf_text(data = Bath_7centroids, aes(label = -level), \n               inherit.aes = FALSE, size = 4, color = \"white\") +\n  theme_void() +\n  coord_sf(xlim = c(3.3,8.8),\n           ylim = c(53.2,55.8),\n           label_axes = list(left = \"N\", bottom = 'E'))+\n  theme(legend.position = 'none')\nBath_8plot"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Contour lines\n\n\n\n\n\n\n\nr\n\n\nggplot2\n\n\ngermansea\n\n\nY2025\n\n\n\n\nIn this blog post, we‚Äôll explore how to plot contour lines from a raster using bathymetry data as an example.\n\n\n\n\n\n\nDec 4, 2025\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nMarine Protected Areas\n\n\n\n\n\n\n\nr\n\n\nggplot2\n\n\ngermansea\n\n\nY2025\n\n\n\n\nIn this blog post, we‚Äôll explore maritime protected areas (MPAs), walking through the process of downloading the data and visualizing it.\n\n\n\n\n\n\nNov 9, 2025\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nExclusive Economic Zones (EEZ)\n\n\n\n\n\n\n\nr\n\n\nggplot2\n\n\ngermansea\n\n\nY2025\n\n\n\n\nIn this blog post, we‚Äôll explore maritime borders, including territorial waters and Exclusive Economic Zones (EEZ), by walking through the process of downloading the data and visualizing it.\n\n\n\n\n\n\nOct 13, 2025\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nUnderwater Power and Telecomunication Cables\n\n\n\n\n\n\n\nr\n\n\nggplot2\n\n\ngermansea\n\n\nY2025\n\n\n\n\nIn this month‚Äôs blog post, I map the underwater cable network of the German North Sea using open data from EMODnet. With R, I explore and visualize both telecommunication and power cables.\n\n\n\n\n\n\nSep 1, 2025\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nOil and Gas Offshore Installations\n\n\n\n\n\n\n\nr\n\n\nggplot2\n\n\ngermansea\n\n\nY2025\n\n\n\n\nIn this month‚Äôs blog post, we‚Äôll explore oil and gas infrastructure in the German North Sea, by using EMODnet geospatial data to map offshore installations and pipelines, as well as focusing on a site near the ecologically sensitive Borkum Reef, revealing why recently proposed projects there have sparked environmental concern.\n\n\n\n\n\n\nAug 4, 2025\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nOffshore Wind Farms\n\n\n\n\n\n\n\nr\n\n\nggplot2\n\n\ngermansea\n\n\nY2025\n\n\n\n\nThis blog post demonstrates how to visualize offshore wind farm data in the German North Sea using R. It covers data download, exploration, mapping with ggplot2, and calculating areas developed before 2016.\n\n\n\n\n\n\nJul 1, 2025\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nShipping traffic\n\n\n\n\n\n\n\nr\n\n\nggplot2\n\n\ngermansea\n\n\nY2025\n\n\n\n\nIn this blog post, I demonstrate how to visualize shipping traffic data using R. The tutorial covers downloading the dataset from EMODnet, performing exploratory data analysis, and creating a map using ggplot2.\n\n\n\n\n\n\nJun 2, 2025\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nLight pollution\n\n\n\n\n\n\n\nr\n\n\nggplot2\n\n\ngermansea\n\n\nY2025\n\n\n\n\nIn this month‚Äôs post, I‚Äôll show you how to create a map using radiance data, often associated with light pollution, collected by the Visible Infrared Imaging Radiometer Suite (VIIRS).\n\n\n\n\n\n\nMay 5, 2025\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nSea surface temperature\n\n\n\n\n\n\n\nr\n\n\nggplot2\n\n\ngermansea\n\n\nY2025\n\n\n\n\nIn this blog post, I walk you through the process of visualizing sea surface temperature in R. From downloading the dataset to reading it and creating a map using ggplot.\n\n\n\n\n\n\nApr 7, 2025\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nFishing effort\n\n\n\n\n\n\n\nr\n\n\nggplot2\n\n\ngermansea\n\n\nY2025\n\n\n\n\nIn this blog post, I walk you through the process of visualizing Global Fishing Watch data in R, covering from downloading the dataset to reading it and creating a map using ggplot.\n\n\n\n\n\n\nMar 3, 2025\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nDistance to coast\n\n\n\n\n\n\n\nr\n\n\nggplot2\n\n\ngermansea\n\n\nY2025\n\n\n\n\nIn this blog post, I share a step-by-step guide on how to use raster data from distance to the coast. I walk you through the steps I used using the North German Sea as an example.\n\n\n\n\n\n\nFeb 20, 2025\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nBathymetry\n\n\n\n\n\n\n\nr\n\n\nggplot2\n\n\ngermansea\n\n\nY2025\n\n\n\n\nHere are the steps I used for creating a bathymetric map in R. From where to download bathymetric data to how to read it and plot it in R.\n\n\n\n\n\n\nJan 10, 2025\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\ntmap\n\n\n\n\n\n\n\nr\n\n\nsula\n\n\nY2024\n\n\nbiologging\n\n\ngis\n\n\n\n\nCreate an interactive map to explore your data.\n\n\n\n\n\n\nDec 4, 2024\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nComplete or incomplete trips\n\n\n\n\n\n\n\nr\n\n\nggplot2\n\n\nsula\n\n\nY2024\n\n\nbiologging\n\n\n\n\nIdentify trips with large gaps and classify the trip as complete or incomplete.\n\n\n\n\n\n\nNov 5, 2024\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nDistance between consecutive points\n\n\n\n\n\n\n\nr\n\n\nggplot2\n\n\nsula\n\n\nY2024\n\n\nbiologging\n\n\n\n\nThis posts allows to calculate distance between consecutive locations.\n\n\n\n\n\n\nOct 8, 2024\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nIdentify events\n\n\n\n\n\n\n\nr\n\n\nggplot2\n\n\nsula\n\n\nY2024\n\n\nbiologging\n\n\n\n\nAssign a number to each event.\n\n\n\n\n\n\nSep 19, 2024\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nRemove undesired locations\n\n\n\n\n\n\n\nr\n\n\nggplot2\n\n\nsula\n\n\nY2024\n\n\nbiologging\n\n\n\n\nCreate a buffer to remove locations.\n\n\n\n\n\n\nAug 1, 2024\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nInterpolate a path\n\n\n\n\n\n\n\nr\n\n\nggplot2\n\n\nY2024\n\n\nbiologging\n\n\nsula\n\n\n\n\nDoing a linear interpolation of tracks of animals.\n\n\n\n\n\n\nJul 5, 2024\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nDistance from point\n\n\n\n\n\n\n\nr\n\n\nggplot2\n\n\nY2024\n\n\ngermansea\n\n\ngis\n\n\n\n\nCalculate distance from a point.\n\n\n\n\n\n\nJun 4, 2024\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nUsing magick for image manipulation\n\n\n\n\n\n\n\nr\n\n\nmagick\n\n\nY2024\n\n\n\n\nAdd text and margins on images.\n\n\n\n\n\n\nMay 2, 2024\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nCreate a buffer\n\n\n\n\n\n\n\nr\n\n\ngis\n\n\nggplot2\n\n\nY2024\n\n\n\n\nThis post is about how to create a spatial buffer of 1 km around a point.\n\n\n\n\n\n\nApr 4, 2024\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nSecondary-axis environmental plot\n\n\n\n\n\n\n\nr\n\n\nggplot2\n\n\nY2024\n\n\ngis\n\n\n\n\nCreate a secondary-axis plot from SST and CHL.\n\n\n\n\n\n\nMar 11, 2024\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nEnvironmental variables\n\n\n\n\n\n\n\nr\n\n\nggplot2\n\n\nY2024\n\n\ngis\n\n\n\n\nDownload and plot SST data from a specific period.\n\n\n\n\n\n\nFeb 6, 2024\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nCreate a calendar\n\n\n\n\n\n\n\nr\n\n\nggplot2\n\n\nY2024\n\n\n\n\nThis post is to create a calendar.\n\n\n\n\n\n\nJan 15, 2024\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nusing arrows\n\n\n\n\n\n\n\nr\n\n\nggplot2\n\n\nseadens\n\n\nY2023\n\n\n\n\nThis post is on how to use arrows in a plot.\n\n\n\n\n\n\nDec 4, 2023\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nsecondary x title\n\n\n\n\n\n\n\nr\n\n\nggplot2\n\n\nY2023\n\n\n\n\nThis post is on how to articially create a secondary x title.\n\n\n\n\n\n\nNov 2, 2023\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nInside legend\n\n\n\n\n\n\n\nr\n\n\nggplot2\n\n\nsula\n\n\nY2023\n\n\n\n\nCreate a custom legend using annotations of text and rectangles inside the plot.\n\n\n\n\n\n\nOct 2, 2023\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nReference legend multiplots\n\n\n\n\n\n\n\nr\n\n\nggplot2\n\n\ngis\n\n\nY2023\n\n\n\n\nCreate a plot to be use as reference legend for multiple plots\n\n\n\n\n\n\nSep 1, 2023\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nCustom legends in a map\n\n\n\n\n\n\n\nr\n\n\nggplot2\n\n\nseadens\n\n\nY2023\n\n\n\n\nPlace the legend inside the map and custom the legend title\n\n\n\n\n\n\nAug 2, 2023\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nCustom points in a map\n\n\n\n\n\n\n\nr\n\n\nggplot2\n\n\nseadens\n\n\nY2023\n\n\n\n\nPlot different size, color and shape points\n\n\n\n\n\n\nJul 13, 2023\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\ngganimate\n\n\n\n\n\n\n\nr\n\n\nggplot2\n\n\nY2023\n\n\nbiologging\n\n\n\n\nCreate an animation of your tracks.\n\n\n\n\n\n\nJun 1, 2023\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nGithub page presentations\n\n\n\n\n\n\n\nr\n\n\ngithub\n\n\nY2023\n\n\n\n\nPublish your slides from a html file.\n\n\n\n\n\n\nMay 5, 2023\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nGrid, Raster, Colors\n\n\n\n\n\n\n\nr\n\n\ngis\n\n\nY2023\n\n\n\n\nCreate a grid, then a raster, and plot them with your custom colors.\n\n\n\n\n\n\nApr 6, 2023\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nMapping in R\n\n\n\n\n\n\n\nr\n\n\nggplot2\n\n\nY2023\n\n\ngis\n\n\n\n\nCreate a map of Europe in ggplot2.\n\n\n\n\n\n\nMar 4, 2023\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nSubset shapefile\n\n\n\n\n\n\n\nr\n\n\ngis\n\n\nY2023\n\n\n\n\nExtract a specific polygon from a shapefile and export it as new shapefile.\n\n\n\n\n\n\nFeb 4, 2023\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nCustom made polygon\n\n\n\n\n\n\n\nqgis\n\n\ngis\n\n\nY2023\n\n\n\n\nCreate a polygon in QGIS using google maps as background\n\n\n\n\n\n\nJan 23, 2023\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nCircadian classification\n\n\n\n\n\n\n\nr\n\n\nbiologging\n\n\nsula\n\n\nY2022\n\n\n\n\nCreate a column with the classification day or night\n\n\n\n\n\n\nDec 4, 2022\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nMastodon\n\n\n\n\n\n\n\nY2022\n\n\n\n\nMigrando a mastodon\n\n\n\n\n\n\nNov 20, 2022\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nIdentify gaps\n\n\n\n\n\n\n\nr\n\n\nbiologging\n\n\nsula\n\n\nY2022\n\n\n\n\nFind the gaps between recordings\n\n\n\n\n\n\nOct 3, 2022\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nKernel UD considerations\n\n\n\n\n\n\n\nr\n\n\nbiologging\n\n\nY2022\n\n\n\n\nSome things to consider before making kernel density estimations.\n\n\n\n\n\n\nSep 14, 2022\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nCount days\n\n\n\n\n\n\n\nr\n\n\nbiologging\n\n\nsula\n\n\nY2022\n\n\n\n\nHow to add a day number as a column, and see differences as days pass.\n\n\n\n\n\n\nAug 17, 2022\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nLocate nest\n\n\n\n\n\n\n\nr\n\n\nbiologging\n\n\nsula\n\n\nY2022\n\n\n\n\nHow to locate the nest of the bird using their GPS locations.\n\n\n\n\n\n\nJul 1, 2022\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nTime formats\n\n\n\n\n\n\n\nr\n\n\nbiologging\n\n\nY2022\n\n\n\n\nHow to convert your time to a format that R can understand as time.\n\n\n\n\n\n\nJun 30, 2022\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nSpeed\n\n\n\n\n\n\n\nr\n\n\nbiologging\n\n\nY2022\n\n\n\n\nHow to calculate speed using time and distance between points.\n\n\n\n\n\n\nMay 23, 2022\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nHabitat use\n\n\n\n\n\n\n\nr\n\n\nbiologging\n\n\nY2022\n\n\n\n\nHow to assign habitat use to animal locations.\n\n\n\n\n\n\nApr 7, 2022\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nInterpolation\n\n\n\n\n\n\n\nr\n\n\nbiologging\n\n\nY2022\n\n\n\n\nHow to interpolate tracking data.\n\n\n\n\n\n\nMar 22, 2022\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nTime overlaps\n\n\n\n\n\n\n\nr\n\n\nbiologging\n\n\nY2022\n\n\n\n\nFind overlapping time periods.\n\n\n\n\n\n\nFeb 24, 2022\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nShared Areas\n\n\n\n\n\n\n\nr\n\n\nY2022\n\n\nbiologging\n\n\n\n\nCalculate area per polygon, their intersection and the shared areas.\n\n\n\n\n\n\nJan 21, 2022\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nEMbC\n\n\n\n\n\n\n\nr\n\n\nbiologging\n\n\nY2021\n\n\n\n\nClassify behaviours using Expectation-Maximization Binary Clustering.\n\n\n\n\n\n\nNov 25, 2021\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nGit & Github\n\n\n\n\n\n\n\nr\n\n\ngithub\n\n\nY2021\n\n\n\n\nA short intro.\n\n\n\n\n\n\nOct 27, 2021\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nHome Range & adehabitatHR\n\n\n\n\n\n\n\nr\n\n\nbiologging\n\n\nY2021\n\n\n\n\nExport polygons generated from adehabitat.\n\n\n\n\n\n\nSep 24, 2021\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nColores en mapas\n\n\n\n\n\n\n\nqgis\n\n\nr\n\n\nY2021\n\n\ngis\n\n\n\n\nCambiar colores en un en un mapa en ggplot2 y en QGIS.\n\n\n\n\n\n\nJul 5, 2021\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nPaquetes\n\n\n\n\n\n\n\nr\n\n\npackage\n\n\nY2023\n\n\n\n\nComo crear tu primer paquete con datos y algunas funciones.\n\n\n\n\n\n\nJun 3, 2021\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nPagina distill\n\n\n\n\n\n\n\nr\n\n\nY2021\n\n\n\n\nComo crear tu propia pagina y agregar contenidos.\n\n\n\n\n\n\nJun 1, 2021\n\n\nMiriam Lerma\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Miriam Lerma‚Äôs website",
    "section": "",
    "text": "About\nLearn a little bit about me, my interests and find my contact information at the about section. \n\n\n Publications\nYou can find abstracts and links to my publications. If you can‚Äôt access a publication please don‚Äôt hesitate to contact me. \n\n\n Teaching\nIn this section, you will find a variety of topics that you might find interesting, such as AI tools, tracking functions, and selecting the right journal, among others. I‚Äôve also prepared materials for teaching R, a programming language for statistical computing and graphics. If you‚Äôre interested in accessing these resources, you can locate them here. \n\n\n Packages\nI develop R packages that are useful for my work. I‚Äôm often working on new packages so stay tuned. \n\n\n Blog\nI blog about what I consider are useful topics and can help other people. I write mostly about R and QGIS, but some of my talks are there. I blog in English and Spanish."
  },
  {
    "objectID": "packages/2021-05-14-spheniscus/spheniscus.html",
    "href": "packages/2021-05-14-spheniscus/spheniscus.html",
    "title": "spheniscus",
    "section": "",
    "text": "Intro\nEl objetivo de este paquete es:\n- Hacer disponibles datos crudos de TDR para que se familiaricen con el formato.\n- Ayudarte a limpiar los datos de TDR para obtener par√°metros de buceo de los animales muestreados.\nInstrucciones en ingles: https://github.com/MiriamLL/spheniscus\n\n\nInstalaci√≥n\nEl paquete estar√° disponible solo por GitHub\n\ninstall.packages(\"devtools\")\ndevtools::install_github(\"MiriamLL/spheniscus\")\n\n\nlibrary(spheniscus)\n\n\n\nEjemplo\nCrea un grafico con el perfil de buceos. Marca el cero con una linea roja.  El objetivo de este gr√°fico es que te permita decidir si debes corregir el cero.\n\nplot_depth(TDR_trip = TDR_trip,\n                   depth_column='Pressure',\n                   time_column='daytime')\n\n\n\n\n\n\nCitar\nLerma, M (2021). Package spheniscus (Version v1.0). Zenodo. http://doi.org/10.5281/zenodo.4709837"
  },
  {
    "objectID": "packages/2021-05-14-sula/sula.html",
    "href": "packages/2021-05-14-sula/sula.html",
    "title": "sula",
    "section": "",
    "text": "Este paquete contiene:\n\nDatos de tracks de kena (Sula dactylatra) colectados en Rapa Nui para replicar los ejemplos üóø\nTrece funciones para limpiar y calcular par√°metros de viajes a partir de datos GPS Detailed information and uses: https://github.com/MiriamLL/sula\n\n\n\nPuedes instalar este paquete desde GitHub usando:\n\n# install.packages(\"devtools\")\ndevtools::install_github(\"MiriamLL/sula\")"
  },
  {
    "objectID": "packages/2021-05-14-sula/sula.html#un-individuo",
    "href": "packages/2021-05-14-sula/sula.html#un-individuo",
    "title": "sula",
    "section": "Un individuo",
    "text": "Un individuo\nCarga los datos de GPS de un individuo.\n\nhead(GPS_01)\n\nNota Incluye columna con fecha y hora en formato POSIXct"
  },
  {
    "objectID": "packages/2021-05-14-sula/sula.html#notas-de-campo",
    "href": "packages/2021-05-14-sula/sula.html#notas-de-campo",
    "title": "sula",
    "section": "Notas de campo",
    "text": "Notas de campo\nIncluye el periodo cuando se coloc√≥ el dispositivo hasta cuando se retir√≥.\n\nNotas<-Notas\n\nNota: no corresponden al periodo real de muestreo. Se proveen estos datos para practicar las funciones."
  },
  {
    "objectID": "packages/2021-05-14-sula/sula.html#ajustar_hora",
    "href": "packages/2021-05-14-sula/sula.html#ajustar_hora",
    "title": "sula",
    "section": "ajustar_hora",
    "text": "ajustar_hora\nEsta funci√≥n corrige el tiempo de acuerdo a la zona horaria, se necesita especificar los datos GPS, el nombre de la columna que contiene datos de hora y d√≠a, el formato en el que est√°n √©stos datos, y el n√∫mero de horas de diferencia a corregir de acuerdo al GMT.\n\nGPS_gmt<-ajustar_hora(GPS_data = GPS_raw,\n                      dia_col = 'DateGMT',\n                      hora_col = 'TimeGMT',\n                      formato=\"%d/%m/%Y %H:%M:%S\",\n                      dif_hor = 5)\n\nRegresa el mismo data frame con dos columnas adicionales: dia_hora con el d√≠a y fecha original y hora_corregida con la hora correspondiente al GMT."
  },
  {
    "objectID": "packages/2021-05-14-sula/sula.html#recortar_periodo",
    "href": "packages/2021-05-14-sula/sula.html#recortar_periodo",
    "title": "sula",
    "section": "recortar_periodo",
    "text": "recortar_periodo\nEste funci√≥n permite recortar periodos dentro de los datos.\n\nGPS_recortado<-recortar_periodo(GPS_data=GPS_01,\n                                inicio='02/11/2017 18:10:00',\n                                final='05/11/2017 14:10:00',\n                                dia_col='DateGMT',\n                                hora_col='TimeGMT',\n                                formato=\"%d/%m/%Y %H:%M:%S\")\n\nNota: El formato de tiempo y hora debe ser el mismo formato que el formato de inicio y final."
  },
  {
    "objectID": "packages/2021-05-14-sula/sula.html#localizar_nido",
    "href": "packages/2021-05-14-sula/sula.html#localizar_nido",
    "title": "sula",
    "section": "localizar_nido",
    "text": "localizar_nido\nEsta funci√≥n usa el primer valor de los datos de GPS como punto de la colonia, sirve para identificar la localizaci√≥n del nido por individuo. Regresa un nuevo data frame con dos columnas: Latitude y Longitude correspondientes a la localizaci√≥n del nido.\n\nnest_loc<-localizar_nido(GPS_data = GPS_01,\n                          lat_col=\"Latitude\",\n                          lon_col=\"Longitude\")\n\nNota Asume que los datos del nido corresponde al primer registro de GPS."
  },
  {
    "objectID": "packages/2021-05-14-sula/sula.html#identificar_viajes",
    "href": "packages/2021-05-14-sula/sula.html#identificar_viajes",
    "title": "sula",
    "section": "identificar_viajesÔ∏è",
    "text": "identificar_viajesÔ∏è\nEsta funci√≥n agrega una columna de acuerdo a distancia de la colonia para determinar si esta en un viaje de alimentaci√≥n o no.\n\nGPS_trip<-identificar_viajes(GPS_data=GPS_01,\n                        nest_loc=nest_loc,\n                        distancia_km=1)\n\nEn la columna llamada trip:\nN=dentro de la distancia considerada como no viaje de alimentaci√≥n, y\nY=viaje de alimentaci√≥n."
  },
  {
    "objectID": "packages/2021-05-14-sula/sula.html#contar_viajes",
    "href": "packages/2021-05-14-sula/sula.html#contar_viajes",
    "title": "sula",
    "section": "contar_viajes",
    "text": "contar_viajes\nEsta funci√≥n agrega una columna con el n√∫mero del viaje y elimina locaciones dentro de el radio de la colonia.\n\nGPS_edited<-contar_viajes(GPS_data=GPS_trip)"
  },
  {
    "objectID": "packages/2021-05-14-sula/sula.html#dist_colonia",
    "href": "packages/2021-05-14-sula/sula.html#dist_colonia",
    "title": "sula",
    "section": "dist_colonia",
    "text": "dist_colonia\nAgrega una columna con la distancia de la colonia de cada punto. Regresa el mismo data frame con una nueva columna llamada ‚Äômaxdist_km.\n\nGPS_dist<-dist_colonia(GPS_edited = GPS_edited, \n                       nest_loc=nest_loc)\n\nNota usa CRS: 4326. Enlaces: ¬øreferencia geogr√°fica?, ¬øcual usar?"
  },
  {
    "objectID": "packages/2021-05-14-sula/sula.html#dist_puntos",
    "href": "packages/2021-05-14-sula/sula.html#dist_puntos",
    "title": "sula",
    "section": "dist_puntos",
    "text": "dist_puntos\nAgrega una columna con la distancia entre cada punto. Regresa el mismo data frame con una nueva columna llamada ‚Äòpointsdist_km‚Äô.\n\nGPS_dist<-dist_puntos(GPS_data = GPS_edited,\n                      separador='trip_number')\n\nNota usa CRS: 4326. Incluye NAs al inicio del viaje. Enlaces: ¬øreferencia geogr√°fica?, ¬øcual usar?"
  },
  {
    "objectID": "packages/2021-05-14-sula/sula.html#calcular_duracion",
    "href": "packages/2021-05-14-sula/sula.html#calcular_duracion",
    "title": "sula",
    "section": "calcular_duracion ‚è≥",
    "text": "calcular_duracion ‚è≥\nIdentifica el inicio y el final del viaje y calcula la duraci√≥n. Regresa un nuevo data frame con 4 columnas: trip_id, trip_start, trip_end y duration.\n\nduracion<-calcular_duracion(GPS_data = GPS_edited,\n                            col_diahora = \"tStamp\",\n                            formato = \"%Y-%m-%d %H:%M:%S\",\n                            unidades=\"hours\",\n                            separador=\"trip_number\")\n\nNota la duraci√≥n se calcula en valores n√∫mericos."
  },
  {
    "objectID": "packages/2021-05-14-sula/sula.html#calcular_totaldist",
    "href": "packages/2021-05-14-sula/sula.html#calcular_totaldist",
    "title": "sula",
    "section": "calcular_totaldist",
    "text": "calcular_totaldist\nCalcula distancia recorrida de la colonia por viaje.\nDebe contener la columna Longitude y Latitude con estos nombres.\nRegresa un nuevo data frame con la distancia total recorrida por viaje.\n\ntotaldist_km<-calcular_totaldist(GPS_data= GPS_edited,\n                                 separador=\"trip_number\")"
  },
  {
    "objectID": "packages/2021-05-14-sula/sula.html#calcular_maxdist",
    "href": "packages/2021-05-14-sula/sula.html#calcular_maxdist",
    "title": "sula",
    "section": "calcular_maxdist",
    "text": "calcular_maxdist\nObtiene la distancia m√°xima de la colonia por viaje.\nDebe contener la columna Longitude y Latitude con estos nombres.\nRegresa un nuevo data frame con la distancia m√°xima de la colonia por viaje.\n\nmaxdist_km<-calcular_maxdist(GPS_data = GPS_edited, \n                             nest_loc=nest_loc,\n                             separador=\"trip_number\")"
  },
  {
    "objectID": "packages/2021-05-14-sula/sula.html#calcular_tripparams",
    "href": "packages/2021-05-14-sula/sula.html#calcular_tripparams",
    "title": "sula",
    "section": "calcular_tripparams",
    "text": "calcular_tripparams\nCalcula la duraci√≥n de los viajes, la distancia m√°xima de la colonia y la distancia total recorrida. Regresa un nuevo data frame con los par√°metros por viaje.\n\ntrip_params<-calcular_tripparams(GPS_data = GPS_edited,\n                              diahora_col = \"tStamp\",\n                              formato = \"%Y-%m-%d %H:%M:%S\",\n                              nest_loc=nest_loc,\n                              separador=\"trip_number\")"
  },
  {
    "objectID": "packages/2023-04-16-seamonas/seamonas.html",
    "href": "packages/2023-04-16-seamonas/seamonas.html",
    "title": "seamonas",
    "section": "",
    "text": "seamonas provides easy access to information based on guidelines for monitoring seabirds at sea. It includes detailed table content and a sample dataset to support implementation. Information based on the HELCOM Monitoring Guidelines for Seabirds at Sea ESAS database.\nDetailed information and uses: https://github.com/MiriamLL/seamonas"
  },
  {
    "objectID": "packages/2023-04-16-seamonas/seamonas.html#code_euring",
    "href": "packages/2023-04-16-seamonas/seamonas.html#code_euring",
    "title": "seamonas",
    "section": "Code_Euring",
    "text": "Code_Euring\n\nA list of 549 species names across 9 morphological separated groups.\n\n\ndata(Code_Euring)\n\nKey fields:\n\nCode: Numerical code based on Euring. The species codes are primarily based on the EURING list, with additional ‚Äòuncertainty codes‚Äô commonly used by ESAS partners to represent species groups that are often difficult to identify under at-sea field conditions.\nScientific_name: A scientific name is the standardized, universally accepted name used to identify and classify living organisms. It follows a system called binomial nomenclature.\nEnglish_name: Official common name of the species.\nArtificial_tax_class: A custom classification system based on taxonomic and morphological similarities among species.\n\nExamples of use\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nScientific_name\nEnglish_name\nArtificial_tax_class\nGroupping\n\n\n\n\n20\nGavia stellata\nRed-throated Diver\nDivers\nDivers\n\n\n30\nGavia arctica\nBlack-throated Diver\nDivers\nDivers\n\n\n40\nGavia immer\nGreat Northern Diver\nDivers\nDivers\n\n\n50\nGavia adamsii\nWhite-billed Diver\nDivers\nDivers\n\n\n59\nGavia spec.\nunidentified diver\nDivers\nDivers\n\n\n60\nPodilymbus podiceps\nPied-billed Grebe\nGrebes\nGrebes"
  },
  {
    "objectID": "packages/2023-04-16-seamonas/seamonas.html#column_descriptions",
    "href": "packages/2023-04-16-seamonas/seamonas.html#column_descriptions",
    "title": "seamonas",
    "section": "Column_Descriptions",
    "text": "Column_Descriptions\n\nHarmonized column names and guidance for completing each entry.\n\n\ndata(Column_Descriptions)\n\nExamples of use\n\n\n\n\n\n\n\n\n\nObservations_Name\nObservations_Description\n\n\n\n\nABIOTIC_STRUCTURES\nNumerical codes specifying physical abiotic features. Includes ships and infrastructures such as wind farms."
  },
  {
    "objectID": "packages/2023-04-16-seamonas/seamonas.html#code_descriptions",
    "href": "packages/2023-04-16-seamonas/seamonas.html#code_descriptions",
    "title": "seamonas",
    "section": "Code_Descriptions",
    "text": "Code_Descriptions\n\nUnified descriptions for field entries, includes abiotic structures, activity codes, associations.\n\n\ndata(Code_Descriptions)\n\nExamples of use\n\n\n\n\n\nACTIVITY_CODE\nACTIVITY_DESCRIPTION\n\n\n\n\n0\nUnknown\n\n\n1\nSwimming\n\n\n2\nFlying\n\n\n3\nSubmerged\n\n\n4\nBreaching surface\n\n\n5\nAssociated with platform"
  },
  {
    "objectID": "packages/2023-06-02-germannorthsea/germannorthsea.html",
    "href": "packages/2023-06-02-germannorthsea/germannorthsea.html",
    "title": "GermanNorthSea",
    "section": "",
    "text": "The goal is provide easy access to shapefiles of the North Sea.\nThis package contains shapefiles from the German North Sea: \nDatailed information and uses: https://github.com/MiriamLL/GermanNorthSea\n\n\n\n# install.packages(\"devtools\")\ndevtools::install_github(\"MiriamLL/GermanNorthSea\")\n\n\nlibrary(GermanNorthSea)"
  },
  {
    "objectID": "packages/2023-06-02-germannorthsea/germannorthsea.html#base-maps",
    "href": "packages/2023-06-02-germannorthsea/germannorthsea.html#base-maps",
    "title": "GermanNorthSea",
    "section": "Base Maps",
    "text": "Base Maps\nFor using other CRS, you can use the function st_transform from the package sf.\n\nlibrary(sf)\n\nWarning: package 'sf' was built under R version 4.4.3\n\n\nLinking to GEOS 3.13.0, GDAL 3.10.1, PROJ 9.5.1; sf_use_s2() is TRUE\n\n\n\nGerman_EEZ<-st_transform(German_EEZ, 4326)\nGerman_coast<-st_transform(German_coast, 4326)\nGerman_land<-st_transform(German_land, 4326)\nGerman_natura<-st_transform(German_natura, 4326)\n\n\nggplot()+\n  geom_sf(data = German_EEZ, colour = \"red\", fill= NA,alpha=0.9, lwd = 0.5)+\n  geom_sf(data = German_coast, colour = \"red\", fill= NA,alpha=0.9, lwd = 0.5,linetype=\"dashed\")+\n  geom_sf(data = German_land, colour = 'black', fill = '#ffffbe')+\n  geom_sf(data = German_natura, colour = \"#3d6d22\", fill= '#3d6d22',alpha=0.2, lwd = 0.5)+\n\n  ggspatial::annotation_north_arrow(location =\"bl\", which_north = \"true\", \n        pad_x = unit(0.05, \"in\"), \n        pad_y = unit(0.05, \"in\"),\n        \n        style = north_arrow_fancy_orienteering)+\n  \n  theme(\n  legend.spacing.y = unit(0.05, 'cm'),\n  legend.text=element_text(size=10),\n  legend.background = element_rect(fill='transparent',colour =\"transparent\"),\n  legend.box.background = element_rect(fill='transparent',colour =\"transparent\"),\n  legend.key = element_rect(fill = \"transparent\", colour = \"transparent\"),\n  panel.background = element_rect(fill = '#bde0fe'))+\n  \n  xlab('Longitude')+ylab('Latitude')+\n  \n  theme(panel.border = element_rect(colour = \"black\", fill=NA, linewidth = 1.5))+\n  \n  coord_sf(xlim = c(3,9), ylim = c(53,56),\n                    label_axes = list(top = \"E\", left = \"N\", bottom = 'E', right='N'))"
  },
  {
    "objectID": "packages/2025-07-03-larus/larus.html",
    "href": "packages/2025-07-03-larus/larus.html",
    "title": "larus",
    "section": "",
    "text": "This package offers tools for data manipulation, trip identification, and calculation of trip parameters like duration, maximum distance, and path length. Additionally, it supports trip interpolation.\nThere are three key issues in determining the foraging trips in GSMs attached to gulls:\n\nBattery charge and gaps (intervals) in the data.\nCentral locations might change, so foraging trips can be difficult to identify.\nThe gulls just do whatever they want.\nFor detailed instructions go to: https://github.com/MiriamLL/larus\n\n\n\nYou can install the development version of larus from GitHub with:\n\n# install.packages(\"devtools\")\ndevtools::install_github(\"MiriamLL/larus\")\n\nLoad packages\n\nlibrary(larus)"
  },
  {
    "objectID": "packages.html",
    "href": "packages.html",
    "title": "My list of packages",
    "section": "",
    "text": "I develop R packages that are useful for my work. I‚Äôm often working on new packages so stay tuned."
  },
  {
    "objectID": "packages.html#larus",
    "href": "packages.html#larus",
    "title": "My list of packages",
    "section": "larus",
    "text": "larus\n\nThis package specializes in GPS-GSM tracking data, focusing on gulls (Larus spp.) with devices that transmit data remotely and usually need no post-retrieval correction. It offers tools for data manipulation, automated trip identification, and calculation of key movement parameter. Because gulls are unpredictable, moving between roosting sites this package helps researchers understand their complex and variable behaviors.\n\n\n\n\n\n\n\n\n\n\n\n\nThe package contains functions to:\n\nCheck battery charge. Monitor the battery levels to identify potential data loss or reduced sampling frequency caused by low power.\nCheck gaps (intervals) in the data. Examine the time intervals between consecutive data points to detect missing data segments or irregular sampling, which can affect the accuracy of movement analysis.\nCheck shifts in central locations. Identify changes or drifts in the central reference points (e.g., nesting or roosting sites), as these can influence trip segmentation and complicate the identification of foraging behavior.\nInterpolate or sub-sample. Apply interpolation methods to fill small gaps in the data for continuous movement paths, or sub-sample data to standardize time intervals, improving comparability and analysis consistency.\nCalculate trip parameters such as duration, maximum distance, and path length.\n\nFor detailed instructions go to: https://github.com/MiriamLL/larus"
  },
  {
    "objectID": "packages.html#germannorthsea",
    "href": "packages.html#germannorthsea",
    "title": "My list of packages",
    "section": "GermanNorthSea",
    "text": "GermanNorthSea\n\nThis package provides easy access to shapefiles for the North Sea region, essential for spatial analyses and mapping in marine research. Seamlessly integrated with R, it enables users to quickly incorporate these datasets into workflows and create detailed, customizable maps with minimal effort. This accelerates data exploration while ensuring reproducibility and consistency, making it easy to generate maps repeatedly for reports, publications, or decision-making.\n\n\n\n\n\n\n\n\n\n\n\n\nThe package contains:\n\nDetailed shapefiles covering the German North Sea, such as administrative boundaries, marine protected areas, shipping lanes, and other relevant geographic features. \n\nYou can install the package GermanNorthSea from GitHub with:\n\ndevtools::install_github(\"MiriamLL/GermanNorthSea\")\n\nDetailed information and uses: https://github.com/MiriamLL/GermanNorthSea. \nFor referencing, please use the original resources and links provided in the githubpage for the different shapefiles."
  },
  {
    "objectID": "packages.html#seamonas",
    "href": "packages.html#seamonas",
    "title": "My list of packages",
    "section": "seamonas",
    "text": "seamonas\n\nThe package seamonas provides easy and streamlined access to information based on established guidelines for monitoring seabirds at sea. It includes detailed table content along with a comprehensive sample dataset to support practical implementation and data analysis. The information is derived from the HELCOM Monitoring Guidelines for Seabirds at Sea and is linked to the ESAS database, ensuring users have reliable and standardized reference material.\n\n\n\n\n\n\n\n\n\n\n\n\nThe package seamonas contains:\n\nA list of 549 species across morphological separated groups.\nHarmonized column names and guidance for completing each entry.\nUnified descriptions for field entries, includes abiotic structures, activity codes, associations.\nOne trip example from a monitoring containing basic trip information.\nOne survey example from a monitoring containing survey information.\nOne survey example from a monitoring containing species detected and specifications.\n\nDetailed information and uses: https://github.com/MiriamLL/seamonas\nYou can install the development version of seamonas from GitHub with:\n\ndevtools::install_github(\"MiriamLL/seamonas\")"
  },
  {
    "objectID": "packages.html#sula",
    "href": "packages.html#sula",
    "title": "My list of packages",
    "section": "sula",
    "text": "sula\n\nThis package specializes in GPS data from recovered tracking devices, offering tools for analyzing animal movement. It includes example datasets from masked boobies (Sula dactylatra) tracked on Rapa Nui (Easter Island), and provides functions for data cleaning, trip identification, and calculation of key movement parameters such as trip duration, total distance, and path length.\n\n\n\n\n\n\n\n\n\n\n\n\nThe package contains:\n\nData from GPS collected from masked booby at Rapa Nui, Chile.\nThirteen functions to clean and calculate trip parameters from GPS data.\n\nDetailed information and uses: https://github.com/MiriamLL/sula\nYou can install the development version of sula from GitHub with:\n\ndevtools::install_github(\"MiriamLL/sula\")\n\nCreated in 2020, updated in 2025, after replacing rgeos with sf."
  },
  {
    "objectID": "packages.html#spheniscus",
    "href": "packages.html#spheniscus",
    "title": "My list of packages",
    "section": "spheniscus",
    "text": "spheniscus\n\nDesigned for the analysis of TDR (Time-Depth Recorder) data from recovered loggers, this package includes example datasets from Humboldt penguins (Spheniscus humboldti) studied on Tilgo Island, Chile. It provides a comprehensive suite of tools for data preprocessing, dive detection, correction of zero-depth values, visualization, and the calculation of key diving metrics.\n\n\n\n\n\n\n\n\n\n\n\n\nThe package contains:\n\nData from TDR collected from Humboldt penguins at Tilgo Island, Chile.\nFunctions to clean data and obtain diving parameters from TDR data.\n\nDetailed information and uses: https://github.com/MiriamLL/spheniscus\nYou can install the development version of spheniscus from GitHub with:\n\ndevtools::install_github(\"MiriamLL/speniscus\")"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "My list of publications",
    "section": "",
    "text": "Here you can find abstracts and links to my publications.\nIf you can‚Äôt access a publication please don‚Äôt hesitate to contact me.\nYou can also find me on GoogleScholar and ResearchGate.\nMy ORCID is 0000-0002-7632-9289."
  },
  {
    "objectID": "publications.html#section",
    "href": "publications.html#section",
    "title": "My list of publications",
    "section": "2024",
    "text": "2024\n\n12. Variations in inter‚Äêspecific and sex‚Äêrelated niche partitioning in pelagic boobies during their annual cycle\nAuthors: Lerma M, Dehnhard N, Castillo-Guerrero JA, Hernandez-Vazquez S, Voigt CC, Garthe S\nAbstract Animals that co-occur in a region (sympatry) may share the same environment (syntopy), and niche differentiation is expected among closely related species competing for resources. The masked booby (Sula dactylatra) and smaller congeneric red-footed booby (Sula sula) share breeding grounds. In addition to the inter-specific size difference, females of both species are also larger than the respective males (reversed sexual size dimorphism). Although both boobies consume similar prey, sometimes in mixed-species flocks, each species and sex may specialize in terms of their diet or foraging habitats. We examined inter- and intra-specific differences in isotopic values (Œ¥13C and Œ¥15N) in these pelagically feeding booby species during the incubation period at Clarion Island, Mexico, to quantify the degrees of inter- and intra-specific niche partitioning throughout the annual cycle. During incubation, both species preyed mainly on flyingfish and squid, but masked boobies had heavier food loads than red-footed boobies. There was no overlap in isotopic niches between masked and red-footed boobies during breeding (determined from whole blood), but there was slight overlap during the non-breeding period (determined from body feathers). Female masked boobies had a higher trophic position than conspecific males during breeding; however, no such pattern was detected in red-footed boobies. These results provide evidence of inter- and intra-specific niche partitioning in these tropical seabird species, particularly during the breeding period and in the more-dimorphic species. Our results suggest that these closely related species use different strategies to cope with the same tropical marine environment.\nRead more: Link to publication"
  },
  {
    "objectID": "publications.html#section-1",
    "href": "publications.html#section-1",
    "title": "My list of publications",
    "section": "2023",
    "text": "2023\n\n11. Corticosterone levels, leukocyte profiles, and foraging and diving behaviours of Humboldt penguins during chick rearing in Northern Chile\nAuthors: Lerma M, Villavicencio CP, Luna N, Portflitt-Toro M, Serratosa J, Luna-Jorquera G, Garthe S, Quispe R\nAbstract Understanding the physiology of stress in wild animals is essential for the conservation of species subject to anthropogenic perturbations. Humboldt penguins (Spheniscus humboldti) are exposed to increasing anthropogenic impacts in their natural habitat. In this species, females are typically smaller and dive less deep than males. In related species, the more limited foraging habitat of females and their reduced resiliency due to their smaller size were associated with higher mortality. We hypothesise that potential sex-specific differences in the foraging behaviour of Humboldt penguins may also relate to differences in their physiological stress. Here, we studied sex-specific foraging and diving behaviours and variations in plasma corticosterone levels and leukocyte profiles of Humboldt penguins during the chick-rearing period in Northern Chile. We report no evidence of sex-related differences in most foraging parameters, except that males dived significantly deeper than females. We found that plasma corticosterone levels and leukocyte profiles showed no significant differences between the sexes. Furthermore, there was no clear relationship between an individual‚Äôs foraging behaviour and its plasma corticosterone level or leukocyte profile. In summary, we found no support for sex-related differences in physiological stress levels of Humboldt penguins, and no link between their foraging behaviour and their physiological stress. However, we acknowledge that our sample size is small and that more studies are needed. This study contributes with information on the physiological stress and foraging behaviours of Humboldt penguins in Northern Chile. This information can help to understand context-dependent differences in physiological parameters and foraging behaviours for the species.\nRead more: Link to publication\n\n\n10. Seabird morphology determines operational wind speeds, tolerable maxima, and responses to extremes\nAuthors: Nourani E, Kamran S, de Grissac S, Anderson D, Cole NC, Gremillet D, Lempidakis E, Lerma M, McKee JL, Pichegru :, Provost P, Rattenbourg NC, Ryan P, Santos CD, Schoombie S, Tatayah V, Weimerskirch H, Wikelski M, Shepard ELC\nAbstract Storms can cause widespread seabird stranding and wrecking, yet little is known about the maximum wind speeds that birds are able to tolerate or the conditions they avoid. We analyzed >300,000 h of tracking data from 18 seabird species, including flapping and soaring fliers, to assess how flight morphology affects wind selectivity, both at fine scales (hourly movement steps) and across the breeding season. We found no general preference or avoidance of particular wind speeds within foraging tracks. This suggests seabird flight morphology is adapted to a ‚Äúwind niche,‚Äù with higher wing loading being selected in windier environments. In support of this, wing loading was positively related to the median wind speeds on the breeding grounds, as well as the maximum wind speeds in which birds flew. Yet globally, the highest wind speeds occur in the tropics (in association with tropical cyclones) where birds are morphologically adapted to low median wind speeds. Tropical species must therefore show behavioral responses to extreme winds, including long-range avoidance of wind speeds that can be twice their operable maxima. By contrast, Procellariiformes flew in almost all wind speeds they encountered at a seasonal scale. Despite this, we describe a small number of cases where albatrosses avoided strong winds at close range, including by flying into the eye of the storm. Extreme winds appear to pose context-dependent risks to seabirds, and more information is needed on the factors that determine the hierarchy of risk, given the impact of global change on storm intensity.\nRead more: Link to publication"
  },
  {
    "objectID": "publications.html#section-2",
    "href": "publications.html#section-2",
    "title": "My list of publications",
    "section": "2022",
    "text": "2022\n\n9. Nutritional state variations in a tropical seabird throughout its breeding season\nAuthors: Lerma M, Dehnhard N, Castillo-Guerrero JA, Fernandez G\nAbstract Individual body condition is frequently used to explain differences in foraging and breeding ecology in seabirds. However, little is known about the covariations of body mass with the nutritional state of animals as measured through plasma metabolites and how these different measures vary between and within individuals during breeding. Here, we assessed intra-individual variations of plasma metabolites (triglycerides, cholesterol, protein, and √ü-hydroxybutyrate concentrations) and in body mass of Blue-footed boobies (Sula nebouxii) throughout their breeding season 2011‚Äì2012 in Isla El Rancho, Mexico. We found breeding-stage and sex-specific variations in individuals‚Äô plasma metabolite concentrations, but these did not mirror variations in body mass. Before egg-laying, females had higher triglycerides, cholesterol, and protein concentrations than males. In contrast, males used their nutritional reserves (higher √ü-hydroxybutyrate concentrations) more than females during the breeding season (except for early chick-rearing). At the individual level, males gained weight during the breeding season, whereas females lost weight. We also found that between-individual differences in plasma metabolite concentrations and changes in body mass were not consistent throughout the breeding season, while individual body mass was significantly repeatable. This study contributes to a better understanding of seabird breeding ecology and physiology by showing that sex-specific breeding roles might highly influence the nutritional state. Similar patterns might occur in other seabird species, helping to explain why we can find stage- and sex-specific foraging behaviors even in monomorphic species.\nRead more: Full publication"
  },
  {
    "objectID": "publications.html#section-3",
    "href": "publications.html#section-3",
    "title": "My list of publications",
    "section": "2020",
    "text": "2020\n\n8. Breeding stage, not sex, affects foraging characteristics in masked boobies at Rapa Nui\nAuthors: Lerma M, Dehnhard N, Luna-Jorquera G, Voigt CC, Garthe S\nAbstract Sexual segregation in foraging occurs in some species and populations of boobies (Sulidae), but it is not a general pattern. Sexual segregation in foraging may occur to avoid competition for food, and this competition may intensify during specific stages of breeding. We examined sexual segregation in foraging in relation to breeding stage in masked boobies Sula dactylatra at Rapa Nui by tracking simultaneously incubating and chick-rearing birds using GPS recorders (n = 18) and collected a total of 11 regurgitate samples. Stable isotope analyses (Œ¥13C and Œ¥15N) of whole blood samples were carried out in 20 birds. There were no differences in foraging trip parameters or diet between females and males. Both sexes traveled farther and for longer while incubating than while rearing chicks. Isotopic niches (Œ¥13C and Œ¥15N) overlapped to some degree among all groups at all times, but the lowest overlap between sexes occurred during incubation. While preying on ephemerally distributed flying fish, vertical or horizontal competition avoidance may be almost impossible, and thus females and males share their foraging grounds. Since birds were tracked simultaneously, shorter foraging trips of chick-rearing birds must be an effect of the constraints of provisioning the chick. Differences observed in Œ¥15N and Œ¥13C values between sexes may be caused by subtle differences in their foraging behaviors, or by differences in physiology linked to breeding. Our findings suggest that local oceanography and its inherent food distribution are determinants for sexual segregation in foraging patterns in masked boobies and possibly also other booby species.\nRead more: Full publication\n\n\n7. Foraging ranges of Humboldt penguins Spheniscus humboldti from Tilgo island: the critical need for protecting a unique marine habitat\nAuthors: Quispe R, Lerma M, Luna N, Portflitt-Toro M, Serratosa J, Luna-Jorquera\nAbstract The largest population of Humboldt Penguins resides in a fertile archipelago of the north-central coast of Chile, formed by eight islands in proximity to upwelling centers of the Humboldt Current System. However, five of these islands lack legal protection. Here, we report the results of breeding Humboldt Penguins tracked while foraging from Tilgo Island. The average and maximum foraging radii around the colony were 22 km and 43 km, respectively. Our data indicate that trip ranges overlap areas proposed for industrial projects. Because Humboldt Penguins are sentinels of local ecosystem health, this underscores the value of expanding conservation zones in this unique marine location.\nRead more: Full publication\n\n\n6. Foraging ecology of a marine top predator in the Eastern Tropical Pacific over 3 years with different ENSO phases\nAuthors: Lerma M, Castillo-Guerrero JA Hernandez-Vazquez S, Garthe S\nAbstract The El Ni√±o Southern Oscillation (ENSO) is a recurrent climatic pattern with important ecological consequences for seabirds due to its impacts on the abundance and distribution of food resources. We investigated the effects of ENSO phases on the foraging ecology of a marine top predator at Clarion Island in the Eastern Tropical Pacific using GPS and time-depth recorder data and regurgitates from incubating masked boobies (Sula dactylatra) during 3 consecutive years. Foraging locations were recorded in 2016 (El Ni√±o, one female, three males), 2017 (neutral; six females, nine males), and 2018 (La Ni√±a; eight females, ten males). Local sea surface temperature (SST) and chlorophyll-a concentration (CHL) within the birds‚Äô foraging range were compared among the 3 years. Regurgitates were collected opportunistically from 25 and 31 incubating adults in 2017 and 2018, respectively. Average local CHL and SST were similar among years (mean SST 25 ¬∞C; mean CHL 0.10 and of 0.09 mg m‚àí3 in January and March, respectively). Masked boobies travelled a maximum of 66 ¬± 34 km from the colony. The maximum trip duration was 7.7 ¬± 3.4 h and total distance travelled during a foraging trip was 164 ¬± 73 km, with no sex- or year-related differences. Masked boobies mainly caught flying fish, but their diet also included one squid and six other fish families. In contrast to previously reported changes in foraging ecology of seabirds, masked boobies at Clarion Island seemed to be unaffected during El Ni√±o, because the local oceanography was relatively unperturbed by ENSO oscillations.\nRead more: Full publication\n\n\n5. Foraging ecology of masked boobies (Sula dactylatra) in the world‚Äôs largest ‚Äòoceanic desert‚Äô\nAuthors: Lerma M, Serratosa J, Luna-Jorquera G, Garthe S\nAbstract The South Pacific Gyre has the most hyper-oligotrophic waters in the world and is considered the largest ‚Äúoceanic desert.‚Äù Rapa Nui (Easter Island), located within the South Pacific Gyre, is a breeding ground for masked boobies (Sula dactylatra), which are seabirds with a foraging range that effectively confines them within the gyre. The foraging ecology of this species in the gyre was examined by attaching GPS and time-depth devices to chick-rearing adult birds (9 and 14 birds in 2016 and 2017, respectively) and by collecting regurgitates (18 and 15 samples in 2016 and 2017, respectively). In addition, the birds‚Äô foraging ecology between years was compared. Masked boobies traveled in various directions, dived at unspecific locations, and explored areas < 110 km from the colony. Local environmental conditions were not significantly different between years, and differences in foraging parameters (maximum foraging range, trip duration, and dive depth) were greater among individuals than between years. The foraging characteristics of masked boobies suggest that resources were ephemerally distributed around the colony, with similar abundances across years. Under these conditions, traveling to unspecific locations may increase the area covered and the probability of prey encounter. The spatial and temporal consistencies in environmental conditions explain the uniformity of foraging parameters between years. The ability of masked boobies to exploit ephemerally distributed resources in seascapes like Rapa Nui may help explain its pantropical distribution.\nRead more: Full publication\n\n\n4. Zinc concentrations in Blue-footed booby (Sula nebouxii) eggs, nestlings, and adults\nAuthors: Lerma M, Castillo-Guerrero JA, Garcia-Hernandez J, Fernandez G\nAbstract Zinc is essential for animal metabolism, but the variation in Zn concentrations within seabird populations has been seldom explored. We collected Blue-footed booby (Sula nebouxii) eggs during 2012 and 2013 and blood samples from nestlings and adults during 2011 and 2012 in Sinaloa, Mexico, to evaluate differences in Zn concentrations among years, ages, sexes, and breeding stages. Zinc concentrations in eggs ranged between 27.3 and 64.9 ppm (dry weight), whereas Zn levels in the blood of nestlings and adults ranged between 16.1 and 53.1 ppm (dry weight). Egg Zn concentrations did not differ due to developmental stage, although Zn concentrations were significantly higher in 2013 than in 2012. Nestling Zn concentrations differed between years and decreased gradually with age. Chicks had significantly higher Zn concentrations than those of adults. Once nestlings stopped growing, females presented higher Zn concentrations than males. Adult Zn concentrations were higher during the pre-laying period than during the other breeding stages. Our results suggest that growth, sex, and breeding stage affect blood Zn concentrations, which may be due to stage-specific requirements. When compared with those of other seabird species, the Zn concentrations reported here are intermediate, and we did not detect adverse effects on either nestlings or adults.\nRead more: Full publication"
  },
  {
    "objectID": "publications.html#section-4",
    "href": "publications.html#section-4",
    "title": "My list of publications",
    "section": "2017",
    "text": "2017\n\n3. Non-Breeding Distribution, Abundance, and Roosting Habitat Use of the American Oystercatcher (Haematopus palliatus frazari) in Sinaloa, Mexico\nAuthors: Lerma M, Castillo-Guerrero JA, Palacios E\nAbstract The American Oystercatcher (Haematopus palliatus frazari) is federally listed as endangered in Mexico due to habitat loss and small population size. Recent surveys indicate that the State of Sinaloa supports about half of the breeding population in Mexico. However, no information is available about the non-breeding ecology in Mexico. To assess American Oystercatcher distribution, abundance, and roosting habitat use during the nonbreeding season (3 August 2014-23 January 2015), six bays were surveyed in Sinaloa. A total of 1,351 American Oystercatchers were detected using this area based on maximum count per roosting site at or near high tide. American Oystercatchers roosted in flocks of variable size (3‚Äì253 individuals per flock) with Bah√≠a Santa Mar√≠a hosting the main roosting sites in Sinaloa. Mangrove islands and mudflats had larger numbers of individuals than expected relative to the availability of those habitats. The non-breeding Sinaloa population comprised approximately 45.0% of the total H. p.¬†frazari population estimate (n = 3,000 individuals). Bah√≠a Santa Mar√≠a represented 74.6% of the non-breeding population observed in Sinaloa. Thus, Sinaloa, and particularly Bah√≠a Santa Mar√≠a, stand out as critical sites for the conservation of this subspecies. Hypothesized threats to American Oystercatchers were predators, livestock, and human activities.\nRead more: Full Publication\n\n\n2. Lead, cadmium and mercury in the blood of the blue-footed booby (Sula nebouxii) from the coast of Sinaloa, Gulf of California, Mexico\nAuthors: Lerma M, Castillo-Guerrero JA, Ruelas-Inzunza J, Fernandez, G\nAbstract We used blood samples of the Blue-footed Booby, considering sex (female and male) and age-class (adult and chick) of individuals at different breeding stages during two breeding seasons (2010‚Äì2011 and 2011‚Äì2012) in Isla El Rancho, Sinaloa, to determine lead, cadmium, and mercury concentrations. Lead and cadmium concentrations were below our detection limit (0.05 and 0.36 ppm, respectively). A higher concentration of mercury was found in early stages of breeding, likely related to changes in mercury environmental availability. Mercury concentrations in adults did not relate with their breeding output. Males and adults had higher mercury concentration than females and chicks. We provide information of temporal, sex and age-related variations in the concentrations of mercury in blood of the Blue-footed Booby.\nRead more: Full Publication"
  },
  {
    "objectID": "publications.html#section-5",
    "href": "publications.html#section-5",
    "title": "My list of publications",
    "section": "2016",
    "text": "2016\n\n1. Environmentally-mediated flexible foraging strategies in Brown Boobies in the Gulf of California\nAuthors: Castillo-Guerrero JA, Lerma M, Mellink E, Suazo-Guill√©n E, Pe√±aloza-Padilla EA\nAbstract The Brown Booby Sula leucogaster is a seabird with a pantropical distribution across a wide variety of oceanic environments. Sexual size dimorphism in Brown Boobies has been proposed as an explanation for intersexual differences in foraging, but results have been inconsistent. We investigated whether there is context-dependent foraging behaviour driven by local environmental conditions. In this study, we evaluated (1) inter-sex differences in foraging behaviour (by capillary tubes, temperature and depth recorders, and diet) at two colonies in the Gulf of California: Isla San Jorge (ISJ) and Farall√≥n de San Ignacio (FSI) and, (2) intercolonial and interannual differences in foraging behaviour, and (at ISJ) their relationship with local-scale environmental variation, using 5-day composite images of sea surface temperature (SST) and primary productivity (PP) as proxies. Inter-sex differences were few and inconsistent between years, and smaller than overall differences between years and localities. At ISJ, Brown Boobies included more prey species in their diet (27 vs.¬†19 spp.) and dove shallower (2.3 vs.¬†3.14 m) than at FSI. At ISJ, Brown Boobies exhibited adjustments in diving depth and prey size as a function of environmental variation: shallower plunge dives and smaller prey items were related with lower SST and higher PP values, whereas deeper dives and larger prey items were related with higher SST and lower PP values. Our results confirmed that the Brown Booby is highly plastic in its foraging ecology, which explains its ability to live in places with large-scale environmental variation (intercolony and interannual), such as tropical areas worldwide.\nRead more: Full Publication"
  },
  {
    "objectID": "teaching/2021-03-01-IntroaR/IntroaR.html",
    "href": "teaching/2021-03-01-IntroaR/IntroaR.html",
    "title": "Clase R desde cero",
    "section": "",
    "text": "Bienvenido!\nEste material fue preparado para t√©cnicos y estudiantes de posgrado del Centro de Investigaci√≥n de Alimentaci√≥n y Desarrollo CIAD.\nNo obstante, espero sea de ayuda para cualquiera que tenga intenciones de aprender R.\nIr√© subiendo materiales conforme se vayan actualizando.\n\n\nEn esta clase aprender√°s a abrir RStudio e identificar sus partes. \nClick en la imagen para abrir html o en el bot√≥n para descargar pdf.\n\n\n  \n\n\n  Descargar pdf\n\n\n\n\nEn esta clase aprender√°s a como cargar paquetes, seleccionar tu directorio y cargar tus datos en R. \n\n\n  \n\n\n\n  Descargar pdf\n\n\n\n\nEn esta clase aprender√°s como funciona ggplot2 y como crear tus propios gr√°ficos.\n\n\n  \n\n\n\n  Descargar pdf\n\n\n\n\nEn esta clase aprender√°s algunas funciones b√°sicas para realizar operaciones matem√°ticas en R y como moverte entre tus columnas y filas. \n\n\n  \n\n\n\n  Descargar pdf\n\n\n\n\nEn esta clase aprender√°s algunas funciones de tidyverse para poder ordenar tus columnas, limpiar tus datos, unir diferentes archivos y exportar tus nuevos data frames.\n\n\n  \n\n\n\n  Descargar pdf\n\n\n\n\nEn esta clase aprender√°s porque es importante trabajar por proyectos, como crear y compartir un proyecto.\n\n\n  \n\n\n\n  Descargar pdf\n\n\n\n\nEn esta clase aprender√°s como explorar tus datos, cuales son los argumentos para un modelo lineal simple en R y como agregar la linea de ajuste a tu gr√°fico.\n\n\n  \n\n\n\n  Descargar pdf\n\n\n\n\nEn esta clase aprender√°s como convertir a factor, cuales son los argumentos para un an√°lisis de varianza en R y como crear gr√°ficos para visualizar tus resultados del an√°lisis.\n\n\n  \n\n\n\n  Descargar pdf\n\n\n\n\nEsta clase es una introducci√≥n a los modelos mixtos y a la selecci√≥n de modelos usando el AIC.\n\n\n  \n\n\n\n  Descargar pdf"
  },
  {
    "objectID": "teaching/2021-03-29-rmd/rmd.html#intro",
    "href": "teaching/2021-03-29-rmd/rmd.html#intro",
    "title": "Clase de Rmd",
    "section": "Intro",
    "text": "Intro\nEn esta clase aprender√°s como crear documentos en Rmd. \n\n\n  \n\n\n\n\n Descargar"
  },
  {
    "objectID": "teaching/2021-03-29-rmd/rmd.html#rmarkdown-para-escribir-art√≠culos",
    "href": "teaching/2021-03-29-rmd/rmd.html#rmarkdown-para-escribir-art√≠culos",
    "title": "Clase de Rmd",
    "section": "Rmarkdown para escribir art√≠culos",
    "text": "Rmarkdown para escribir art√≠culos\nEn esta clase aprender√°s como agregar citas y formato de revista. \n\n\n  \n\n\n\n\n Descargar"
  },
  {
    "objectID": "teaching/2021-03-29-rmd/rmd.html#presentar-tus-resultados-usando-xaringan",
    "href": "teaching/2021-03-29-rmd/rmd.html#presentar-tus-resultados-usando-xaringan",
    "title": "Clase de Rmd",
    "section": "Presentar tus resultados usando Xaringan",
    "text": "Presentar tus resultados usando Xaringan\nEn esta clase aprender√°s como crear presentaciones en Xaringan. Podr√°s incluir tablas y figuras sin salir de RStudio. \n\n\n  \n\n\n\n\n Descargar"
  },
  {
    "objectID": "teaching/2021-03-29-rmd/rmd.html#estilizar-tus-dispositivas-xaringan",
    "href": "teaching/2021-03-29-rmd/rmd.html#estilizar-tus-dispositivas-xaringan",
    "title": "Clase de Rmd",
    "section": "Estilizar tus dispositivas Xaringan",
    "text": "Estilizar tus dispositivas Xaringan\nEn esta clase aprender√°s como cambiar el estilo de letras o colores de tus presentaciones en Xaringan. Tambi√©n aprender√°s como compartirlas ya sea en github o en pdf. \n\n\n  \n\n\n\n\n Descargar"
  },
  {
    "objectID": "teaching/2021-03-29-rmd/rmd.html#github-zenodo-y-git",
    "href": "teaching/2021-03-29-rmd/rmd.html#github-zenodo-y-git",
    "title": "Clase de Rmd",
    "section": "Github, Zenodo y Git",
    "text": "Github, Zenodo y Git\nEn esta clase aprender√°s como crear un repositorio en github, como utilizar Zenodo para darle un DOI a nuestros materiales y los b√°sicos de Git. \n\n\n  \n\n\n\n\n Descargar"
  },
  {
    "objectID": "teaching/2021-03-29-rmd/rmd.html#reproducibilidad",
    "href": "teaching/2021-03-29-rmd/rmd.html#reproducibilidad",
    "title": "Clase de Rmd",
    "section": "Reproducibilidad",
    "text": "Reproducibilidad\nEn esta clase ver√°s b√°sicos de reproducibilidad en la ciencia y en las publicaciones. \n\n\n  \n\n\n\n\n Descargar"
  },
  {
    "objectID": "teaching/2023-04-18-intro-to-r/intro-to-r.html#slides",
    "href": "teaching/2023-04-18-intro-to-r/intro-to-r.html#slides",
    "title": "Intro to R",
    "section": "Slides",
    "text": "Slides\n\n\n  \n\n\n\n\n Open"
  },
  {
    "objectID": "teaching/2023-04-18-intro-to-r/intro-to-r.html#downloads",
    "href": "teaching/2023-04-18-intro-to-r/intro-to-r.html#downloads",
    "title": "Intro to R",
    "section": "Downloads",
    "text": "Downloads\nTo download the files for the exercises there are several options:\n\nDirectly from github , go to file, click on raw, select save as. See video here.\nIn firefox , open link, click on three lines icon , and select save page as (or control+S).\nIn chrome , open the link, and click on the share icon .\n\nExercises\n\nR script containing exercises from the first part. Click here.\nCsv file containing penguin data. Click here.\n\nPresentation\nTo download the presentation as pdf click here."
  },
  {
    "objectID": "teaching/2023-05-08-data-wrangling/data-wrangling.html#slides",
    "href": "teaching/2023-05-08-data-wrangling/data-wrangling.html#slides",
    "title": "Data wrangling",
    "section": "Slides",
    "text": "Slides\n\n\n  \n\n\n\n\n Download"
  },
  {
    "objectID": "teaching/2023-05-08-data-wrangling/data-wrangling.html#downloads",
    "href": "teaching/2023-05-08-data-wrangling/data-wrangling.html#downloads",
    "title": "Data wrangling",
    "section": "Downloads",
    "text": "Downloads\nTo download the files there are several options:\n\nDirectly from github , go to file, click on raw, select save as. See video here\nIn firefox , open link, click on three lines icon , and select save page as (or control+S)\nIn chrome , open the link, and click on the share icon \n\nExercises\n\nRmd script containing exercises. Click here to download .\nCsv file containing penguin data. Click here to download ."
  },
  {
    "objectID": "teaching/2023-06-06-plotting/plotting.html#slides",
    "href": "teaching/2023-06-06-plotting/plotting.html#slides",
    "title": "Plotting",
    "section": "Slides",
    "text": "Slides\n\n\n  \n\n\n\n\n Download"
  },
  {
    "objectID": "teaching/2023-06-06-plotting/plotting.html#downloads",
    "href": "teaching/2023-06-06-plotting/plotting.html#downloads",
    "title": "Plotting",
    "section": "Downloads",
    "text": "Downloads\nTo download the files there are several options:\n\nDirectly from github , go to file, click on raw, select save as. See video here.\nIn firefox , open link, click on three lines icon , and select save page as (or control+S)\nIn chrome , open the link, and click on the share icon \n\nExercises\n\nRmd script containing exercises. Click here to download.\nShapefile of Europa. Click here to download.\nRmd script to export word document. Click here to download.\nRmd script to export html document. Click here to download."
  },
  {
    "objectID": "teaching/2023-06-06-tracking/tracking.html",
    "href": "teaching/2023-06-06-tracking/tracking.html",
    "title": "Tracking",
    "section": "",
    "text": "Move\nWelcome!\nThis material was prepared for DDA-FTZ\nThe materials will be updated together with the training.\n\n\nIndex\nIn this presentation:\nLoad data - From movebank - From csv\nTidy - Select columns - Export\nTransform - Converting times\nVisualise - Plot - Map\n\n\nSlides\n\n\n  \n\n\n\n\n Open"
  },
  {
    "objectID": "teaching/2024-12-06-tracking/tracking_2024.html",
    "href": "teaching/2024-12-06-tracking/tracking_2024.html",
    "title": "Animal tracking",
    "section": "",
    "text": "There are numerous tools available for analyzing tracking data. In this post, I share a curated collection of my blog entries that focus specifically on movement analysis, covering from data loading and cleaning to visualizations. Additionally, I‚Äôve included a brief list of papers that can serve as guidance when embarking on tracking studies.\n\n\n\nFrom movebank\n\nFrom csv\n\n\n\n\n\nUsage of time formats\n\nConverting times\n\nTime overlap between individuals\n\nLocate the animals central location\n\nInclude Julian days\n\nIdentify Day or night\n\nCalculate speed\n\nBehaviour classification\n\n\n\n\n\nSelect columns\n\nRemove undesired locations\n\nIdentify gaps\n\nComplete or incomplete\n\nExport clean data frame\n\n\n\n\n\nNumber of trips: Identify events\n\nMaximum distance: Distance from point\n\nTotal length path: Distance between points\n\n\n\n\n\nKernel UD considerations\n\nInterpolate a path\n\nCalculate UD and export shapefiles\n\nCalculate shared areas\n\n\n\n\n\nIn land or not\n\n\n\n\n\nPlot basics\n\nCreate a base map in R\n\nInside plot legend\n\nAnimations"
  },
  {
    "objectID": "teaching/2025-02-19-ai-tools/ai-tools.html",
    "href": "teaching/2025-02-19-ai-tools/ai-tools.html",
    "title": "AI Tools in Research",
    "section": "",
    "text": "AI Tools in Research\nThis collection of materials has been compiled by Dagmar Cimiotti and Miriam Lerma, presenting a curated selection of AI tools that are reshaping research. It includes not only an curated list of tools but also practical examples of how these tools can be used.\nIn addition to the tools themselves, implications of AI in research are presented. The goal is to open the discussion on how these technologies can impact the efficiency and integrity of scientific research. Moreover, with the rise of AI in research there are implications from the journals, reviewers and the authors point-of-view by using this technology.\nThis resource goal is to be a guide for those looking to start using AI while considering the broader impact these tools may have on the future of academia and the environment.\n\n\n\n\n\n\nClick on the image to open the pdf"
  },
  {
    "objectID": "teaching/2025-02-19-ai-tools/ai-tools.html#artificial-intelligence",
    "href": "teaching/2025-02-19-ai-tools/ai-tools.html#artificial-intelligence",
    "title": "AI Tools in Research",
    "section": "Artificial Intelligence",
    "text": "Artificial Intelligence\nThe term ‚Äòartificial intelligence‚Äô (AI) was first coined by John McCarthy at a conference in Dartmouth in 1956. Since then, a lot has happened. Large language models (LLM) are a type of AI and have enormous value across the entire value chain of research.¬†\nThey have potential applications in the automation of research techniques\n- Generating a hypothesis (ChatGPT) - Searching for content and get the sources (‚Äúgrey‚Äù literature, laws, scientific publications; perplexity.ai)\n- Searching scientifically published content (scite, connectedpapers)\n- Assist in writing scripts for QGIS (Quantum GIS) and R programming, and Excel-questions (ChatGPT)\n- Detecting plagiarism (quillbot)\n- Improving readability (Grammarly, ChatGPT)\n- Translating (deepl)\n- Creating pictures for presentations / posters (Image Creator from Bing)"
  },
  {
    "objectID": "teaching/2025-02-19-ai-tools/ai-tools.html#limitations",
    "href": "teaching/2025-02-19-ai-tools/ai-tools.html#limitations",
    "title": "AI Tools in Research",
    "section": "Limitations",
    "text": "Limitations\nAI relies heavily on the quality of input data and researchers need to be mindful of this fact. Biased or incomplete datasets can lead to inaccurate insights.\nAdditionally, it can be extremely difficult ‚Äì and sometimes impossible ‚Äì to know how complex machine learning models have arrived at a particular decision. This is known as the ‚Äòblack box‚Äô problem and means it can be challenging for humans to understand how the model arrived at a particular conclusion or prediction based on its input data."
  },
  {
    "objectID": "teaching/2025-02-19-ai-tools/ai-tools.html#chatgpt",
    "href": "teaching/2025-02-19-ai-tools/ai-tools.html#chatgpt",
    "title": "AI Tools in Research",
    "section": "ChatGPT?",
    "text": "ChatGPT?\nOpenAI announced the groundbreaking release of ChatGPT in 2022, an online chatbot that enables users to interact with the GPT-3.5 language model.\nChatGPT is a type of narrow AI (also known as weak AI) because it is designed to perform specific tasks, such as natural language processing and generation, within a defined scope. It does not possess general intelligence or self-awareness, and its capabilities are limited to the tasks it‚Äôs trained on, such as answering questions and generating text based on input.\nChatGPT creators include Ilya Sutskever, chief scientist and cofounder OpenAI. His company was showered with billions of dollars by Microsoft. Among founders are Elon Musk and Amazon Web Services."
  },
  {
    "objectID": "teaching/2025-02-19-ai-tools/ai-tools.html#trying-chatgpt",
    "href": "teaching/2025-02-19-ai-tools/ai-tools.html#trying-chatgpt",
    "title": "AI Tools in Research",
    "section": "Trying ChatGPT",
    "text": "Trying ChatGPT\n\nLink: webpage https://chatgpt.com/\nNewest update: Jan.¬†2025 (Version ChatGPT 4omini)\nFree\nWhy ‚ÄûLog in?‚Äú\nMore personalized and continuous support (timeline).\nNot really necessary.\nChatGPT Plus: Necessary to log in\n23 EUR\nAlways newest ChatGPT version possible\nMore ‚Äúthinking processes‚Äù before answering\nStill fast and working when too many people use ChatGPT\n\n3.App: Just nicer to handle on smartphone. Same functions as web version."
  },
  {
    "objectID": "teaching/2025-02-19-ai-tools/ai-tools.html#trying-chatgpt-1",
    "href": "teaching/2025-02-19-ai-tools/ai-tools.html#trying-chatgpt-1",
    "title": "AI Tools in Research",
    "section": "Trying ChatGPT",
    "text": "Trying ChatGPT\nFor tutorials and problem solving:\n- Incredibly helpful and time saving\nFor literature search:\n- Journal exists\n- Authors exist\nPaper: Does not exist"
  },
  {
    "objectID": "teaching/2025-02-19-ai-tools/ai-tools.html#perplexity.ai",
    "href": "teaching/2025-02-19-ai-tools/ai-tools.html#perplexity.ai",
    "title": "AI Tools in Research",
    "section": "Perplexity.ai",
    "text": "Perplexity.ai\nFor literature search:\nIncludes grey literature\nPeer-review and grey literature seem to be considered equally relevant\nGives data-resources with links"
  },
  {
    "objectID": "teaching/2025-02-19-ai-tools/ai-tools.html#scite.ai",
    "href": "teaching/2025-02-19-ai-tools/ai-tools.html#scite.ai",
    "title": "AI Tools in Research",
    "section": "Scite.ai",
    "text": "Scite.ai\nFor literature search:\nHelpful but limited in the number of free prompts\nInformation still needs to be double-checked"
  },
  {
    "objectID": "teaching/2025-02-19-ai-tools/ai-tools.html#connected-papers",
    "href": "teaching/2025-02-19-ai-tools/ai-tools.html#connected-papers",
    "title": "AI Tools in Research",
    "section": "Connected papers",
    "text": "Connected papers\nFor literature search:\nHelpful for literature search, but most (if not all) literature must have a doi."
  },
  {
    "objectID": "teaching/2025-02-19-ai-tools/ai-tools.html#ai-europe-alternatives",
    "href": "teaching/2025-02-19-ai-tools/ai-tools.html#ai-europe-alternatives",
    "title": "AI Tools in Research",
    "section": "AI Europe alternatives",
    "text": "AI Europe alternatives\nMistral AI (France)\nAleph alpha (Germany)"
  },
  {
    "objectID": "teaching/2025-02-19-ai-tools/ai-tools.html#in-research-journals",
    "href": "teaching/2025-02-19-ai-tools/ai-tools.html#in-research-journals",
    "title": "AI Tools in Research",
    "section": "In Research: Journals",
    "text": "In Research: Journals\nDeclaration of generative AI in scientific writing\nAuthors must declare the use of generative AI in scientific writing upon submission of the paper. The following guidance refers only to the writing process, and not to the use of AI tools to analyze and draw insights from data as part of the research process: Generative AI and AI-assisted technologies should only be used in the writing process to improve the readability and language of the manuscript.\nThe technology must be applied with human oversight and control and authors should carefully review and edit the result, as AI can generate authoritative-sounding output that can be incorrect, incomplete or biased. Authors are ultimately responsible and accountable for the contents of the work.\nAuthors must not list or cite AI and AI-assisted technologies as an author or co-author on the manuscript since authorship implies responsibilities and tasks that can only be attributed to and performed by humans.\nThe use of generative AI and AI-assisted technologies in scientific writing must be declared by adding a statement at the end of the manuscript when the paper is first submitted. The statement will appear in the published work and should be placed in a new section before the references list.\nSource: Journal of Experimental Marine Biology and Ecology"
  },
  {
    "objectID": "teaching/2025-02-19-ai-tools/ai-tools.html#in-research-reviewers",
    "href": "teaching/2025-02-19-ai-tools/ai-tools.html#in-research-reviewers",
    "title": "AI Tools in Research",
    "section": "In Research: Reviewers",
    "text": "In Research: Reviewers\nReviews can be discarded if they are found to be primarily generated by an AI software.\nJournals are using AI detectors to identify if the review was human generated. For example: gptzero."
  },
  {
    "objectID": "teaching/2025-02-19-ai-tools/ai-tools.html#in-research-authors",
    "href": "teaching/2025-02-19-ai-tools/ai-tools.html#in-research-authors",
    "title": "AI Tools in Research",
    "section": "In Research: Authors",
    "text": "In Research: Authors\nAuthors should be careful when using this technology and carefully review and edit the result. Authors are ultimately responsible and accountable for the contents of the work.\nImages generated using AI also had been retracted. There are negative implications while using misleading images."
  },
  {
    "objectID": "teaching/2025-02-19-ai-tools/ai-tools.html#potential",
    "href": "teaching/2025-02-19-ai-tools/ai-tools.html#potential",
    "title": "AI Tools in Research",
    "section": "Potential",
    "text": "Potential\nChatGPT and its counterparts are here to stay. For this reason, it is crucial to understand its capabilities in the research field, as well as its limitations and potential ethical shortcomings."
  },
  {
    "objectID": "teaching/2025-02-19-ai-tools/ai-tools.html#environmental-impacts",
    "href": "teaching/2025-02-19-ai-tools/ai-tools.html#environmental-impacts",
    "title": "AI Tools in Research",
    "section": "Environmental impacts",
    "text": "Environmental impacts\nThere is a negative side to the explosion of AI and its associated infrastructure, according to a growing body of research.\n- The proliferating data centers that house AI servers produce electronic waste.\n- They are large consumers of water, which is becoming scarce in many places.\n- They rely on critical minerals and rare elements, which are often mined unsustainably.\n- And they use massive amounts of electricity, spurring the emission of planet-warming greenhouse gases."
  },
  {
    "objectID": "teaching/2025-02-19-ai-tools/ai-tools.html#take-home-messages",
    "href": "teaching/2025-02-19-ai-tools/ai-tools.html#take-home-messages",
    "title": "AI Tools in Research",
    "section": "Take-home messages",
    "text": "Take-home messages\nAI tools are here to stay, and many researchers are already using them.\n- AI tools save us a lot of time, but we must be careful when evaluating the responses they give us; critical thinking becomes key.\n- Do not blindly trust the information, always double-check.\n- We must also be mindful of using these technologies, as they have a real impact on the environment."
  },
  {
    "objectID": "teaching/2025-04-01-journals/journals.html",
    "href": "teaching/2025-04-01-journals/journals.html",
    "title": "Choosing a journal",
    "section": "",
    "text": "Choosing a journal\nIn this blog post, I provide a decision tree with that might help you choose the most suitable journal for publishing your research.\nI‚Äôll also share tips and links to get you started, focusing on journal scope, open access fees, impact factor, DOI, peer review process, and publication timelines.\nI briefly share my own experiences. In addition, I offer a brief list of journals that publish ornithological research, complete with a map to guide your selection.\nThe goal is to be a guide for those looking to submit papers into an ornithological journals.\n\n\nClick on the image to open the pdf\n\n\n  \n\n\n\n\nLinks to journals\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJournal\nLink\n\n\n\n\nActa ornithologica\nhttps://bioone.org/journals/acta-ornithologica/current\n\n\nArdea\nhttps://bioone.org/journals/ardea\n\n\nArdeola\nhttps://www.ardeola.org/es/autores/\n\n\nAustral ecology\nhttps://onlinelibrary.wiley.com/journal/14429993\n\n\nAvian Research\nhttps://www.sciencedirect.com/journal/avian-research\n\n\nBehavioural ecology and sociobiology\nhttps://link.springer.com/journal/265\n\n\nBird Conservation International\nhttps://www.cambridge.org/core/journals/bird-conservation-international\n\n\nBird study\nhttps://www.tandfonline.com/journals/tbis20\n\n\nEcology\nhttps://esajournals.onlinelibrary.wiley.com/journal/19399170\n\n\nEcology and Evolution\nhttps://onlinelibrary.wiley.com/journal/20457758\n\n\nEcology letters\nhttps://onlinelibrary.wiley.com/journal/14610248\n\n\nEcosphere\nhttps://esajournals.onlinelibrary.wiley.com/journal/21508925\n\n\nEmu\nhttps://www.tandfonline.com/journals/temu20\n\n\nIbis\nhttps://onlinelibrary.wiley.com/journal/1474919x\n\n\nJournal of Animal Ecology\nhttps://besjournals.onlinelibrary.wiley.com/journal/13652656\n\n\nJournal of Avian Biology\nhttps://nsojournals.onlinelibrary.wiley.com/journal/1600048x\n\n\nJournal of Field Ornithology\nhttps://journal.afonet.org/\n\n\nJournal of Ornithology\nhttps://link.springer.com/journal/10336\n\n\nJournal of Sea Research\nhttps://www.sciencedirect.com/journal/journal-of-sea-research\n\n\nMarine Biology\nhttps://link.springer.com/journal/227\n\n\nMarine ecology\nhttps://onlinelibrary.wiley.com/journal/14390485\n\n\nMarine Ecology Progress Series\nhttps://www.int-res.com/journals/meps/meps-home/\n\n\nMarine Ornithology\nhttp://www.marineornithology.org/\n\n\nMovement ecology\nhttps://movementecologyjournal.biomedcentral.com/about\n\n\nOecologia\nhttps://link.springer.com/journal/442\n\n\nOikos\nhttps://nsojournals.onlinelibrary.wiley.com/journal/1600048x\n\n\nOrnithologia Neotropical\nhttps://journals.sfu.ca/ornneo/index.php/ornneo/about/submissions\n\n\nOrnithological applications\nhttps://academic.oup.com/condor\n\n\nOrnithology\nhttps://academic.oup.com/auk\n\n\nOrnithology research\nhttps://link.springer.com/journal/43388\n\n\nPacific Science\nhttps://bioone.org/journals/pacific-science\n\n\nThe Auk - Now Ornithology\nhttps://americanornithology.org/publications/ornithology/\n\n\nThe Condor - Now Ornithological applications\nhttps://americanornithology.org/publications/ornithological-applications/\n\n\nTropical Zoology\nhttps://www.pagepress.org/biology/index.php/tz\n\n\nWaterbirds\nhttps://bioone.org/journals/waterbirds/scope-and-details\n\n\nWilson Journal of Ornithology\nhttps://wilsonsociety.org/pubs/wjo/"
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "Choosing a journal\n\n\n\n\n\nA file with a decision tree that might help you choose the most suitable journal for publishing your research. Links to journals are included.\n\n\n\n\n\n\nApr 1, 2025\n\n\n\n\n\n\n  \n\n\n\n\nAI Tools in Research\n\n\n\n\n\nA presentation with a compilation of AI Tools and its implications in research.\n\n\n\n\n\n\nFeb 19, 2025\n\n\n\n\n\n\n  \n\n\n\n\nAnimal tracking\n\n\n\n\n\nA curated collection of my blog posts focused on animal tracking analysis.\n\n\n\n\n\n\nDec 6, 2024\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nPlotting\n\n\n\n\n\nUsing ggplot to create plots and maps.\n\n\n\n\n\n\nJun 6, 2023\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nTracking\n\n\n\n\n\nA presentation with tips and tools to put you analyses on a workflow.\n\n\n\n\n\n\nJun 6, 2023\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nData wrangling\n\n\n\n\n\nLoad data, basic calculations, tidydata, pipe operations, join and export data frames.\n\n\n\n\n\n\nMay 8, 2023\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nIntro to R\n\n\n\n\n\nFirst steps into R. Install or update R. Workspace panes. Packages. Directories. Load data.\n\n\n\n\n\n\nApr 18, 2023\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nClase de Rmd\n\n\n\n\n\nDesde como crear documentos en Rmd hasta como compartirlos.\n\n\n\n\n\n\nMar 16, 2021\n\n\nMiriam Lerma\n\n\n\n\n\n\n  \n\n\n\n\nClase R desde cero\n\n\n\n\n\nDesde como abrir R y RStudio hasta como exportar tus gr√°ficos, la idea es que este curso te haga sentir c√≥modo trabajando tus datos y an√°lisis en R.\n\n\n\n\n\n\nJan 28, 2021\n\n\n\n\n\n\nNo matching items"
  }
]